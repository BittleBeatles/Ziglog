-- MySQL dump 10.13  Distrib 8.0.19, for Win64 (x86_64)
--
-- Host: 127.0.0.1    Database: ziglogdb
-- ------------------------------------------------------
-- Server version	8.2.0

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!50503 SET NAMES utf8mb4 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

--
-- Table structure for table `bookmark`
--

DROP TABLE IF EXISTS `bookmark`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `bookmark` (
  `id` bigint NOT NULL AUTO_INCREMENT,
  `member_id` bigint NOT NULL,
  `note_id` bigint NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `unique_constraint` (`member_id`,`note_id`),
  KEY `FKew5wnn961kij88sojdecravr1` (`note_id`),
  CONSTRAINT `FK5bm7rup91j277mc7gg63akie2` FOREIGN KEY (`member_id`) REFERENCES `member` (`id`),
  CONSTRAINT `FKew5wnn961kij88sojdecravr1` FOREIGN KEY (`note_id`) REFERENCES `note` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=165 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `bookmark`
--

LOCK TABLES `bookmark` WRITE;
/*!40000 ALTER TABLE `bookmark` DISABLE KEYS */;
INSERT INTO `bookmark` VALUES (49,1,55),(66,1,92),(69,1,93),(70,1,94),(71,1,95),(73,1,96),(74,1,97),(87,1,98),(72,1,99),(76,1,100),(67,1,101),(68,1,102),(150,2,6),(136,2,7),(137,2,9),(54,2,58),(4,3,6),(111,4,6),(108,4,7),(39,4,8),(5,4,9),(147,4,10),(6,4,11),(7,4,13),(8,4,14),(37,4,15),(10,4,16),(11,4,18),(12,4,19),(13,4,20),(14,4,21),(15,4,22),(16,4,23),(17,4,24),(18,4,25),(19,4,26),(20,4,27),(21,4,28),(22,4,29),(23,4,30),(24,4,31),(25,4,32),(26,4,33),(27,4,34),(28,4,35),(29,4,36),(30,4,37),(31,4,38),(32,4,39),(33,4,40),(34,4,41),(35,4,42),(38,4,43),(64,4,58),(77,4,101),(58,5,6),(57,5,8),(84,5,108),(103,6,106),(104,6,107),(105,6,112),(102,6,113),(92,6,120),(94,6,121),(95,6,122),(96,6,123),(97,6,124),(98,6,125),(99,6,126),(100,6,127),(101,6,128),(106,6,130),(107,6,131),(164,7,55),(61,8,6),(60,8,7),(62,8,8),(59,8,55),(56,8,58),(90,10,8),(153,15,9),(156,15,14);
/*!40000 ALTER TABLE `bookmark` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `folder`
--

DROP TABLE IF EXISTS `folder`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `folder` (
  `id` bigint NOT NULL AUTO_INCREMENT,
  `member_id` bigint NOT NULL,
  `parent_id` bigint DEFAULT NULL,
  `title` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `FKc6kqvlv0usxg86dodoybx4lfm` (`member_id`),
  KEY `FKn0cjh1seljcp0mc4tj1ufh99m` (`parent_id`),
  CONSTRAINT `FKc6kqvlv0usxg86dodoybx4lfm` FOREIGN KEY (`member_id`) REFERENCES `member` (`id`),
  CONSTRAINT `FKn0cjh1seljcp0mc4tj1ufh99m` FOREIGN KEY (`parent_id`) REFERENCES `folder` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=46 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `folder`
--

LOCK TABLES `folder` WRITE;
/*!40000 ALTER TABLE `folder` DISABLE KEYS */;
INSERT INTO `folder` VALUES (1,1,NULL,'root'),(2,2,NULL,'root'),(5,2,2,'asdasdasd'),(6,2,2,'가나다라마바'),(7,2,2,'abcd'),(8,3,NULL,'root'),(9,3,8,'나김코치다'),(10,4,NULL,'root'),(11,4,10,'Docker'),(12,4,10,'Kubernetes'),(13,5,NULL,'root'),(14,6,NULL,'root'),(18,2,2,'폴더'),(20,7,NULL,'root'),(21,8,NULL,'root'),(22,8,21,'기능 추가해줘요'),(23,8,21,'버그'),(24,9,NULL,'root'),(25,1,31,'Algorithm-Basics'),(26,1,31,'Data-Structure'),(27,1,31,'Dynamic-Programming'),(28,1,31,'Graph'),(29,1,31,'Number-Theory'),(30,1,1,'CS'),(31,1,1,'알고리즘'),(35,6,14,'포트폴리오'),(36,10,NULL,'root'),(37,10,36,'컨설턴트 QA'),(38,11,NULL,'root'),(39,6,14,'프로젝트'),(40,6,14,'React'),(41,12,NULL,'root'),(42,13,NULL,'root'),(43,14,NULL,'root'),(44,15,NULL,'root'),(45,15,44,'ㅁㅈㄹ');
/*!40000 ALTER TABLE `folder` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `member`
--

DROP TABLE IF EXISTS `member`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `member` (
  `id` bigint NOT NULL AUTO_INCREMENT,
  `email` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `nickname` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `password` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `profile_url` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `role` enum('ADMIN','USER') COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `UK_mbmcqelty0fbrvxp1q58dn57t` (`email`)
) ENGINE=InnoDB AUTO_INCREMENT=16 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `member`
--

LOCK TABLES `member` WRITE;
/*!40000 ALTER TABLE `member` DISABLE KEYS */;
INSERT INTO `member` VALUES (1,'hanulkim2000@gmail.com','Iam김하림',NULL,'https://ziglog.s3-ap-northeast-2.amazonaws.com/profile/다꼬리.gif','USER'),(2,'pj0642@gmail.com','내가진짜김하늘',NULL,'https://ziglog.s3-ap-northeast-2.amazonaws.com/profile/제목없음.png','USER'),(3,'whdtmql1228@gmail.com','서쪽의슬픈코끼리9867',NULL,'https://lh3.googleusercontent.com/a/ACg8ocIfr7pi-r8IqXxkDHHTK05nODuLQQRi1WxDmlbh5_x5=s96-c','USER'),(4,'suhyeng119@gmail.com','수형',NULL,'https://ziglog.s3-ap-northeast-2.amazonaws.com/profile/리트리버.jpg','USER'),(5,'fueledbyjellies@gmail.com','리락쿠마',NULL,'https://ziglog.s3-ap-northeast-2.amazonaws.com/profile/D5wK7AIVUAAOHiU.jpg','USER'),(6,'tjddyd1663@gmail.com','사장님맥주하나요',NULL,'https://ziglog.s3-ap-northeast-2.amazonaws.com/profile/catgif.gif','USER'),(7,'reunai@snu.ac.kr','살짝귀여운성용3863',NULL,'https://lh3.googleusercontent.com/a/ACg8ocKv1m02QysitqvM0Mz1nhc1z6OS_GBGmL84HWDeIMmK=s96-c','USER'),(8,'haaarimmm@gmail.com','지그로그화이팅',NULL,'https://lh3.googleusercontent.com/a/ACg8ocJml2rlbiB0HOmVczl2OkJGcT9MNNWaZ-_f8y_OyxRrOQ=s96-c','USER'),(9,'quso12358@naver.com','엄청못생긴알파카3645',NULL,'http://k.kakaocdn.net/dn/dpk9l1/btqmGhA2lKL/Oz0wDuJn1YV2DIn92f6DVK/img_640x640.jpg','USER'),(10,'gsmj1712@gmail.com','약간달리는토끼7000',NULL,'https://lh3.googleusercontent.com/a/ACg8ocIY2zNmoFWFJUZnfOOdkgP2nG0Wkf6LTMaoSsRYpcN6=s96-c','USER'),(11,'bonnie0430@naver.com','서쪽의굶주린알파카8758',NULL,'http://k.kakaocdn.net/dn/dpk9l1/btqmGhA2lKL/Oz0wDuJn1YV2DIn92f6DVK/img_640x640.jpg','USER'),(12,'qoruddms96@nate.com','동쪽의귀여운무당벌레9418',NULL,'http://k.kakaocdn.net/dn/ekuSSm/btsyJvZo3Oo/yWdF2ascmXK4puok0KRke1/img_640x640.jpg','USER'),(13,'hhyeona0104@gmail.com','북쪽의아리따운성용5762',NULL,'https://lh3.googleusercontent.com/a/ACg8ocISb7d04pQaVvxGjLHWBb4x1DId7nDhqNOQodPVSkOO=s96-c','USER'),(14,'ababgusdk@daum.net','상당히달리는개구리7576',NULL,'http://k.kakaocdn.net/dn/dNQrkM/btsAorhNNMI/zaga2KQYVOuOqt2x8fBFmk/img_640x640.jpg','USER'),(15,'suhyeng119@khu.ac.kr','즐겁게못생긴정민2355',NULL,'https://lh3.googleusercontent.com/a/ACg8ocKXS9-VB5Az5vw87Z0jlzJZh_vu8zKYDB1riZpxUqlG=s96-c','USER');
/*!40000 ALTER TABLE `member` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `note`
--

DROP TABLE IF EXISTS `note`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `note` (
  `is_public` bit(1) DEFAULT NULL,
  `edit_datetime` datetime(6) DEFAULT NULL,
  `folder_id` bigint DEFAULT NULL,
  `id` bigint NOT NULL AUTO_INCREMENT,
  `post_datetime` datetime(6) DEFAULT NULL,
  `user_id` bigint NOT NULL,
  `content` text COLLATE utf8mb4_unicode_ci,
  `preview` varchar(512) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `title` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `FK7nue4plvgrof60qkymspt262k` (`user_id`),
  KEY `FK2316sprb5ket7ap1l33v4y1g2` (`folder_id`),
  CONSTRAINT `FK2316sprb5ket7ap1l33v4y1g2` FOREIGN KEY (`folder_id`) REFERENCES `folder` (`id`),
  CONSTRAINT `FK7nue4plvgrof60qkymspt262k` FOREIGN KEY (`user_id`) REFERENCES `member` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=139 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `note`
--

LOCK TABLES `note` WRITE;
/*!40000 ALTER TABLE `note` DISABLE KEYS */;
INSERT INTO `note` VALUES (_binary '','2023-11-15 04:52:45.586903',1,6,'2023-11-13 01:41:55.258987',1,'# 귀엽죠?\n![image](https://s3.orbi.kr/data/file/united2/ae89244c165f4f79b363e22bd61719a1.gif)','귀엽죠? image','겁나귀여운다꼬리 보고 가세요'),(_binary '','2023-11-14 04:38:11.702538',2,7,'2023-11-14 04:38:12.989250',2,NULL,'','임수형'),(_binary '','2023-11-13 05:22:30.078499',8,8,'2023-11-13 05:11:02.001405',3,'- 왜 슬픈 코끼리인가?\n  - 코끼리 아저씨는 코가 손이기 때문이다\n  - 그럼 진짜 손은 어디갔는가?\n    - 애덤 스미스의 보이지 않는 손을 들어봤는가? 사실 그것이 코끼리의 진짜 손이다. 이것은 19세기동안 비밀로 여겨져 왔으며 최근 전국 코끼리 연합에 의해 사실로 판명되었다.\n  - 그렇다면 왜 서쪽인가?\n    - 서쪽의 웨스트.. 그곳에 그는 홀로 서있었다. 그의 이름은 바로.... `황금왕 골드킹`\n\n``` javascript\n어둠에 Dark 에서 죽음의 Death 를 느끼며\n서쪽에서 불어오는 바람의 Wind 를 맞았다.\n\n그것은 운명의 Destiny.\n\n그는 인생의 Life 를 끝내기 위해 TheEnd .\n\n모든것을 옭아매는 폭풍같은 Storm 에서 벗어나기 위해\n결국 자신 스스로를 죽음에  Death 로 몰아갔다.\n후에 전설의 Legend 로써 기억에 Memory- 기적에 Miracle\n\n길이길이 가슴속의 Heart 에 기억될 Remember.\n\n\n-끝에 Fin-\n```\n','왜 슬픈 코끼리인가?  코끼리 아저씨는 코가 손이기 때문이다  그럼 진짜 손은 어디갔는가?   애덤 스미스의 보이지 않는 손을 들어봤는가? 사실 그것이 코끼리의 진짜 손이다. 이것은 19세기동안 비밀로 여겨져 왔으며 최근 전국 코끼리 연합에 의해 사실로 판명되었다.  그렇다면 왜 서쪽인가?   서쪽의 웨스트.. 그곳에 그는 홀로 서있었다. 그의 이름은 바로.... 황금왕 골드킹  어둠에 Dark 에서 죽음의 Death 를 느끼며 서쪽에서 불어오는 바람의 Wind 를 맞았다.  그것은 운명의 Destiny.  그는 인생의 Life 를 끝내기 위해 TheEnd .  모든것을 옭아매는 폭풍같은 Storm 에서 벗어나기 위해 결국 자신 스스로를 죽음에  Death 로 몰아갔다. 후에 전설의 Legend 로써 기억에','나는 서쪽의 슬픈 코끼리이다.'),(_binary '','2023-11-15 01:24:16.465682',11,9,'2023-11-13 06:23:21.407059',4,'\n- Docker 란?\nContainer를 생성하고 관리하기 위한 도구, Container technology 다.  핵심은 컨테이너다.\nVirtual Machines 에서 Host OS위에 각 OS를 설치하는 것과 달리, 도커 엔진위에서 컨테이너를 돌릴 수 있다.\n\n\n- Docker Engine\n- 도커 실습\n1. 해당 레포에서 도커 이미지를 빌드한다.\n`Docker build .` \n\n```\n도커 빌드 에러\n\n~/.docker/config.json 에서 \ncredsStore -> credStore로 바꾸니 잘 돌아감.\n\n{\n        \"auths\": {},\n        \"credStore\": \"desktop\",\n        \"currentContext\": \"default\"\n}\n\n\n```\n\n\n2. 이미지의 ID를 찾고, run한다.\n`docker image ls` \n`docker run -p 3000:3000 ID` 포트를 열어줘야 컨테이너와 통신 할 수 있다.\n\n```\n 도커 포트 에러 \n docker: Error response from daemon: Ports are not available: exposing port TCP 0.0.0.0:3000 -> 0.0.0.0:0: listen tcp 0.0.0.0:3000: bind: An attempt was made to access a socket in a way forbidden by its access permissions.\n \n net stop winnat으로 해결함. \n\n다음 명령어로 미리 예약을 할 수도 있다.\nnetsh int ipv4 add excludedportrange protocol=tcp startport=3000 numberofports=1 store=persistent\n\n\n```\n\n\n\n\n3. 도커 ps로 이름을 찾고 stop한다.\n`docker ps`\n```\nCONTAINER ID   IMAGE          COMMAND                   CREATED          STATUS          PORTS                    NAMES\n3e218254e45d   0bfd37f8f793   \"docker-entrypoint.s…\"   2 minutes ago    Up 2 minutes    0.0.0.0:3000->3000/tcp   dazzling_johnson\n2a7785ddb9ed   0bfd37f8f793   \"docker-entrypoint.s…\"   48 minutes ago   Up 48 minutes   3000/tcp                 jolly_darwin\n\n```\n\n\n### 데이터\n\n도커는 다음 3가지로 데이터를 구분할 수 있다.\n![[Data.png]]\n1. 코드 및 환경 데이터 : Read-only 이다. \n2. 컨테이너가 작성하는 일시적인 데이터. : Read-Write 이다.\n3. 영구 데이터. : 컨테이너가 삭제 되더라도 생존 해야함.\n\n\n\n### .dockerignore\n\ncopy 명령으로 복사해서는 안 되는 폴더 및 파일을 지정할 수 있다. ','Docker 란? Container를 생성하고 관리하기 위한 도구, Container technology 다.  핵심은 컨테이너다. Virtual Machines 에서 Host OS위에 각 OS를 설치하는 것과 달리, 도커 엔진위에서 컨테이너를 돌릴 수 있다.   Docker Engine  도커 실습   해당 레포에서 도커 이미지를 빌드한다. Docker build .  도커 빌드 에러  ~/.docker/config.json 에서  credsStore -> credStore로 바꾸니 잘 돌아감.  {         \"auths\": {},         \"credStore\": \"desktop\",         \"currentContext\": \"default\" }      이미지의 ID를 찾고, run한다. ','Docker'),(_binary '','2023-11-13 07:06:53.732811',10,10,'2023-11-13 06:45:33.304265',4,NULL,'','Pod internal'),(_binary '','2023-11-15 05:45:05.878742',11,11,'2023-11-13 06:31:28.809470',4,'호스트 머신에 매핑을 시키는 것. \n\n컨테이너를 런할때, -v 옵션에 절대경로를 넣어서 바인드 마운트를 한다. \n\n`docker run -d -p 3000:80 --rm --name feedback-app -v feedback`\n\n코드를 수정했을 때 다시 이미지를 빌드하고 컨테이너를 생성하는 대신에 바운드 마운트를 써서 컨테이너가 로컬 호스트의 디렉토리를 바라보게 한다.  \n\n이미지를 생성할 때 /app 디렉토리가 만들어지고 그곳에 npm install을 수행.  \n컨테이너를 시작하면 볼륨이나 바인드 마운트에서 파일을 찾는다. \n로컬에서 도커 컨테이너에 있는 내용을 덮어씌우기 때문에 종속성이 사라지는 것. \n\n그래서 덮어 씌워지기 싫은 파일을 익명 볼륨을 생성하고 매핑해서 로컬로부터 덮어씌워지지 않도록 해야한다. \n\n도커는 컨테이너에 설정하는 모든 볼륨을 평가하고, 충돌이 있는 경우 더 긴 내부 경로를 우선한다. \n`docker run -d -p 3000:80 -v feedback:/api/feedback -v \"<바인드할 디렉토리의 절대경로>:/app\" -v /app/node_modules feedback`\n\n다수에 컨테이너에서 접근 가능하다. \n지우려면 실제 호스트 머신에 있는 폴더를 지우면 됨. \n당연하겠지만 재사용이 가능함. \n\n\n','호스트 머신에 매핑을 시키는 것.  컨테이너를 런할때, -v 옵션에 절대경로를 넣어서 바인드 마운트를 한다.  docker run -d -p 3000:80 --rm --name feedback-app -v feedback  코드를 수정했을 때 다시 이미지를 빌드하고 컨테이너를 생성하는 대신에 바운드 마운트를 써서 컨테이너가 로컬 호스트의 디렉토리를 바라보게 한다.  이미지를 생성할 때 /app 디렉토리가 만들어지고 그곳에 npm install을 수행. 컨테이너를 시작하면 볼륨이나 바인드 마운트에서 파일을 찾는다. 로컬에서 도커 컨테이너에 있는 내용을 덮어씌우기 때문에 종속성이 사라지는 것.  그래서 덮어 씌워지기 싫은 파일을 익명 볼륨을 생성하고 매핑해서 로컬로부터 덮어씌워지지 않도록 해야한다.  도커는 컨','Bind Mounts'),(_binary '','2023-11-15 01:26:31.983961',11,13,'2023-11-13 06:32:08.103751',4,'Software에서 컨테이너란?\n\n표준화된 소프트웨어 유닛이다. \n소스 코드 패키지, 해당 코드를 실행하는데 필요한 종속성과 도구가 포함됨. \n\n같은 컨테이너는 언제나 동일한 어플리케이션과 실행 결과를 준다는 특징을 가진다.\n최신 운영체제에는 컨테이너를 보통 지원함.\n\n- 왜 컨테이너인가?\n\n왜 우리는 독립적이고, 표준화된 어플리케이션 패키지를 원하는가. \n\n1. 코드가 항상 정확한 버젼으로 동작 할 수 있다. \n2. 팀이나 회사에서의 개발 환경의 통일. 각각 팀원이 로컬 환경에서 개발 하는 것과 달리 같은 개발 환경에서 개발 하기 위함.\n소프트웨어 개발에서는 이러한 재현성을 원한다.\n\n3. 혼자서 활용 할 때에도 다양한 프로젝트간 작업할 때, 버젼의 충돌을 회피 할 수 있다.  \n\n\n컨테이너는 구성파일을 만들어 설정할 수 있다. 그리고 Image로 빌드 할 수 있다.\n\n\nVM에 비해서..\n- OS에 미치는 영향을 줄이고, 빠르고, 적게 디스크 공간을 활용할 수 있다.\n- 공유, 재구축 및 배포하는 것이 매우 쉽다. \n- 앱에 필요한 것들만 캡슐화했다. \n\n\n\n### 컨테이너\n\n컨테이너는 기본적으로 독립되어 있다. \n\n컨테이너는 이미지에 저장된 환경을 사용한다. 컨테이너는 이미지 위에 추가된 얇은 레이어이다. \n\n코드를 복사하지 않는다는게 뭐지.....?\n\n여튼 컨테이너는 이미지를 기반으로 실행된다. 이게 아키텍쳐에 \n\n## 세부 설정. \n\n\n`docker run`은 이미지를 기반으로 새로운 컨테이너를 만들고 실행시킨다. \n\n코드, 종속성 등 이미지가 바뀌지 않은 경우 새로운 컨테이너를 생성할 필요가 없다. \n\n`docker start name`으로 컨테이너를 재시작 할 수 있다. \n\n그리고 `attached` 모드와 `detached` 모드를 구분할 수 있다. \n\n`attached` 모드는 컨테이너의 출력 결과를 수신한다. \n\n`-d` 태그로 `run` 하면 `detached` 로 실행 가능하다. \n`-a` 태그로 `start` 하면 `attached` 로 실행 가능하다.\n\n그리고 `docker attach ID` 를 통해 다시 수신할 수도 있다. \n\n`docker logs ID` 를 하면 과거 로그를 볼 수 있다.\n`docker logs -f ID`를 하면 과거 로그를 보고, 수신 모드로 전환 가능하다.\n\n\n### interactive\n-t : 컨테이너를 생산하겠다. \n\n`run` 할 때, --rm 플래그를 통해 컨테이너가 멈출 때 제거할 수 있다. \n`docker run -p 3000:80 -d --rm ID`\n\n일반적으로 컨테이너가 멈출 때는 소스코드나 종속성이 변경되어서 다시 빌드하고 새로운 컨테이너를 띄워야 할 때기 때문에 컨테이너가 멈출때 지워지도록 하는게 적절한 시나리오이다.  \n\n\n### 실행중인 컨테이너와 소통\n\n`docker cp` 로 해당 컨테이너 내/외부로 파일을 송/수신 할 수 있다.\n```\n$ docker cp dummy/. recursing_mendel:/test\nSuccessfully copied 2.56kB to recursing_mendel:/test\n```\n자주 사용하진 않지만 config를 보고싶거나, logs를 읽고싶은 경우 사용한다. \n\n\n`docker run -p 3000:80 -d --rm --name suhyeng ID` 로 이름을 지정할 수 있다. \n','Software에서 컨테이너란?  표준화된 소프트웨어 유닛이다. 소스 코드 패키지, 해당 코드를 실행하는데 필요한 종속성과 도구가 포함됨.  같은 컨테이너는 언제나 동일한 어플리케이션과 실행 결과를 준다는 특징을 가진다. 최신 운영체제에는 컨테이너를 보통 지원함.    왜 컨테이너인가?  왜 우리는 독립적이고, 표준화된 어플리케이션 패키지를 원하는가.    코드가 항상 정확한 버젼으로 동작 할 수 있다.  팀이나 회사에서의 개발 환경의 통일. 각각 팀원이 로컬 환경에서 개발 하는 것과 달리 같은 개발 환경에서 개발 하기 위함. 소프트웨어 개발에서는 이러한 재현성을 원한다.   혼자서 활용 할 때에도 다양한 프로젝트간 작업할 때, 버젼의 충돌을 회피 할 수 있다.  컨테이너는 구성파일을 만들어 설정할 수 있다','Container'),(_binary '','2023-11-15 01:27:15.105418',11,14,'2023-11-13 06:38:51.185617',4,'\n- 도커 컴포즈\n`docker build` 와 `docker run` 을 대체할 수 있는 도구이다. 단순히 대체하는 것 뿐 아니라 여러개의 이미지를 빌드하고 여러개의 컨테이너를 런할 수 있다. \n\n물론, run 뿐만 아니라 stop도 가능. 다중 컨테이너 애플리케이션을 시작하거나 관리 할 수 있다.\n\n\n특징\n- 커스텀 이미지인 Dockerfile 을 대체하진 않는다. (같이 사용함.)\n- 도커 컴포즈는 이미지나 컨테이너를 대체하진 않는다. (설정 및 관리)\n- 다수의 호스트(여러 서버)에서 다중 컨테이너를 관리하는데 적합하진 않다. (이건 쿠버가 함)\n\n그럼 뭘 해줌? 포트, 볼륨, 네트워크, 환경변수 등 이전에 직접한걸 미리 설정가능\n\n### 어떻게 만드는가\n\n백엔드와 프론트 폴더와 동일한 디렉토리에 docker-compose.yaml 파일을 생성한다.\n\nyaml은 들여쓰기를 통해 구성 옵션 간의 종속성을 표현하는 특정한 텍스트 포맷이다. \n\n- 이미지가 없는 경우 docker-compose.yml 의 상대 경로로 하위 Dockerfile의 path를 알려주면 된다.\n\n- docker-compose.yml\n```\n# 들여쓰기로 직계 후손\n# 도커 컴포즈에서 -d 와 --rm 은 디폴트다\n# 도커 컴포즈는 포함된 service들을 모두 동일한 네트워크로 간주하고 관리하게 해준다.\n# 같은 컴포즈에서 동일한 볼륨을 쓰면 공유하게된다. 명명 볼륨만 적음. 익명과 바인드는 적을 필요가 없다.\n\n# 도커 컴포즈의 버젼\n# 사용가능한 구문 구분\nversion: \"3.8\"\n\n# 서비스 키\nservices:\n    mongodb:\n        image: \'mongo\'\n        volumes:\n            - data:/data/db\n        env_file:\n            - ./env/mongo.env\n      # environment:\n      #   MONGO_INITDB_ROOT_USERNAME: max\n      #   MONGO_INITDB_ROOT_PASSWORD: secre\n        # - MONGO_INITDB_ROOT_USERNAME=max 으로 표현해도 된다.\n        # networks:\n        #     - goals-net # 특정 네트워크에 추가 가능.\n\n    backend:\n        build: \"./backend\"\n        # build:\n        #     context: ./backend # context는 Dockerfile이 이미지로 복사할 경로를 포함해야 한다.\n        #     dockerfile: Dockerfile # Dockerfile이면 위에 처럼 경로만 알려줘도 되지만, 이름이 다를경우 지정가능하다.\n        #     args:\n        #         some-arg: 1\n        ports:\n            - \'80:80\'\n        volumes:\n            - logs:/app/logs # 명명 볼륨\n            - ./backend:/app # 바운드 마운트를 상대경로를 통해 지정할 수가 있다.\n            - /app/node_modules\n        env_file:\n            - ./env/backend.env\n        depends_on: # 다른 컨테이너에 영향을 받는 경우. 즉 컨테이너 실행에 순서가 있는 경우.\n            - mongodb\n            \n    frontend:\n        build: ./frontend\n        ports:\n            - \'3000:3000\'        \n        volumes:\n            - ./frontend/src:/app/src\n        stdin_open: true # 이 두 가지가 -it 옵션이다.\n        tty: true\n        depends_on:\n            - backend\n\n# 볼륨에 대한 키를 추가\nvolumes:\n  data:\n  logs:\n```\n\n이후 `docker compose up`을 하면, \n다음과 같이 기본 네트워크 및 볼륨을 생성해 준다.\n```\n[+] Running 3/3\n ✔ Network compose-01-starting-setup_default      Created 0.8s \n ✔ Volume \"compose-01-starting-setup_data\"        Created 0.0s \n ✔ Container compose-01-starting-setup-mongodb-1  Created        \n```\n\n`-d` 옵션으로 detach 실행을 해주자.\n\n`docker compose down`으로 멈출 수 있다. 다만 볼륨은 삭제되지 않는데, \n`down`에 `-v` 옵션도 넣어주면 된다.\n\n컨테이너 이름은 더 길게 할당되는데, 서비스 이름을 통해 통신이 가능하다.\n\n`docker compose up` 에 `--build` 를 추가하면 이미지 빌드를 강제할 수 있다. \n그 말인즉 이미지가 이미 있다면 재사용한다는 뜻.\n\n#### 이름\n\n컨테이너 이름은 폴더와 서비스명이 붙어서 만들어진다.\n`container_name: mongodb` 옵션으로 이름을 직접 지을 수 있다..\n\n구성하는게 편해서 컨테이너 하나만으로 잘 씀.\n\n\n\n\n','도커 컴포즈 docker build 와 docker run 을 대체할 수 있는 도구이다. 단순히 대체하는 것 뿐 아니라 여러개의 이미지를 빌드하고 여러개의 컨테이너를 런할 수 있다.  물론, run 뿐만 아니라 stop도 가능. 다중 컨테이너 애플리케이션을 시작하거나 관리 할 수 있다.  특징 - 커스텀 이미지인 Dockerfile 을 대체하진 않는다. (같이 사용함.) - 도커 컴포즈는 이미지나 컨테이너를 대체하진 않는다. (설정 및 관리) - 다수의 호스트(여러 서버)에서 다중 컨테이너를 관리하는데 적합하진 않다. (이건 쿠버가 함)  그럼 뭘 해줌? 포트, 볼륨, 네트워크, 환경변수 등 이전에 직접한걸 미리 설정가능  어떻게 만드는가 백엔드와 프론트 폴더와 동일한 디렉토리에 docker-compose.','Docker Compose'),(_binary '','2023-11-15 01:28:01.689837',11,15,'2023-11-13 06:38:48.774535',4,'\nDissolver의 개념.. \n이미지는 템플릿, 컨테이너의 청사진이다. 모든 코드와 환경에 대한 변수를 저장하는 일종의 패키지로 보면된다. \nContainer는 실제 App이 돌아가는 인스턴스이다(run을 통해서 생성됨). 즉 이미지를 정의하면 여러 복수의 컨테이너를 다른 서버에서 실행시킬 수 있다. \n\npre-built 된 이미지를 가져오거나 생성해서 사용하면 된다. \n[[Docker Hub]]에 많음. \n\n## 이미지 실행 해보기\n\n1. 허브에서 다운로드. \n`docker run node` 하면 다운된다. \n\n도커 내부에서 인터렉티브 쉘이 돌아가고있다. 그런데 도커는 독립적으로 작동하기 때문에 노출되진 않았음. \n\n-  it 플래그\n`docker run -it node` -it 플래그는 interactice의 줄임말이다.  도커 컨테이너 내부로부터 호스팅 머신으로 대화형 세션을 노출하게 된다. \n\n\n```\n깃 배쉬로 할 시 에러가 나는 이슈.\n$ docker run -it node\nthe input device is not a TTY.  If you are using mintty, try prefixing the command with \'winpty\'\n\n# winpty를 붙여야 함. \n\n$ winpty docker run -it node\nWelcome to Node.js v21.0.0.\nType \".help\" for more information.\n> 1 + 1\n2\n>\n\n```\n\n2. 도커 파일로 직접 이미지 만들어보기.\n\n`DockerFile` 은 도커 데몬에 의해 관리된다. \n\n`FROM`은 베이스 이미지에 본인의 이미지를 구축할 수 있다. 도커 허브 상이나 로컬에 있는 이미지를 넣는다.\n처음 도커허브에서 실행해보면 캐시되어서 로컬에도 존재하게된다. \n\n`WORKDIR /app` 컨테이너 내부에서 명령어가 실행될 위치를 지정할 수 있다.\n\n`COPY . ./` \n첫 번째 경로는 컨테이너의 외부, 이미지의 외부 경로로 이미지로 복사되어야 할 파일들이 있는 곳. \n예시에서는 Dockerfile이 존재하는 디렉토리로 볼 수 있다. \n두 번째 경로는 데이터가 복사되는 컨테이너 내부의 경로이다.  `./`는 작업 디렉토리를 의미함. \n\n`RUN npm install` 로 복사한 후 종속성을 유지하면 된다. \n\n`EXPOSE` 를 통해 컨테이너를 특정 포트로 노출 시켜야 통신이 가능하다.\n\n`CMD` 는 이미지가 생성될 때 실행되지 않고, 이미지를 기반으로 컨테이너가 생성될 때 실행된다. 이미지는 청사진이기 때문에 빌드될 때 굳이 서버를 실행할 이유가 없다. \n```\nFROM node\n\nWORKDIR /app  \n\nCOPY . ./\n\nRUN npm install\n\nEXPOSE 80\n\nCMD [\"node\", \"server.js\"]\n```\n\n\n하지만 그냥 런하면 호스트 머신의 포트어느 포트가 해당 도커포트와 연결되는지 알 수가 없으므로 run 할 때, 포트를 지정해줘야한다. \n\n`$ docker run -p 3000:80 84d1016c860a`\n\n\n그리고 코드를 수정 후 적용을 하려면, 해당 코드를 다시 이미지로 빌드하고 컨테이너를 생성해 줘야 반영이 된다 .\n\n\n## Layer 기반 아키텍쳐\n\n이미지를 빌드 할 때, 변경된 부분과 이후의 모든 명령이 재평가 된다. \nuging cache.\n\n도커는 기본적으로 모든 명령어에 대해 캐쉬한다. 다시 빌드할 필요가 없으면 캐시된 결과를 사용한다. \n\n이미지는 다시 빌드하지 않는 이상 Read-only다. \nCMD 전까지는 별개의 레이어이다. \n\n소스 코드를 수정하면, 모든 파일의 COPY를 다시해야 한다. 그리고 후속 레이어도 다시 빌드를 하게 된다. \n\n그래서 소스 코드가 바뀌어도  굳이\n`RUN npm install`를 다시 하게된다. 이를 최적화 할 수 있는데, \n\n```\nFROM node\n\nWORKDIR /app\n\nCOPY . /app\n\nRUN npm install\n\nEXPOSE 80\n\nCMD [\"node\", \"server.js\"]\n```\n위 상황에서, npm install에 필요한 package.json만 Copy 한 후 npm install을 먼저 해도 된다. 이렇게 하면 오래 걸리는 npm install이 변경이 일어난 COPY . /app 부분 후속 레이어로 오지 않게 되므로 시간을 단축 시킬 수 있다.\n```\nFROM node\n\nWORKDIR /app\n\nCOPY package.json /app\n\nRUN npm install\n\nCOPY . /app\n\nEXPOSE 80\n\nCMD [\"node\", \"server.js\"]\n```\n\n\n```\n[+] Building 0.9s (10/10) FINISHED                                           docker:default\n => [internal] load build definition from Dockerfile                                   0.0s\n => => transferring dockerfile: 152B                                                   0.0s \n => [internal] load .dockerignore                                                      0.0s \n => => transferring context: 2B                                                        0.0s \n => [internal] load metadata for docker.io/library/node:latest                         0.8s \n => [1/5] FROM docker.io/library/node@sha256:bf718fc580177cd927173c8617cf7f527a1b7f62  0.0s\n => [internal] load build context                                                      0.0s \n => => transferring context: 1.14kB                                                    0.0s \n => CACHED [2/5] WORKDIR /app                                                          0.0s \n => CACHED [3/5] COPY package.json /app                                                0.0s \n => CACHED [4/5] RUN npm install                                                       0.0s \n => [5/5] COPY . /app                                                                  0.0s \n => exporting to image                                                                 0.0s \n => => exporting layers                                                                0.0s \n => => writing image sha256:f1bbbd303ca2a880f6fd9bd4dc4cc0db21b2d15879a9fb9b290a93397  0.0s\n```\n\n컨테이너는 이미지 위에 얇게 추가된 레이어이다. \n\n\n## 이미지 분석 및 관리\n\n`docker images` 를 통해 image 리스트를 볼 수 있다 .\n\n```\n$ docker images\nREPOSITORY   TAG       IMAGE ID       CREATED          SIZE\n<none>       <none>    570ff0d02af0   29 minutes ago   1.02GB\n<none>       <none>    e4ea10d8dc9c   30 minutes ago   1.02GB\n<none>       <none>    f1bbbd303ca2   2 hours ago      1.11GB\n<none>       <none>    26780a9f1f65   2 hours ago      1.11GB\n<none>       <none>    b05633d8e512   2 hours ago      1.11GB\n<none>       <none>    d62f7d0b3cd2   3 hours ago      1.11GB\n```\n\n노드 뿐만아니라 리눅스 운영체제까지 포함된 사이즈이다.\n\n컨테이너는 `docker rm`  이미지는 `docker rmi` 로 지울 수 있다. \n해당 이미지를 기반으로하는 컨테이너가 모두 중지되어야만 지울 수 있다. \n\n`docker image prune` 을 통해서 사용되지 않는 이미지를 모두 지울 수 있다. \n\n`docker image inspect ID` 를 하면 이미지에 대한 정보를 볼 수 있다.\n\n\n\n### 이미지에 이름 과 태그를 지정하기\n\n`node` 와 같이 이미지에 이름을 특정할 수 있다.\n그리고 tag를 통해 이름 그룹내에서 이미지의 특정 버젼을 지칭 할 수 있다. \n\n`docker build -t name:tags .` 를 통해서 name과 tag를 지정할 수 있다. \n\n\n### 이미지 공유\n\n1. Dockerfile 공유\ndocker build 를 해야됨. \n코드 및 종속성이 필요함.\n\n2. 빌드된 이미지 공유\n빌드 했기 때문에 이미지만 있으면 컨테이너를 띄울 수 있다. \n\n','Dissolver의 개념.. 이미지는 템플릿, 컨테이너의 청사진이다. 모든 코드와 환경에 대한 변수를 저장하는 일종의 패키지로 보면된다. Container는 실제 App이 돌아가는 인스턴스이다(run을 통해서 생성됨). 즉 이미지를 정의하면 여러 복수의 컨테이너를 다른 서버에서 실행시킬 수 있다.  pre-built 된 이미지를 가져오거나 생성해서 사용하면 된다. Docker Hub에 많음.  이미지 실행 해보기   허브에서 다운로드. docker run node 하면 다운된다.  도커 내부에서 인터렉티브 쉘이 돌아가고있다. 그런데 도커는 독립적으로 작동하기 때문에 노출되진 않았음.    it 플래그 docker run -it node -it 플래그는 interactice의 줄임말이다.  도커 컨테이너 내부','Image'),(_binary '','2023-11-13 06:39:16.072056',11,16,'2023-11-13 06:39:18.134023',4,NULL,'','Layer Architecture'),(_binary '','2023-11-13 06:40:13.581514',11,18,'2023-11-13 06:39:41.845190',4,NULL,'','Multi Container with 3 Layer Architecture'),(_binary '','2023-11-15 01:29:15.209226',11,19,'2023-11-13 06:40:16.411564',4,'\n\n- VM이란\n\nSW동작에 모든 것이 보유된 캡슐화된 환경이다.\nHost OS위에 VM을 설치. VM이 OS를 포함하기 때문에 OS를 또 설치하는 격.\n\n가상 운영체제를 쓰는 여러 VM 운용시 Overhead가 크다는 것이 가장 큰 문제이다.\n매번 새로운 리소스를 설치해야 된다. \n\n\n- 장점 : 분리된 환경 제공, 환경별 구성을 제공. 안정적 공유와 재생산\n- 단점 : 중복에 의한 공간 낭비, 호스트 시스템위에 추가 시스템이 실행되고 있기 때문에 성능이 저하됨,  모든 시스템에 VM을 설정해야됨. -> 배포할 때도 설정을 또 해야된다. ','VM이란  SW동작에 모든 것이 보유된 캡슐화된 환경이다. Host OS위에 VM을 설치. VM이 OS를 포함하기 때문에 OS를 또 설치하는 격.  가상 운영체제를 쓰는 여러 VM 운용시 Overhead가 크다는 것이 가장 큰 문제이다. 매번 새로운 리소스를 설치해야 된다.    장점 : 분리된 환경 제공, 환경별 구성을 제공. 안정적 공유와 재생산  단점 : 중복에 의한 공간 낭비, 호스트 시스템위에 추가 시스템이 실행되고 있기 때문에 성능이 저하됨,  모든 시스템에 VM을 설정해야됨. -> 배포할 때도 설정을 또 해야된다.','Virtual Machines'),(_binary '','2023-11-15 01:29:35.280824',11,20,'2023-11-13 06:40:32.813477',4,'도커 컨테이너는 삭제되면, 안에 read-write 하던 임시 데이터 들이 지워진다. 영구 저장을 가능하게 하는 볼륨에 대해 알아보자.\n\n볼륨은 컨테이너가 마운트 되어있는 호스트 머신의 폴더이다. 즉 컨테이너나 이미지에 있는 것이 아니다.\n\n\n- 폴더와 폴더를 매핑해두는 개념. 즉 서로 접근이 가능하다...!\n\n`VOLUME [ \"/app/feedback\" ]` 을 추가하여 볼륨을 설정해주자.\n\n도커를 실행시키고 api를 호출하면... 안된다. \n\n```\ndocker logs fdv\n\n...\ncross-device link not permitted, rename \'/app/temp/2f.txt\' -> \'/app/feedback/2f.txt\'\n...\n\n```\n\n도커는 실제로 컨테이너 파일을 파일 시스템 내부의 다른 폴더로 옮기지 않는다....\n기존의 `rename` 을 `copyFile` 과 `unlink` 로 바꾸어 주자.\n즉 옮기기 대신 복사 후 삭제를 하는 것!\n\n\n## Anonymous/Named Volume & Bind Mounts\n\n- 익명 볼륨\n\n컨테이너 실행시 명명하지 않으면 컨테이너가 삭제될 때 볼륨도 삭제된다. \n컨테이너에 이미 존재하는 특정 데이터를 잠그는데 유용하다. \n\n\n- 명명 볼륨\n\n컨테이너 삭제시에도 사라지지않고 영구 보관이 가능하다. 하지만 도커가 관리하기 때문에 로컬에서 접근 할 수가 없다. \n\n다른 컴퓨터에도 해당 명명한 이름으로 바인딩이 가능하다.\n다음은 `feedback`이라고 볼륨명을 정해서 컨테이너를 런하는 코드. \n\n```\ndocker run -d -p 3000:80 --rm --name feedback-app -v feedback:/app/feedback feedback-node:volumes\n```\n\n볼륨에는 익명 볼륨이 있다. \n\n다양한 컨테이너가 공유할 수 있다. \n\n\n- [[Bind Mounts]]\n\n### Read Only Volume\n\n사실  바인드 마운트를 했을 때, 컨테이너가 app 폴더에 쓸 수 있게 하는 것이 아니라. 로컬 파일을 변경할 수 없어야한다. \n\n컨테이너에서 실행 중인 애플리케이션은 본인 스스로를 변경해서는 안된다.\n\n볼륨의 디폴트 권한은 read-write다. \n\n컨테이너를 런할 때, :ro 를 붙여서 권한도 같이 설정할 수 있다. \n물론 write가 가능한 폴더를 빼두어야한다. \n\n구체적인 하위 볼륨설정이 우선되기 때문에 예외처리가 가능하다. \n\n### 볼륨 관리\n\n`docker volume ls`를 통해 볼륨 목록을 볼 수 있다.\n바인트 마운트는 볼 수 없는데, 도커에 의해서 관리되는 볼륨이 아니기 때문.\n\n`docker volume create`를 통해서 볼륨 생성도 가능.\n\n`docker volume inspect name`으로 검사도 가능하다. 여기서 볼륨의 위치를 볼 수 있는데, 컨테이너의 os상의 위치이므로 호스트에서 접근 할 수 없다. \n\n\n','도커 컨테이너는 삭제되면, 안에 read-write 하던 임시 데이터 들이 지워진다. 영구 저장을 가능하게 하는 볼륨에 대해 알아보자.  볼륨은 컨테이너가 마운트 되어있는 호스트 머신의 폴더이다. 즉 컨테이너나 이미지에 있는 것이 아니다.    폴더와 폴더를 매핑해두는 개념. 즉 서로 접근이 가능하다...!  VOLUME [ \"/app/feedback\" ] 을 추가하여 볼륨을 설정해주자.  도커를 실행시키고 api를 호출하면... 안된다.  docker logs fdv  ... cross-device link not permitted, rename \'/app/temp/2f.txt\' -> \'/app/feedback/2f.txt\' ...   도커는 실제로 컨테이너 파일을 파일 시스템 내부의 다른 폴더로 옮기지 ','Volume'),(_binary '','2023-11-15 01:30:07.297210',12,21,'2023-11-13 06:40:54.150167',4,'\n### env\n\n도커는 빌드 타임 인수와 런타임 환경 변수를 지원한다. \n\n\n`ENV PORT 80`\n`EXPOSE $PORT`\n\n`-env PORT=8000` 옵션으로 컨테이너 런할때 설정 가능하다. \n\n`-e` 로 함축 가능\n\n또는 `.env` 파일에 설정해 두고 `--env-file ./.env` 로 호출 해서 사용해도 된다. \n\n\n### arg\n\n`ARG DEFAULT_PORT=80` 를 정의하고 환경변수의 디폴트 값을 넣을 수 있다.\n\n`ENV PORT $DEFAULT_PORT` \n\n그리고 이미지 빌드시 `--build-arg DEFAULT_PORT=8000` 옵션을 둘 수 있다.\n\n이미지가 빌드되고 나면 ARG값은 잠긴다.\n','env 도커는 빌드 타임 인수와 런타임 환경 변수를 지원한다.  ENV PORT 80 EXPOSE $PORT  -env PORT=8000 옵션으로 컨테이너 런할때 설정 가능하다.  -e 로 함축 가능  또는 .env 파일에 설정해 두고 --env-file ./.env 로 호출 해서 사용해도 된다.  arg ARG DEFAULT_PORT=80 를 정의하고 환경변수의 디폴트 값을 넣을 수 있다.  ENV PORT $DEFAULT_PORT  그리고 이미지 빌드시 --build-arg DEFAULT_PORT=8000 옵션을 둘 수 있다.  이미지가 빌드되고 나면 ARG값은 잠긴다.','Arguments & Environment'),(_binary '','2023-11-13 06:58:01.999077',12,22,'2023-11-13 06:41:15.847789',4,NULL,'','Cluster'),(_binary '','2023-11-15 01:30:44.169131',12,23,'2023-11-13 06:41:26.423491',4,'\n컨테이너간 통신\n\n컨테이너 안에서 외부 api 혹은 다른 app과 통신하려면 어떻게 해야할까. \n그리고 다른 컨테이너 간 통신은 어떻게 할까.\n\n즉 다중 컨테이너로 작업하는 것은 빈번하다. \n\n\n## 영화 api 예제\n\n4개의 엔드 포인트고, post 요청에 mongo DB가 엮여있다. 돌려보면, \n\n```\n$ docker logs favorites\n(node:1) [MONGODB DRIVER] Warning: Current Server Discovery and Monitoring engine is deprecated, and will be removed in a future version. To use the new Server Discover and Monitoring engine, pass option { useUnifiedTopology: true } to the MongoClient constructor.\n(Use `node --trace-warnings ...` to show where the warning was created)\nMongoNetworkError: failed to connect to server [localhost:27017] on first connect [Error: connect ECONNREFUSED 127.0.0.1:27017\n    at TCPConnectWrap.afterConnect [as oncomplete] (node:net:1595:16) {\n  name: \'MongoNetworkError\'\n}]\n    at Pool.<anonymous> (/app/node_modules/mongodb/lib/core/topologies/server.js:441:11)\n    at Pool.emit (node:events:515:28)\n    at /app/node_modules/mongodb/lib/core/connection/pool.js:564:14\n    at /app/node_modules/mongodb/lib/core/connection/pool.js:1000:11\n    at /app/node_modules/mongodb/lib/core/connection/connect.js:32:7\n    at callback (/app/node_modules/mongodb/lib/core/connection/connect.js:300:5)\n    at Socket.<anonymous> (/app/node_modules/mongodb/lib/core/connection/connect.js:330:7)\n    at Object.onceWrapper (node:events:630:26)\n    at Socket.emit (node:events:515:28)\n    at emitErrorNT (node:internal/streams/destroy:151:8)\n    at emitErrorCloseNT (node:internal/streams/destroy:116:3)\n    at process.processTicksAndRejections (node:internal/process/task_queues:82:21)\n\n```\n\n몽고 db 부분을 지우고 하면 잘 돌아간다. \n\n### 로컬의 몽고 DB와  연결\n\n호스트의 `localhost`은 컨테이너에서  `host.docker.internal` 로 접근 가능하다. \n\n### 컨테이너 몽고 DB와 연결\n\n몽고DB의 경우 도커 허브에 이미 있기 때문에 \n`docker run mongo` 를 하면 된다. \n\n1. IPAdress\n그리고 나서 해당 컨테이너를 보기 위해 inspect를 하면, NetworkSettings에 IPAdress를 볼 수 있다.\n```\n$ docker container inspect mongodb\n[\n    ...\n        \"NetworkSettings\": {\n            \"Bridge\": \"\",\n            \"SandboxID\": \"6097412bde10c4a91e27b105864959415b246f1c3a72adef5cdc506cce72c57b\",\n            \"HairpinMode\": false,\n            \"LinkLocalIPv6Address\": \"\",\n            \"LinkLocalIPv6PrefixLen\": 0,\n            \"Ports\": {\n                \"27017/tcp\": null\n            },\n            \"SandboxKey\": \"/var/run/docker/netns/6097412bde10\",\n            \"SecondaryIPAddresses\": null,\n            \"SecondaryIPv6Addresses\": null,\n            \"EndpointID\": \"ea267ec2353225d4db27c50d7bc08e8a9b230fb80e054298bde6c1c33f4e79f8\",\n            \"Gateway\": \"172.17.0.1\",\n            \"GlobalIPv6Address\": \"\",\n            \"GlobalIPv6PrefixLen\": 0,\n            \"IPAddress\": \"172.17.0.2\",\n            \"IPPrefixLen\": 16,\n            \"IPv6Gateway\": \"\",\n            \"MacAddress\": \"02:42:ac:11:00:02\",\n            \"Networks\": {\n                \"bridge\": {\n                    \"IPAMConfig\": null,\n                    \"Links\": null,\n                    \"Aliases\": null,\n                    \"NetworkID\": \"7c31ab53329fcd6ea0d597abd3e33f7ca4de8d132682f76cd3b2439fd0aaff0b\",\n                    \"EndpointID\": \"ea267ec2353225d4db27c50d7bc08e8a9b230fb80e054298bde6c1c33f4e79f8\",\n                    \"Gateway\": \"172.17.0.1\",\n                    \"IPAddress\": \"172.17.0.2\",\n                    \"IPPrefixLen\": 16,\n                    \"IPv6Gateway\": \"\",\n                    \"GlobalIPv6Address\": \"\",\n                    \"GlobalIPv6PrefixLen\": 0,\n                    \"MacAddress\": \"02:42:ac:11:00:02\",\n                    \"DriverOpts\": null\n                }\n            }\n        }\n    }\n]\n\n```\n\n해당 값을 node App에서 몽고 커넥트 부분에 넣으면 통신이 된다. \n\n하지만, 주소가 변경 될 때마다 하드 코딩 해 놔야하는 단점이 있다. \n\n2. Container Network\n\n컨테이너간 통신을 위해 같은 네트워크로 구성할 수 있다.\n`--network`\n\n단, 먼저 네트워크를 만들어 줘야한다.\n`docker network create favorites-net`\n\n다음과 같이 확인 가능.\n`docker network ls` \n\n다음 구성한 네트워크에 도커런을 해주자\n`docker run -d --name mongodb --network favorites-net mongo`\n\n```\n그리고 몽고DB는 다른 도커 컨테이너속 APP만 접근 하기 때문에 포트 연결을 안해줘도 된다.   \n```\n\n네트워크가 같은 경우 컨테이너 이름으로 연결할 수 있다.\n`\'mongodb://mongodb:27017/swfavorites\',`\n\n\n\n','컨테이너간 통신  컨테이너 안에서 외부 api 혹은 다른 app과 통신하려면 어떻게 해야할까. 그리고 다른 컨테이너 간 통신은 어떻게 할까.  즉 다중 컨테이너로 작업하는 것은 빈번하다.  영화 api 예제 4개의 엔드 포인트고, post 요청에 mongo DB가 엮여있다. 돌려보면,  $ docker logs favorites (node:1) [MONGODB DRIVER] Warning: Current Server Discovery and Monitoring engine is deprecated, and will be removed in a future version. To use the new Server Discover and Monitoring engine, pass option { useUnifie','Networking'),(_binary '','2023-11-13 06:58:18.922736',12,24,'2023-11-13 06:41:52.704189',4,'a','a','Contorl Plane'),(_binary '','2023-11-13 06:58:09.257043',12,25,'2023-11-13 06:41:54.856270',4,NULL,'','Deployment Object'),(_binary '','2023-11-13 06:53:18.678485',12,26,'2023-11-13 06:42:08.910474',4,'a','a','Docker Hub'),(_binary '','2023-11-13 06:58:44.120560',12,27,'2023-11-13 06:42:18.826970',4,'a','a','etcd'),(_binary '','2023-11-13 06:56:43.162116',12,28,'2023-11-13 06:42:30.073094',4,'e','e','Kafka'),(_binary '','2023-11-13 07:00:04.924423',12,29,'2023-11-13 06:42:37.821788',4,'a','a','kube-proxy'),(_binary '','2023-11-13 06:58:54.663882',12,30,'2023-11-13 06:42:54.268011',4,'a','a','kube-apiserver'),(_binary '','2023-11-13 06:59:03.641972',12,31,'2023-11-13 06:43:03.875333',4,NULL,'','kube-controller-manager'),(_binary '','2023-11-13 06:59:18.289107',12,32,'2023-11-13 06:43:21.125159',4,'a','a','kube-scheduler'),(_binary '','2023-11-13 06:59:28.002712',12,33,'2023-11-13 06:43:34.582614',4,'a','a','kubectl'),(_binary '','2023-11-13 07:00:16.559247',12,34,'2023-11-13 06:43:43.820971',4,'a','a','kubelet'),(_binary '','2023-11-13 06:57:51.176301',12,35,'2023-11-13 06:44:02.525585',4,NULL,'','Node'),(_binary '','2023-11-13 06:59:39.798128',12,36,'2023-11-13 06:44:11.161235',4,NULL,'','Node Component'),(_binary '','2023-11-13 06:56:56.112849',12,37,'2023-11-13 06:44:24.777241',4,'a','a','Operator Pattern'),(_binary '','2023-11-15 01:31:14.482774',12,38,'2023-11-13 06:44:35.900138',4,'kubectl get pods를 통해 상태를 알 수 있다. \n\nerror가 나도 자동으로 재시작 된다. \n\n\n### Replica\n\npod의 복제본 수이다. \n\n```\nSSAFY@DESKTOP-BLHP263 MINGW64 ~/git_dog/Docker_practice/kub-action-01-starting-setup\n$ kubectl scale deployment/first-app --replicas=3\ndeployment.apps/first-app scaled\n\n$ kubectl get pods\nNAME                         READY   STATUS    RESTARTS        AGE\nfirst-app-6c94c7fbb5-7spfq   1/1     Running   0               16s\nfirst-app-6c94c7fbb5-bjj5t   1/1     Running   0               16s\nfirst-app-6c94c7fbb5-qbbh8   1/1     Running   2 (3m46s ago)   103m\n\n```\n\n`--replicas=1` 로 하면 나머지 2개는 멈추고, 곧 사라진다. \n\n\n\n','kubectl get pods를 통해 상태를 알 수 있다.  error가 나도 자동으로 재시작 된다.  Replica pod의 복제본 수이다.  SSAFY@DESKTOP-BLHP263 MINGW64 ~/git_dog/Docker_practice/kub-action-01-starting-setup $ kubectl scale deployment/first-app --replicas=3 deployment.apps/first-app scaled  $ kubectl get pods NAME                         READY   STATUS    RESTARTS        AGE first-app-6c94c7fbb5-7spfq   1/1     Running   0               1','Pod'),(_binary '','2023-11-15 01:31:36.864751',12,39,'2023-11-13 06:44:43.039473',4,'\n서비스는 pod의 논리적 집합이며, 어떻게 접근할지에 대한 정책을 정의해 둔 것이다.\n\n\npod 의 ip는 자주 바뀜. 클러스터 외부에서 pod에 접근 가능하게 해준다. \n\n\n\n`kubectl create service`로 생성이 가능하지만 `kubectl expose`라는 명령어로 구성이 가능하다.\n\nservice를 생성하여, deployment에 의해 생성된 pod를 노출한다.\n\n`$ kubectl expose deployment first-app --type=NodePort --port=8080`\n\nNodePort는 워커노드가 할당 받은 IP를 의미함.\n\n`$ kubectl expose deployment first-app --type=LoadBalancer --port=8080`\n\nLoadBalancer는 서비스에 대한 고유한 주소를 생성한다.  또한 service의 일부인 pod에 트래픽을 고르게 분산해준다. \n\n```\nSSAFY@DESKTOP-BLHP263 MINGW64 ~/git_dog/Docker_practice/kub-action-01-starting-setup\n$ kubectl expose deployment first-app --type=LoadBalancer --port=8080\nservice/first-app exposed\n\nSSAFY@DESKTOP-BLHP263 MINGW64 ~/git_dog/Docker_practice/kub-action-01-starting-setup\n$ kubectl get services\nNAME         TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE\nfirst-app    LoadBalancer   10.108.222.187   <pending>     8080:30968/TCP   12s\nkubernetes   ClusterIP      10.96.0.1        <none>        443/TCP          123m\n```\n\n```\nminikube service first-app\n\n|-----------|-----------|-------------|---------------------------|\n| NAMESPACE |   NAME    | TARGET PORT |            URL            |\n|-----------|-----------|-------------|---------------------------|\n| default   | first-app |        8080 | http://192.168.49.2:30968 |\n|-----------|-----------|-------------|---------------------------|\n🏃  first-app 서비스의 터널을 시작하는 중\n|-----------|-----------|-------------|------------------------|\n| NAMESPACE |   NAME    | TARGET PORT |          URL           |\n|-----------|-----------|-------------|------------------------|\n| default   | first-app |             | http://127.0.0.1:49681 |\n|-----------|-----------|-------------|------------------------|\n🎉  Opening service default/first-app in default browser...\n❗  Because you are using a Docker driver on windows, the terminal needs to be open to run it.\n```\n\n\n\n#### Selector\n셀렉터는 이 리소스에게 제어되거나, 연결되어야 하는 다른 리소스를 식별한다. \n\n셀렉터를 사용하면, name이 아닌 metadata에 정의된 레이블로만 선택이 가능하다.\n\n\n```\n# 쿠버네티스 구성요소기 때문에 apiVerison이 필요함\napiVersion: v1 # service 는 deployment와 조금 다르다.\nkind: Service\nmetadata:\n  name: backend\n  labels:\n    group: example\nspec:\n  selector:\n    app: second-app # app:second-app 레이블을 가진 모든 pod는 Service에 의해 제어된다.\n  ports:\n    - protocol: \'TCP\'\n      port: 80\n      targetPort: 8080\n  type: LoadBalancer # NodePort ClusterIP\n```','서비스는 pod의 논리적 집합이며, 어떻게 접근할지에 대한 정책을 정의해 둔 것이다.  pod 의 ip는 자주 바뀜. 클러스터 외부에서 pod에 접근 가능하게 해준다.  kubectl create service로 생성이 가능하지만 kubectl expose라는 명령어로 구성이 가능하다.  service를 생성하여, deployment에 의해 생성된 pod를 노출한다.  $ kubectl expose deployment first-app --type=NodePort --port=8080  NodePort는 워커노드가 할당 받은 IP를 의미함.  $ kubectl expose deployment first-app --type=LoadBalancer --port=8080  LoadBalancer는 서비스에 대한 ','Service'),(_binary '','2023-11-15 01:32:13.546208',12,40,'2023-11-13 06:44:52.489751',4,'\n\nState는 App에 의해서 사용되지만, 잃으면 안되는 데이터다.\n\nUser가 만들어 내는 데이터 - DB, FS에 저장. \napp이 만들어 내는 데이터 - memory, tmp에 저장. \n\n둘 다 잃으면 안되기 때문에 volume을 사용한다.  \n\n쿠버네티스로 오면서 볼륨은 매우 다양하고, 많아진다.  \npod에 속하게 되어 관리대상이 된다. \n\npod에 속하긴 때문에 볼륨의 수명은 pod의 수명에 의존하게 된다. \n\n\n### 쿠버의 볼륨\n\n쿠버의 볼륨은 다양한 드라이버와 유형이 있다. 도커의 볼륨은 호스트머신 어딘가에 생성되는 폴더 정도로 볼 수 있지만, 쿠버에선 다르다. \n\n파드 안에 컨테이너와 볼륨이 있다. 컨테이너와 별개로, 파드에 종속되며, 컨테이너에서 해당 볼륨을 쓰기위해서 마운트를 해줘야한다. \n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: story-deployment\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: story\n  template:\n    metadata:\n      labels:\n        app: story\n    spec:\n      containers:\n        - name: story\n          image: suhyeng/kub-data-demo:1\n          volumeMounts: # 컨테이너 내부에서 파드에 있는 볼륨을 쓰기위해 마운트\n          - mountPath: /app/story # 컨테이너 내부 경로\n            name: story-volume # 볼륨을 마운트\n      volumes:\n        - name: story-volume\n          emptyDir: {}  # 파드에 종속, 컨테이너가 재시작 되도 살아있다. 드라이버\n                        # 도커 컴포즈에서 정의한 stories라는 명명 볼륨의 타입을 명시해준다.\n```\n\n\n### hostpath\n\n노드를 기준으로 패스를 지정할 수가 있다.  물론 여러 호스트 환경에서 공유할 수는 없으나, emptyDir보다는 용이하다. \n\n호스트 패스를 통해 노드의 파일, 폴더를 공유할 수 있다.  바인드 마운트와 유사하다. \n\n\n파드 안 템플릿의 스펙.\n```\nspec:\n      containers:\n        - name: story\n          image: suhyeng/kub-data-demo:1\n          volumeMounts: # 컨테이너 내부에서 파드에 있는 볼륨을 쓰기위해 마운트\n          - mountPath: /app/story # 컨테이너 내부 경로\n            name: story-volume # 볼륨을 마운트\n      volumes:\n        - name: story-volume\n          hostPath:\n            path: /data  # 호스트 머신의 경로, 바인드 마운트와 유사하다.\n            type: DirectoryOrCreate # 존재하면 바인드하고, 아니면 폴더를 생성한다\n```\n\n이것도 좋지만 여전히 노드에 종속되어서 클러스터 환경에서 사용하기엔 용이하지 않다.\n\n뭐. 노드 별로 독립시키고 싶다면 이렇게 해도 된다.\n\n## CSI Volume\n\nContainer Storage Interface\n\n파일시스템도 프로바이더에 따라 종류가 다양할 수 있다. 모든 종류에 대해 볼륨의 타입을 정의 놓을 수는 없기 때문에, 인터페이스를 정의해 두었다. \n\n\n## Persistent Volumes \n\n파드에 노드에 독립적인 볼륨을 보자.  \n\n독립 스토리지 그 이상의 개념이다. \n핵심은 볼륨이 파드에서 분리되는 것인데,  파드의 수명주기와 무관해지는 것.\n\ndeployment 와 파드에서 계속 정의할 필요 없이, 한 번 만들어 놓고 갖다가 쓰면 된다. \n\n\n영구 볼륨을 사용하기 위해서는 pv claim을 노드 안에 파드옆에 붙여서 써야한다. 이렇게 하면 파드안에 컨테이너가 해당 볼륨을 쓸 수 있는지 claim을 걸 수가 있다.\n\n```\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: host-pv\nspec:\n  capacity:\n    storage: 1Gi\n  volumeMode: Filesystem  # 파일시스템과 블록이 있다.\n  accessModes:\n    - ReadWriteOnce     # 볼륨이 단일 노드에 의해 읽기/쓰기 볼륨으로 마운트\n    # - ReadOnlyMany      # 읽기 전용이지만 여러 노드에서 요청가능.\n    # - ReadWriteMany     #\n  hostPath:\n    path: /data\n    type: DirectoryOrCreate\n```\n\n볼륨을 만들고 그에 맞는 클래임을 만들 수 있는데, 재밌는건 클레임을 만들고 클레임이 나 어떤 볼륨 줘 라고 하는 동적 볼륨 프로비저닝 이라는 토픽이 있다. \n\n근데 그건 너무 고급 관리라 잘 안 씀. 그냥 정적 볼륨 프로비저닝 쓰자. \n\n그리고 엑세스모드도 설정이 가능한데, 특정 파드에 대해 리드만 할지 쓰기까지 할지 설정이 가능하다. \n\n그리고 리소스를 적어서 뭘 얻고싶은지 명시하게 한다.\n\n```\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: host-pvc\nspec:\n  volumeName: host-pv\n  accessMode:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 1Gi\n```\n\n그리고 볼륨의 타입을 설정하다.\n\n```\nvolumes:\n        - name: story-volume\n          persistentVolumeClaim:\n            claimName: host-pvc\n```\n\n### Storage class\n\n쿠버에서 볼륨을 어떻게 관리할지 설정을 해주는 놈인데, 영구 볼륨은 등록을 해줘야한다. \n\n\n\n```\n$ kubectl get pv\nNAME      CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM\n    STORAGECLASS   REASON   AGE\nhost-pv   1Gi        RWO            Retain           Bound    default/host-pvc   standard                73s\n\n```','State는 App에 의해서 사용되지만, 잃으면 안되는 데이터다.  User가 만들어 내는 데이터 - DB, FS에 저장. app이 만들어 내는 데이터 - memory, tmp에 저장.  둘 다 잃으면 안되기 때문에 volume을 사용한다.  쿠버네티스로 오면서 볼륨은 매우 다양하고, 많아진다. pod에 속하게 되어 관리대상이 된다.  pod에 속하긴 때문에 볼륨의 수명은 pod의 수명에 의존하게 된다.  쿠버의 볼륨 쿠버의 볼륨은 다양한 드라이버와 유형이 있다. 도커의 볼륨은 호스트머신 어딘가에 생성되는 폴더 정도로 볼 수 있지만, 쿠버에선 다르다.  파드 안에 컨테이너와 볼륨이 있다. 컨테이너와 별개로, 파드에 종속되며, 컨테이너에서 해당 볼륨을 쓰기위해서 마운트를 해줘야한다.  apiVersion: a','State'),(_binary '','2023-11-13 06:56:26.861131',12,41,'2023-11-13 06:45:01.138532',4,'n','n','Strimzi'),(_binary '','2023-11-15 01:42:39.688822',12,42,'2023-11-13 06:45:15.313087',4,'\n- 특정 어플리케이션을 개발하려면, 각종 언어 및 툴을 설치하여 환경을 구성해야한다.. 근데 컨테이너로 환경만 제공해 준다면 어떨까\n\n\n도커로 노드를 interactive, detach로 실행해보자\n`docker run -it -d node`\n\n### `exec` 커맨드\n\nDockerfile에 지정된 명령어 외에 추가로 실행이 가능하다.  즉 해당 환경 안으로 명령어를 exec할 수가 있다는 것.\n\n`docker exec -it hopeful_hellman npm init`\n\n\n### 유틸리티 컨테이너\n\n바인드 마운트로 파일은 호스트 머신을 사용하는대신, 노드와 같은 개발환경은 컨테이너로 사용한다.\n\n\n`Dockerfile` 에 ENTRYPOINT 는 이미지 시작 이후 명령어들을 추가할 수 있다.\n\n\n\n','특정 어플리케이션을 개발하려면, 각종 언어 및 툴을 설치하여 환경을 구성해야한다.. 근데 컨테이너로 환경만 제공해 준다면 어떨까  도커로 노드를 interactive, detach로 실행해보자 docker run -it -d node  exec 커맨드 Dockerfile에 지정된 명령어 외에 추가로 실행이 가능하다.  즉 해당 환경 안으로 명령어를 exec할 수가 있다는 것.  docker exec -it hopeful_hellman npm init  유틸리티 컨테이너 바인드 마운트로 파일은 호스트 머신을 사용하는대신, 노드와 같은 개발환경은 컨테이너로 사용한다.  Dockerfile 에 ENTRYPOINT 는 이미지 시작 이후 명령어들을 추가할 수 있다. ','Utility Container'),(_binary '','2023-11-13 07:09:51.211286',12,43,'2023-11-13 06:54:47.584543',4,NULL,'','Kubernetes'),(_binary '\0','2023-11-16 01:52:39.710276',5,46,NULL,2,' ㅁㄴㅇㅁㄴㅇ','ㅁㄴㅇㅁㄴㅇ',''),(_binary '','2023-11-16 16:39:45.574694',2,55,'2023-11-14 00:44:05.196387',2,'asdasd','asdasd','나김하늘성원숭'),(_binary '','2023-11-15 04:11:09.889855',13,58,'2023-11-14 02:16:34.945117',5,'- ~~공개 설정만 바꿨을 때 수정하기/게시하기 버튼이 안눌림~~\n- 글을 수정한 후에 page.css 적용이 안됨\n- ~~개인 정보 수정 후에 변경된 사항이 적용이 안됨 내가 바꾸기 전 사람인줄 아는 것 같음~~ \n-  ~~Nickname Input에 `maxLength={18}` 추가하기~~\n- ~~그래프 2D, 3D 버튼 z-index~~\n- 글 제목, 닉네임 수정한게 참조에 반영 안됨\n- ~~프로필 이미지 1:1 비율에 맞게 잘라줘야 할듯~~\n- ~~다른 사람의 페이지에서도 폴더 수정/삭제 버튼 보임(실제로 수정이 되지는 않음)~~\n- ~~글 등록 시간 +9h 해주기~~\n- ~~글 등록/수정 시 제목 input창 길이가 너무 짧다~~\n- 로컬에서는 글이 길어지면 수정이 안됨 \n- ~~글 검색 시 비공개 글 날짜 1970년 1월 1일로 뜸~~\n- ~~글 검색 시 가로 스크롤 생김~~','공개 설정만 바꿨을 때 수정하기/게시하기 버튼이 안눌림  글을 수정한 후에 page.css 적용이 안됨  개인 정보 수정 후에 변경된 사항이 적용이 안됨 내가 바꾸기 전 사람인줄 아는 것 같음  Nickname Input에 maxLength={18} 추가하기  그래프 2D, 3D 버튼 z-index  글 제목, 닉네임 수정한게 참조에 반영 안됨  프로필 이미지 1:1 비율에 맞게 잘라줘야 할듯  다른 사람의 페이지에서도 폴더 수정/삭제 버튼 보임(실제로 수정이 되지는 않음)  글 등록 시간 +9h 해주기  글 등록/수정 시 제목 input창 길이가 너무 짧다  로컬에서는 글이 길어지면 수정이 안됨  글 검색 시 비공개 글 날짜 1970년 1월 1일로 뜸  글 검색 시 가로 스크롤 생김','수정 사항 정리!'),(_binary '\0','2023-11-14 04:41:44.121669',20,59,NULL,7,'ㅁㄴㅇㅁㄴㅇㅁㄴㅇ','ㅁㄴㅇㅁㄴㅇㅁㄴㅇ','글 제목'),(_binary '','2023-11-14 05:43:38.715335',22,60,'2023-11-14 05:43:26.986108',8,'- 파일 추가 버튼 누르면\n- 왼쪽 워크스페이스에 생기고 수정해야 하는데\n- 바로 글 작성 페이지로 넘어가게 해주셈!','파일 추가 버튼 누르면  왼쪽 워크스페이스에 생기고 수정해야 하는데  바로 글 작성 페이지로 넘어가게 해주셈!','이거 기능 추가해주세요'),(_binary '','2023-11-14 05:43:53.041054',23,61,'2023-11-14 05:43:44.563691',8,'![망키](https://static.wikia.nocookie.net/pokemon/images/6/6a/%EB%A7%9D%ED%82%A4_%EA%B3%B5%EC%8B%9D_%EC%9D%BC%EB%9F%AC%EC%8A%A4%ED%8A%B8.png/revision/latest?cb=20170405011817&path-prefix=ko)\n\n\n- 이거 왜 이미지 안 떠요','망키    이거 왜 이미지 안 떠요','망키 사진인데'),(_binary '','2023-11-14 05:44:34.476310',22,63,'2023-11-14 05:45:22.385734',8,'파일 폴더에 넣을 수 있게 바꿔주셈','파일 폴더에 넣을 수 있게 바꿔주셈','드래그로'),(_binary '','2023-11-14 05:46:13.665561',22,64,'2023-11-14 05:45:44.826083',8,'- 프로필 하단에 톱니바퀴 안 보이게 해주세요\n- 누르면 내 프로필 수정 뜸','프로필 하단에 톱니바퀴 안 보이게 해주세요  누르면 내 프로필 수정 뜸','남의 페이지 갔을 때'),(_binary '','2023-11-14 05:49:56.354497',22,65,'2023-11-14 05:51:04.450596',8,'- 뭔가 화면크기 커지면서 아래랑 옆에 스크롤 생기는데\n- 불편함 고쳐주셈','뭔가 화면크기 커지면서 아래랑 옆에 스크롤 생기는데  불편함 고쳐주셈','폴더 누르면'),(_binary '','2023-11-15 02:06:44.329669',25,66,'2023-11-15 02:33:53.844701',1,'### <그래프의 탐색>\n하나의 정점에서 시작하여 그래프의 모든 정점들을 한 번씩 방문(탐색)하는 것이다.\n\n### <BFS 와 DFS의 사용>\nBFS와 DFS는 모든 정점을 한 번만 방문한다는 공통점을 가지고 있지만, 사용할 때의 장단점은 분명하기 때문에 해당 상황에 맞는 탐색 기법을 사용해야 한다.\n\n\n## BFS\n- 너비 우선 탐색\n- 큐 (Queue)와 함께 사용\n    \n    선입선출(FIFO, Fisrt In First Out)\n\n\n**<BFS 란>**\n\n시작 점으로부터 가까운 정점을 먼저 방문\n\n하고 멀리 떨어져 있는 정점을 나중에 방문\n\n하는 순회 방법.\n\n주로 두 노드 사이의 최단 경로 혹은 임의의 경로를 찾고 싶을 때 사용하는 방법이다.\n\n(최단 경로, 길찾기)\n\n방문한 노드들을 차례대로 저장한 후 꺼낼 수 있는 자료구조인 Queue를 사용한다.\n\n\n\n**<탐색 순서>**\n\n![Untitled](https://user-images.githubusercontent.com/78436899/215311736-3aa888b1-8548-49bc-ae68-f93a925f56fe.png)\n\n**<장점>**\n\n- 노드의 수가 적고 깊이가 얕은 경우 빠르게 동작할 수 있다.\n- 단순 검색 속도가 DFS보다 빠르다.\n- 최단 경로가 존재한다면 어느 한 경로가 무한히 깊어진다고 해도 최단 경로를 반드시 찾을 수 있다.\n\n**<단점>**\n\n- 노드의 수가 늘어나면 탐색해야 하는 노드 또한 많아지기 때문에 비현실적이다.\n- 재귀호출의 DFS와는 달리 다음에 탐색할 정점들을 큐에 저장해야 하므로 저장공간이 많이 필요하다.\n\n## DFS\n\n- 깊이 우선 탐색\n- 스택 (Stack)과 함께 사용\n    \n    재귀 함수로 구현 하는 것이 쉬움\n    \n\n**<DFS 란>**\n\n시작 점에서 다음 분기(branch)로 넘어가기 전에 해당 분기를 완벽하게 탐색하고 넘어가는 방법.\n\n넓게(wide) 탐색하기 전에 깊게(deep) 탐색\n\n한다.\n\nDFS가 BFS보다 좀 더 간단하지만, 단순 검색 속도 자체는 BFS에 비해서 느리다.\n\n\n\n**<탐색 순서>**\n\n\n\n![Untitled](https://user-images.githubusercontent.com/78436899/215311813-7cce081e-7bb6-490b-a95c-995303499c74.png)\n\n**<장점>**\n\n- 현재 경로상의 노드들만 기억하면 되므로, 저장 공간의 수요가 비교적 적음\n- 목표 노드가 깊은 단계에 있는 경우 해를 빨리 구할 수 있음\n- BFS 보다 간단함\n\n**<단점>**\n\n- 단순 검색 속도는 너비 우선 탐색(BFS) 보다 느림\n- 깊이 우선 탐색은 해를 구하면 탐색이 종료되므로, 구한 해가 최단 경로가 된다는 보장이 없음(목표에 이르는 경로가 다수인 경우 구한 해가 최적이 아닐 수 있음)\n\n### [관련 강의](https://www.youtube.com/watch?v=7C9RgOcvkvo)\n\n','<그래프의 탐색> 하나의 정점에서 시작하여 그래프의 모든 정점들을 한 번씩 방문(탐색)하는 것이다.  <BFS 와 DFS의 사용> BFS와 DFS는 모든 정점을 한 번만 방문한다는 공통점을 가지고 있지만, 사용할 때의 장단점은 분명하기 때문에 해당 상황에 맞는 탐색 기법을 사용해야 한다.  BFS   너비 우선 탐색  큐 (Queue)와 함께 사용  선입선출(FIFO, Fisrt In First Out)  <BFS 란>  시작 점으로부터 가까운 정점을 먼저 방문  하고 멀리 떨어져 있는 정점을 나중에 방문  하는 순회 방법.  주로 두 노드 사이의 최단 경로 혹은 임의의 경로를 찾고 싶을 때 사용하는 방법이다.  (최단 경로, 길찾기)  방문한 노드들을 차례대로 저장한 후 꺼낼 수 있는 자료구조인 Queue','BFS & DFS'),(_binary '','2023-11-15 02:07:37.392003',25,68,'2023-11-15 02:34:00.637939',1,'# 1. 알고리즘 기초\n---\n\n## Brute Force\n<br>\n\n- 알고리즘 문제에 있어, 해가 존재할 수 있는 모든 영역을 탐색하는 단순 완전 탐색 방법이다. \n\n- 알고리즘이 직관적이고, 확실한 해를 구할 수 있다는 장점이 있다. \n\n- 알고리즘 실행 시간이 매우 오래걸린다. \n<br><br>\n\n넓은 의미로는 모든 완전 탐색 알고리즘으로 볼 수 있지만, 일반적으로 선형문제에 국한하고 단순 완전 탐색을 의미한다. 따라서 Brute Force는 __문제를 선형구조화 하고, 탐색하는 것이 핵심이다.__\n\n\nBrute Force에 비해 비교적 효율적인 완전 탐색 알고리즘으로는 Bitmasking, Permutation, Recursive Function, BFS, DFS가 있다.\n<br>\n\n```Markdown\n     - - - [선형 구조를 가진 Brute Froce 문제] - - -\n\n         1018 체스판 다시 칠하기     1065 한수  \n         2798 블랙잭                7568 덩치        \n```\n<br>\n\n---\n## Recursion\n\n\n### __Reductions__ \n\nRecursion(재귀)에 대해 바로 설명하기 전에 Reduction(환원)에 대해 잠깐 짚고 넘어가자. 보통 Reduction개념은 P, NP, NP-hard 문제를 다룰 때 나온다. \n\n\n\n>두 문제 X, Y에 대해 X를 polynomial time(다항 시간)안에 풀 수 있고, Y문제를 polynomial time 안에 X문제로 바꿀 수 있다면, Y는 X로 polynomial-time reducible 하다.\n\n여기서 polynomial time(다항 시간)이란 $n^k + ...$ 로 표현된다. 주로 $2^n$ 과 같은 exponential time(지수 시간)과 구분되어 사용된다. \n\n\nReduction의 정확한 예는 아니지만, 곱셈은 더하기를 여러번 함으로써 풀 수 있다. 핵심은 지수 시간을 가지는 문제를 다항 시간문제로 변환하는데 있고, Recursion은 강력한 Reduction의 한 예로 볼 수 있다.\n<br><br>\n\n### __Recursive Function__\n\nRecursive Function은 자기 자신을 호출 하는 함수로 정의된다. 단순히 반복되는 작업을 할당하여 알고리즘을 구성할 수 있지만, 그러면 Brute Force를 사용하는 것과 구분되지 않는다. \n<br>\n\n바로 연상되지는 않지만, 위에서 설명한 Reduction의 개념으로 접근하면, 재귀는 동일한 문제를 풀 수 있는 문제로 환원 되어야한다. __호출될 수록 쉬워지거나, 차수가 낮아져야 한다.__ \n<br><br>\n\n> 핵심은 __귀납적 사고__ 에 있다. \n\n<br>\n\n$f(n)$ 다양한 $f(a(n-b))$ 조합으로 나누어 구현하는 과정에서 Recursive Function이 활용된다. \n\n```\n - - - [Recursive Function을 사용하여 푸는 문제들] - - -\n\n        Finbonachi Number, Tower of Hanoi\n        Fast Multiplication(Karatsuba)\n        Merge Sort, Quik sort\n```\n\n\n- c, java, python 에서 재귀함수는 호출될 때마다 스택 프레임으로 쌓이게 되므로 Depth가 깊어지면 stackoverflow가 발생 할 수 있다.\n\n- 따라서 무한 호출이 되지않게 Stop point를 설정하거나,  Memoization을 통해 중복연산을 줄여 리소스 낭비를 줄여야한다.','1. 알고리즘 기초  Brute Force     알고리즘 문제에 있어, 해가 존재할 수 있는 모든 영역을 탐색하는 단순 완전 탐색 방법이다.   알고리즘이 직관적이고, 확실한 해를 구할 수 있다는 장점이 있다.   알고리즘 실행 시간이 매우 오래걸린다.   넓은 의미로는 모든 완전 탐색 알고리즘으로 볼 수 있지만, 일반적으로 선형문제에 국한하고 단순 완전 탐색을 의미한다. 따라서 Brute Force는 문제를 선형구조화 하고, 탐색하는 것이 핵심이다.  Brute Force에 비해 비교적 효율적인 완전 탐색 알고리즘으로는 Bitmasking, Permutation, Recursive Function, BFS, DFS가 있다.        - - - [선형 구조를 가진 Brute Froce 문제] - - -','algo_basic'),(_binary '','2023-11-15 02:07:54.826004',25,69,'2023-11-15 02:34:03.289887',1,'# Search Algorithm\n## 1. Linear Search (선형 검색)\n![Linear-Search](https://user-images.githubusercontent.com/108309396/214469677-92944d5b-be6b-4c36-a6bd-d16a8b369108.png)\n- 순차적으로 검색하여 Sequential search라고도 함\n- array, linked list 등의 처음부터 끝까지 하나씩 비교해가며 원하는 값을 찾아내는 알고리즘\n- 장점: 단순하여 구현이 쉽고 정렬되지 않은 리스트에서도 사용 가능\n- 단점: 데이터의 양이 많아지면 검색에 소요되는 시간도 길어져 비효율적임\n\n### > Time Complexity\n- Best case: $O(n) = 1$\n-  Worst case: $O(n) = n$\n- Average case: $O(n) = (\\frac{n}{2}\\times\\frac{1}{2})+(n\\times\\frac{1}{2}) = \\frac{3}{4}n$  \n&rarr; 원하는 대상이 있을 경우와 없을 경우 각각 확률 $\\frac{1}{2}$  \n&rarr; $O(n)= n$\n\n### > Implementation(using Python)\n```python\ndef LinearSearch(arr, size, target):\n    for i in range(size)\n        if arr[i] == target # arr이라는 배열에서 target을 찾는다.\n            return i # 찾으면 해당 index를 return\n    return -1 # 못 찾으면 -1을 return\n```\n\n\n## 2. Binary Search (이진 검색)\n![BinarySearch](https://user-images.githubusercontent.com/108309396/214477517-ad8be845-eb14-443b-b505-eabc081f5bd0.png)\n- 반으로 나누어 검색\n- linear search의 경우 처음부터 끝까지 탐색해야 하지만 binary search는 중간값부터 탐색함\n- linear search는 linked list에서, binary search는 tree에서 많이 쓰임\n- 계속 반으로 나누면서 연산하기 때문에 처리속도가 매우 빠름\n- 대신 반드시 정렬되어야 함\n\n### > Time Complexity\n전체 데이터 수를 N이라고 할 때\n1) 첫 번째 탐색 후 $\\frac{N}{2}$\n2) 두 번째 탐색 후 $\\frac{N}{2}\\times\\frac{1}{2}$\n3) 세 번쨰 탐색 후 $\\frac{N}{2}\\times\\frac{1}{2}\\times\\frac{1}{2}$\n4) ...k번째 탐색 후 남은 데이터 수 $N\\times(\\frac{1}{2})^k$  \n&rarr; In worst case, $N\\times(\\frac{1}{2})^k$ = 1  \n&rarr; $k = log_2N$  \n&rarr; $O(logN)$  \n\n### > Implementation(using Python)\n```python\ndef BinarySearch(arr, size, target):\n    first = 0\n    last = n - 1\n    while first <= last:\n        mid = (first + last) // 2\n        if target == arr[mid]:\n            return mid\n        elif target < arr[mid]:\n            last = mid - 1\n        else \n            first = mid + 1\n    return -1\n```\n## 3. Hash Search\n### > Hash Basic\n![ComponentsofHashing (1)](https://user-images.githubusercontent.com/108309396/214489817-9ce48fa8-79e7-453d-8261-76f1d1f72624.png)\n- Hash Table이란 Key-value쌍으로 데이터를 저장하는 자료구조\n- Space-Time trade off의 대표적인 알고리즘\n- key, Hash function, Hash, value, bucket, slot으로 이루어져 있음\n  - key: 고유한 값으로 해시 함수의 input이 된다.\n  - Hash function: key를 hash로 바꿔주는 역할을 함. 다양한 길이를 가지고 있는 key를 일정한 길이를 가지는 hash로 변환하여 저장소를 효율적으로 운용할 수 있도록 도와줌.\n  - Hash: 해시 함수의 결과물로 저장소(bucket, slot)에서 value와 매칭되어 저장됨\n  - value: 저장소에 최종적으로 저장되는 값으로 key와 매칭되어 저장, 삭제, 검색, 접근이 가능\n\n\n### > Hash Search Algorithm\n![hash3](https://user-images.githubusercontent.com/108309396/214490361-23260cab-87c4-4d72-ae07-50abe17348f8.png)\n- Hash search를 위해서는 총 두 개의 알고리즘이 필요\n  - 데이터를 저장하는 알고리즘\n  - 데이터를 검색하는 알고리즘\n- 해시함수로는 나누기 연산, 나머지 연산 등 다양한 연산을 이용할 수 있다.\n1. 데이터를 저장하는 알고리즘\n   - 배열 2개를 준비한다\n    - 주어진 값들을 해시함수를 이용하여 별도의 배열에 다시 저장하기 때문\n    - 다른 탐색 알고리즘에서는 배열 크기를 데이터 수 만큼만 준비하면 충분하지만, 해시 탐색법은 데이터 수의 1.5~2배의 크기의 배열을 준비해야 한다.\n    - ex) 데이터가 10개이면, 데이터를 15으로 나눈 나머지를 해시값으로 설정한다.\n\n   - 만약, 같은 해시값을 가진 데이터가 있다면 (충돌이 일어난다면) 비어있는 옆 칸에 보관한다.\n\n2. 데이터를 검색하는 알고리즘\n   - 저장할 때 사용한 것과 같은 해시 함수를 사용\n   - 원하는 데이터가 존재하지 않을 경우에 어떻게 처리할 것인지 정해야 한다\n- 장점\n  - 데이터를 저장하거나, 탐색하고자 하는 위치를 즉시 참조할 수 있기 때문에 빠른 속도로 처리가 가능\n- 단점\n  - Hash collision 발생 시 탐색이 시간 복잡도 $O(n)$에 점점 수렴함\n  - 정렬이나 순차적인 메모리 저장이 필요한 경우 적합하지 않음\n  - 해시 함수의 성능에 따라 해시 테이블 전체 성능이 크게 영향을 받는다.\n\n### Hash Collision\n(1) 충돌이 일어난 인덱스를 뛰어넘어서, 빈 공간이 있는지 탐색 후 삽입 → 개방주소법 (Open addressing)\n\n(2) 충돌이 일어난 지점을 사용하되, 연결 리스트로 묶는 방법 → 체이닝 (Chaning)\n\n개방주소법의 경우, 인덱스만 증가시켜주면 되므로 안정적인 방법입니다.\n\n체이닝의 경우, 정해진 해시테이블 이외의 주소를 추가로 할당해서\n\n확장해서 사용할 수 있다는 장점이 있습니다.\n### > Time Complexity\n- Best case: $O(1)$\n- Worst case: $O(n)$\n- Hash Table에서 해당하는 데이터를 찾아 바로 return 하기 때문에 $O(1)$\n\n### > Implementation\n1. **python의 경우, hash table을 별도로 구현할 필요없음! &rarr; dictionary 사용**\n2. C++\n```c++\n#include <iostream>\n\n#define MAX_TABLE	8191\n#define MAX_KEY		64\n\ntypedef long long ll;\n\nusing namespace std;\n\ntypedef struct Hash {\n	char key[MAX_KEY + 1];\n	int data;\n} Hash;\nHash table[MAX_TABLE];\n\nll hashGen(char key[]) {\n	ll h = 5381;\n	while (*key != \'\\0\')\n		h = (((h << 5) + h) + *key++) % MAX_TABLE;\n	return h;\n}\n\nint m_strcmp(const char* str1, const char* str2) {\n	while (*str1 != \'\\0\' || *str2 != \'\\0\') {\n		if (*str1 != *str2) return *str1 - *str2;\n		str1++; str2++;\n	}\n	return 0;\n}\n\nvoid m_strcpy(char dsc[], char src[]) {\n	while (*src != \'\\0\')\n		*(dsc++) = *(src++);\n}\n\nint hashDelete(char key[]) {\n	ll h = hashGen(key);\n	int cnt = MAX_TABLE;\n\n	while (table[h].key[0] != 0 && cnt--) {\n		if (!m_strcmp(table[h].key, key)) {\n			table[h].key[0] = 0;\n			table[h].data = 0;\n			return 1;\n		}\n		h = (h + 1) % MAX_TABLE;\n	}\n	return 0;\n}\n\nint hashAdd(char key[], int data) {\n	ll h = hashGen(key);\n	int cnt = MAX_TABLE;\n\n	while (table[h].key[0] != 0 && cnt--) {\n		if (!m_strcmp(table[h].key, key)) {\n			table[h].data = data;\n			return 1;\n		}\n		else cout << \"[충돌 발생]\\n\";\n		h = (h + 1) % MAX_TABLE;\n	}\n\n	if (cnt == -1) return 0;\n	m_strcpy(table[h].key, key);\n	table[h].data = data;\n	return 1;\n}\n\nint hashFind(char key[], int* data) {\n	ll h = hashGen(key);\n	int cnt = MAX_TABLE;\n\n	while (table[h].key[0] != 0 && cnt--) {\n		if (!m_strcmp(table[h].key, key)) {\n			*data = table[h].data;\n			return 1;\n		}\n		h = (h + 1) % MAX_TABLE;\n	}\n	return 0;\n}\n\nint main(void) {\n	while (true) {\n		char key[64];\n		int data;\n		char c;\n		cout << \"[명령]\\n1. 삽입\\n2. 찾기\\n3. 삭제\\n4. 테이블 조회\\n5. 종료\\n→ \";\n		cin >> c;\n\n		switch (c) {\n		case \'1\':\n			cout << \"[Key, Data 입력] \";\n			cin >> key >> data;\n			if (hashAdd(key, data)) cout << \"[성공] 입력 완료\\n\";\n			else cout << \"[실패] 해시가 가득 찼습니다.\\n\";\n			cout << \"-----------------------------\\n\";\n			break;\n		case \'2\':\n			cout << \"[Key 입력] \";\n			cin >> key;\n			if (hashFind(key, &data)) cout << \"[성공] \" << data << \'\\n\';\n			else cout << \"[실패] 존재하지 않는 데이터입니다.\\n\";\n			cout << \"-----------------------------\\n\";\n			break;\n		case \'3\':\n			cout << \"[Key 입력] \";\n			cin >> key;\n			if (hashDelete(key)) cout << \"[성공] 삭제되었습니다.\\n\";\n			else cout << \"[실패] 존재하지 않는 데이터입니다.\\n\";\n			cout << \"-----------------------------\\n\";\n			break;\n		case \'4\':\n			for (int i = 0; i < MAX_TABLE; i++)\n				cout << \"[\" << i << \"] \" << table[i].key << \", \" << table[i].data << \'\\n\';\n			cout << \"-----------------------------\\n\";\n			break;\n		case \'5\':\n			return 0;\n		default:\n			cout << \"잘못 입력하였습니다.\\n\";\n			cout << \"-----------------------------\\n\";\n			continue;\n		}\n	}\n\n	return 0;\n}\n```','Search Algorithm 1. Linear Search (선형 검색) Linear-Search - 순차적으로 검색하여 Sequential search라고도 함 - array, linked list 등의 처음부터 끝까지 하나씩 비교해가며 원하는 값을 찾아내는 알고리즘 - 장점: 단순하여 구현이 쉽고 정렬되지 않은 리스트에서도 사용 가능 - 단점: 데이터의 양이 많아지면 검색에 소요되는 시간도 길어져 비효율적임  > Time Complexity   Best case: $O(n) = 1$  Worst case: $O(n) = n$  Average case: $O(n) = (\\frac{n}{2}\\times\\frac{1}{2})+(n\\times\\frac{1}{2}) = \\frac{3}{4}n$ → 원하는 대상이','search'),(_binary '','2023-11-15 02:38:47.697766',25,70,'2023-11-15 02:33:58.514463',1,'# Sliding Window\n\n- 고정된 크기의 window를 옮기는 알고리즘\n\n![Untitled](https://raw.githubusercontent.com/Al9-Mor9/Concepts/main/Algorithm-Basics/src/window.png)\n![Untitled](https://github.com/Al9-Mor9/Concepts/blob/main/Algorithm-Basics/src/window_1.png?raw=true)\n\n- 예제 1\n    \n    \n\nN, K를 입력 받고 N개의 정수를 입력 받습니다. (0 ≤ K ≤ N ≤ 100,000)\n\n연속하는 K개의 정수의 합의 최댓값을 출력해봅시다. (단 K개 정수의 합은 int의 범위를 넘어가지 않는다고 가정)\n\n```cpp\n/*\n	풀이 1\n*/\n#include <iostream>\nusing namespace std;\n#define ans 2147483647\n\nint N, K, ans = INF, sum;\nint arr[100000];\nint main(){\n	scanf(\"%d%d\", &N, &K);\n	for (int i = 0; i < N; i++) scanf(\"%d\", &arr[i]);\n	for (int i = 0; i <= N - K; i++) {\n		sum = 0;\n		for (int j = 0; j < K; j++) {\n				sum += arr[i + j];\n		}\n		if (ans > sum) ans = sum;\n	}\n	printf(\"%d\", ans);\n}\n```\n\n풀이 1의 경우 매 index마다 연속된 K개 정수의 합을 구하면서 최솟합을 찾습니다. 따라서 시간복잡도는 O(N*K)가 됩니다.\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/blob/main/Algorithm-Basics/src/naive.png?raw=true)\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/blob/main/Algorithm-Basics/src/naive_1.png?raw=true)\n\n(…)\n\n\n\n```cpp\n/*\n풀이 2\n*/\n#include <iostream>\nusing namespace std;\n\nint N, K, ans, sum;\nint arr[100000];\nint main(){\n	scanf(\"%d%d\", &N, &K);\n	for (int i = 0; i < N; i++) scanf(\"%d\", &arr[i]);\n	for (int i = 0; i < K; i++) {\n		ans += arr[i];\n		sum += arr[i];\n	}\n\n	for (int i = 1; i <= N - K; i++){\n		sum -= arr[i-1];\n		sum += arr[i + (K - 1)];\n		if (ans > sum) ans = sum;\n	}\n\n	printf(\"%d\", ans);\n}\n```\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/blob/main/Algorithm-Basics/src/slidingSol.png?raw=true)\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/blob/main/Algorithm-Basics/src/slidingSol_1.png?raw=true)\n![Untitled](https://github.com/Al9-Mor9/Concepts/blob/main/Algorithm-Basics/src/slidingSol_2.png?raw=true)\n\n(…)\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/blob/main/Algorithm-Basics/src/slidingSol_3.png?raw=true)   \n주황색 부분은 공통된 부분이므로 그대로 두고, 노란색은 빼고 파란색은 더해 가면서 연속된 구간의 합을 구합니다. 매번 구간 내 배열 요소들을 모두 더하면서 합을 구하는 것이 아니기 때문에 시간복잡도는 O(N)입니다.','Sliding Window   고정된 크기의 window를 옮기는 알고리즘  Untitled Untitled    예제 1  N, K를 입력 받고 N개의 정수를 입력 받습니다. (0 ≤ K ≤ N ≤ 100,000)  연속하는 K개의 정수의 합의 최댓값을 출력해봅시다. (단 K개 정수의 합은 int의 범위를 넘어가지 않는다고 가정)  /* 	풀이 1 */ #include <iostream> using namespace std; #define ans 2147483647  int N, K, ans = INF, sum; int arr[100000]; int main(){ 	scanf(\"%d%d\", &N, &K); 	for (int i = 0; i < N; i++) scanf(\"%d\", &arr[i]); 	for ','sliding_window'),(_binary '','2023-11-15 02:08:49.634429',25,72,'2023-11-15 02:34:06.342872',1,'## Bubble sort\n\n- 개념 요약\n    - 서로 인접한 두 원소를 검사하여 정렬하는 알고리즘\n        - 인접한 2개의 레코드를 비교하여 크기가 순서대로 되어 있지 않으면 서로 교환\n- 구체적인 개념\n    - 첫 번째 ↔ 두 번째, 두 번째 ↔ 세 번째, … , (마지막-1)번째와 마지막 자료를 비교하여 교환 → 1회전을 수행하면 가장 큰 자료가 맨 뒤로 이동\n    - 2회전 수행 시 끝에서 두 번째 자료까지는 정렬에서 제외\n- 예제\n    \n    ![Untitled](https://user-images.githubusercontent.com/90077061/214869782-56ce7ec1-efa8-4221-852e-572a559ca428.png)\n    \n- 코드\n    \n    ```python\n    def bubble_sort(arr):\n        for i in range(len(arr) - 1, 0, -1):\n            *for j in range(i):*\n                if arr[j] > arr[j + 1]:\n                    arr[j], arr[j + 1] = arr[j + 1], arr[j]\n    ```\n    \n- 특징\n    - 구현이 매우 간단\n    - 순서에 맞지 않은 요소를 인접한 요소와 교환한다\n    - 하나의 요소가 가장 왼쪽에서 가장 오른쪽까지 이동하기 위해서 배열의 다른 모든 요소와 교환 되어야 함\n    - 단순하지만 거의 쓰이지 않음\n- 시간복잡도\n    \n    $T(n) = O(n^2)$\n    \n\n## Selection sort\n\n- 개념 요약\n    - 입력 배열 이외에 다른 추가 메모리를 요구하지 않는 정렬방법\n    - 해당 순서에 원소를 넣을 위치는 이미 정해져 있고, 어떤 원소를 넣을지 선택하는 알고리즘\n    - 과정 설명\n    1. 주어진 배열 중에서 최솟값을 찾는다\n    2. 그 값을 맨 앞에 위치한 값과 교체한다\n    3. 맨 처음 위치를 뺀 나머지 리스트를 같은 방법으로 교체한다\n    4. 하나의 원소만 남을 때까지 위의 과정을 반복한다\n- 구체적인 개념\n    - 가장 작은 값을 찾아 첫 번째에 놓고, 두번째부터 마지막까지 가장 작은 값을 찾아 두번째에 넣고 …\n    - 1회전을 하고 나면 가장 작은 값의 자료가 맨 앞으로 오게 되므로 그 다음 회전에서 두 번째 자료를 가지고 비교한다\n- 예제\n    \n    ![Untitled (1)](https://user-images.githubusercontent.com/90077061/214871369-b8882a63-c15c-4752-abe3-3b696a863194.png)\n    \n- 코드\n    \n    ```python\n    def selection_sort(arr):\n        for i in range(len(arr) - 1):\n            min_idx = i\n            for j in range(i + 1, len(arr)):\n                if arr[j] < arr[min_idx]:\n                    min_idx = j\n            arr[i], arr[min_idx] = arr[min_idx], arr[i]\n    ```\n    \n- 특징\n    - 자료 이동 횟수가 미리 결정 된다\n    - 안정성이 부족\n        \n        = 값이 같은 레코드가 있는 경우 상대적 위치가 변경될 수 있다\n        \n- 시간복잡도\n    \n    $T(n) = O(n^2)$\n    \n\n## Insertion sort\n\n- 개념 요약\n    - 손안의 카드를 정렬하는 방법과 유사\n    - 모든 요소를 앞에서부터 차례대로 이미 정렬된 배열 부분과 비교\n- 구체적인 개념\n    - 두 번째 자료부터 시작하여 그 앞의 자료들과 비교하여 삽입할 위치를 지정한 후 자료를 뒤로 옮기고 직정한 자리에 자료를 삽입하여 정렬하는 알고리즘\n- 예제\n    \n    ![Untitled (2)](https://user-images.githubusercontent.com/90077061/214871483-9690673b-6ce9-409e-a719-7ad6fb4d6358.png)\n    \n- 코드\n    \n    ```python\n    def insertion_sort(arr):\n        for end in range(1, len(arr)):\n            for i in range(end, 0, -1):\n                if arr[i - 1] > arr[i]:\n                    arr[i - 1], arr[i] = arr[i], arr[i - 1]\n    ```\n    \n- 특징\n    - 안정한 정렬 방법\n    - 레코드의 수가 적을 경우 알고리즘 자체가 매우 간단하므로 다른 정렬 법보다 유리\n    - 비교적 많은 레코드들의 이동을 포함\n    - 레코드 수가 많고 레코드 크기가 클 경우 적합하지 않음\n- 시간복잡도\n    - $Worst : T(n) = O(n^2)$','Bubble sort   개념 요약   서로 인접한 두 원소를 검사하여 정렬하는 알고리즘   인접한 2개의 레코드를 비교하여 크기가 순서대로 되어 있지 않으면 서로 교환  구체적인 개념   첫 번째 ↔ 두 번째, 두 번째 ↔ 세 번째, … , (마지막-1)번째와 마지막 자료를 비교하여 교환 → 1회전을 수행하면 가장 큰 자료가 맨 뒤로 이동  2회전 수행 시 끝에서 두 번째 자료까지는 정렬에서 제외  예제  Untitled   코드  def bubble_sort(arr):     for i in range(len(arr) - 1, 0, -1):         *for j in range(i):*             if arr[j] > arr[j + 1]:                 arr[j], arr','sort'),(_binary '','2023-11-15 02:09:12.901284',25,73,'2023-11-15 02:34:08.700170',1,'# Merge Sort\n## 개념 요약\n- **안정 정렬** 에 속하며, **분할 정복 알고리즘**의 하나이다.\n  - 분할 정복(divide and conquer) 방법\n    - 문제를 작은 2개의 문제로 분리하고 각각을 해결한 다음, 결과를 모아서 원래의 문제를 해결하는 전략이다.\n    - 분할 정복 방법은 대개 순환 호출을 이용하여 구현한다.\n- 과정\n  1. 리스트의 길이가 0 또는 1이면 이미 정렬된 것으로 본다. \n  2. 그렇지 않은 경우에는 정렬되지 않은 리스트를 절반으로 잘라 비슷한 크기의 두 부분 리스트로 나눈다.\n  3. 각 부분 리스트를 재귀적으로 합병 정렬을 이용해 정렬한다.\n  4. 두 부분 리스트를 다시 하나의 정렬된 리스트로 합병한다.\n\n- P) **안정정렬이란?**   \n  배열을 정렬했을 때, 동일한 값의 원소 사이의 위치 관계가 변하지 않는 정렬입니다.   \n  (예 [4, 3, 2_1, 1, 2_2] 를 정렬했을 때, 안정정렬인 경우 [1, 2_1, 2_2, 3, 4]로 2의 값을 가지는 두 원소 사이의 위치 관계가 유지되지만, 불안정정렬인 경우에는 [1, 2_2, 2_1, 3, 4]와 같이 나올 수도 있음.)\n\n## 개념\n- 하나의 리스트를 두 개의 균등한 크기로 **분할**하고, 분할된 부분 리스트를 **정렬**한 다음, 두 개의 정렬된 부분 리스트를 **합하여** 전체가 정렬된 리스트가 되게 하는 방법이다.\n- 단계\n  - 분할(Divide): 입력 배열을 같은 크기의 2개의 부분 배열로 분할한다.\n  - 정복(Conquer): 부분 배열을 정렬한다. 부분 배열의 크기가 충분히 작지 않으면 **순환 호출**을 이용하여 다시 분할 정복 방법을 적용한다.\n  - 결합(Combine): 정렬된 부분 배열들을 하나의 배열에 합병한다.\n- 과정\n  - 추가적인 리스트가 필요하다.\n  - 각 부분 배열을 정렬할 때도 합병 정렬을 순환적으로 호출하여 적용한다.\n  - 합병 정렬에서 실제로 정렬이 이루어지는 시점은 2개의 리스트를 합병(merge)하는 단계 이다.  \n![merge-sort-concepts](https://user-images.githubusercontent.com/108309396/216827345-734ad9ef-51c8-4a6a-a023-623ae21cc795.png)\n- 2개의 정렬된 리스트를 합병(merge)하는 과정\n  1. 2개의 리스트의 값들을 처음부터 하나씩 비교하여 두 개의 리스트의 값 중에서 더 작은 값을 새로운 리스트(sorted)로 옮긴다.\n  2. 둘 중에서 하나가 끝날 때까지 이 과정을 되풀이한다.\n  3. 만약 둘 중에서 하나의 리스트가 먼저 끝나게 되면 나머지 리스트의 값들을 전부 새로운 리스트(sorted)로 복사한다.\n  4. 새로운 리스트(sorted)를 원래의 리스트(list)로 옮긴다.  \n![merge-sort2](https://user-images.githubusercontent.com/108309396/216827349-e593474b-92f1-4ba3-87e1-b560c3fba430.png)\n\n## 합병 정렬(merge sort) 알고리즘의 특징\n- 단점\n  - 만약 레코드를 **배열(Array)** 로 구성하면, 임시 배열이 필요하다.\n    - 제자리 정렬(in-place sorting)이 아니다.\n  - 레코드의 크기가 큰 경우에는 이동 횟수가 많으므로 매우 큰 시간적 낭비를 초래한다.\n- 장점\n  - 안정적인 정렬 방법\n    - 데이터의 분포에 영향을 덜 받는다. 즉, 입력 데이터가 무엇이든 간에 정렬되는 시간은 동일하다. ($O(nlogn)$로 동일)\n  - 만약 레코드를 **연결 리스트(Linked List)** 로 구성하면, 링크 인덱스만 변경되므로 데이터의 이동은 무시할 수 있을 정도로 작아진다.\n    - 제자리 정렬(in-place sorting)로 구현할 수 있다.\n  - 따라서 크기가 큰 레코드를 정렬할 경우에 연결 리스트를 사용한다면, 합병 정렬은 퀵 정렬을 포함한 다른 어떤 졍렬 방법보다 효율적이다.\n\n## 시간복잡도\n1. 분할 단계\n- 비교 연산과 이동 연산이 수행되지 않는다.\n2. 합병 단계\n- 비교 횟수  \n  - ![sort-time-complexity-etc4](https://user-images.githubusercontent.com/108309396/216827667-c328b96c-5800-46e3-9e84-11cadf6bc84a.png)\n\n  - 순환 호출의 깊이 (합병 단계의 수)\n    - 레코드의 개수 n이 2의 거듭제곱이라고 가정$(n=2^k)$했을 때, $n=2^3$의 경우, $2^3$&rarr;$2^2$&rarr;$2^1$&rarr;$2^0$ 순으로 줄어들어 순환 호출의 깊이가 3임을 알 수 있다. 이것을 일반화하면 $n=2^k$의 경우, $k=log_2n$임을 알 수 있다.\n    - $k=log_2n$\n  - 각 합병 단계의 비교 연산\n    - 크기 1인 부분 배열 2개를 합병하는 데는 최대 2번의 비교 연산이 필요하고, 부분 배열의 쌍이 4개이므로 $2\\times4=8$번의 비교 연산이 필요하다. 다음 단계에서는 크기 2인 부분 배열 2개를 합병하는 데 최대 4번의 비교 연산이 필요하고, 부분 배열의 쌍이 2개이므로 $4\\times2=8$번의 비교 연산이 필요하다. 마지막 단계에서는 크기 4인 부분 배열 2개를 합병하는 데는 최대 8번의 비교 연산이 필요하고, 부분 배열의 쌍이 1개이므로 $8\\times1=8$번의 비교 연산이 필요하다. 이것을 일반화하면 하나의 합병 단계에서는 최대 n번의 비교 연산을 수행함을 알 수 있다.\n    - 최대 n번\n  - 순환 호출의 깊이 만큼의 합병 단계 * 각 합병 단계의 비교 연산 = $nlog_2n$\n- 이동 횟수\n  - 순환 호출의 깊이 (합병 단계의 수)\n    - $k=log_2n$\n  - 각 합병 단계의 이동 연산\n    - 임시 배열에 복사했다가 다시 가져와야 되므로 이동 연산은 총 부분 배열에 들어 있는 요소의 개수가 n인 경우, 레코드의 이동이 2n번 발생한다.\n  - 순환 호출의 깊이 만큼의 합병 단계 * 각 합병 단계의 이동 연산 = $2nlog_2n$\n3. $T(n) = nlog_2n(비교) + 2nlog_2n(이동) = 3nlog_2n = O(nlogn)$\n\n## Merge Sort C언어 구현\n```C\n# include <stdio.h>\n# define MAX_SIZE 8\nint sorted[MAX_SIZE] // 추가적인 공간이 필요\n\n// i: 정렬된 왼쪽 리스트에 대한 인덱스\n// j: 정렬된 오른쪽 리스트에 대한 인덱스\n// k: 정렬될 리스트에 대한 인덱스\n/* 2개의 인접한 배열 list[left...mid]와 list[mid+1...right]의 합병 과정 */\n/* (실제로 숫자들이 정렬되는 과정) */\nvoid merge(int list[], int left, int mid, int right){\n  int i, j, k, l;\n  i = left;\n  j = mid+1;\n  k = left;\n\n  /* 분할 정렬된 list의 합병 */\n  while(i<=mid && j<=right){\n    if(list[i]<=list[j])\n      sorted[k++] = list[i++];\n    else\n      sorted[k++] = list[j++];\n  }\n\n  // 남아 있는 값들을 일괄 복사\n  if(i>mid){\n    for(l=j; l<=right; l++)\n      sorted[k++] = list[l];\n  }\n  // 남아 있는 값들을 일괄 복사\n  else{\n    for(l=i; l<=mid; l++)\n      sorted[k++] = list[l];\n  }\n\n  // 배열 sorted[](임시 배열)의 리스트를 배열 list[]로 재복사\n  for(l=left; l<=right; l++){\n    list[l] = sorted[l];\n  }\n}\n\n// 합병 정렬\nvoid merge_sort(int list[], int left, int right){\n  int mid;\n\n  if(left<right){\n    mid = (left+right)/2 // 중간 위치를 계산하여 리스트를 균등 분할 -분할(Divide)\n    merge_sort(list, left, mid); // 앞쪽 부분 리스트 정렬 -정복(Conquer)\n    merge_sort(list, mid+1, right); // 뒤쪽 부분 리스트 정렬 -정복(Conquer)\n    merge(list, left, mid, right); // 정렬된 2개의 부분 배열을 합병하는 과정 -결합(Combine)\n  }\n}\n\nvoid main(){\n  int i;\n  int n = MAX_SIZE;\n  int list[n] = {21, 10, 12, 20, 25, 13, 15, 22};\n\n  // 합병 정렬 수행(left: 배열의 시작 = 0, right: 배열의 끝 = 7)\n  merge_sort(list, 0, n-1);\n\n  // 정렬 결과 출력\n  for(i=0; i<n; i++){\n    printf(\"%d\\n\", list[i]);\n  }\n}\n```  \n![merge-sort-ccode3](https://user-images.githubusercontent.com/108309396/216827344-c657ca30-2cc1-4d30-9732-649945ee9ce1.png)\n\n\n\n# Heap Sort\n## 자료구조 ‘힙(heap)’\n- 완전 이진 트리의 일종으로 우선순위 큐를 위하여 만들어진 자료구조\n- 최댓값, 최솟값을 쉽게 추출할 수 있는 자료구조  \n![1](https://user-images.githubusercontent.com/108309396/216829091-1422af71-c1c0-4407-8ff0-b158a99a67a9.png)\n\n## 개념 요약\n- 최대 힙 트리나 최소 힙 트리를 구성해 정렬을 하는 방법\n- 내림차순 정렬을 위해서는 최대 힙을 구성하고, 오름차순 정렬을 위해서는 최소 힙을 구성\n- 과정\n  1. 정렬해야 할 n개의 요소들로 최대 힙(완전 이진 트리 형태)을 만든다.\n     - 내림차순을 기준으로 정렬\n  2. 그 다음으로 한 번에 하나씩 요소를 힙에서 꺼내서 배열의 뒤부터 저장하면 된다.\n  3. 삭제되는 요소들(최댓값부터 삭제)은 값이 감소되는 순서로 정렬되게 된다.\n\n## 힙 정렬(heap sort) 알고리즘의 특징\n- 장점\n  - 시간 복잡도가 좋은편\n  - 힙 정렬이 가장 유용한 경우는 전체 자료를 정렬하는 것이 아니라 가장 큰 값 몇개만 필요할 때 이다.\n\n## 힙 정렬(heap sort)의 시간복잡도\n\n- 힙 트리의 전체 높이가 거의 $log_2n$(완전 이진 트리이므로)이므로 하나의 요소를 힙에 삽입하거나 삭제할 때 힙을 재정비하는 시간이 $log_2n$만큼 소요된다.\n- 요소의 개수가 n개 이므로 전체적으로 $O(nlog_2n)$의 시간이 걸린다.\n- $T(n) = O(nlogn)$\n\n\n## 내림차순 정렬을 위한 최대 힙(max heap)의 구현\n- 힙(heap)은 1차원 배열로 쉽게 구현될 수 있다.\n- 정렬해야 할 n개의 요소들을 1차원 배열에 기억한 후 최대 힙 삽입을 통해 차례대로 삽입한다.\n- 최대 힙으로 구성된 배열에서 최댓값부터 삭제한다.\n1. 최대 힙(max heap)의 삽입\n    1) 힙에 새로운 요소가 들어오면, 일단 새로운 노드를 힙의 마지막 노드에 이어서 삽입한다.\n    2) 새로운 노드를 부모 노드들과 교환해서 힙의 성질을 만족시킨다.\n- 아래의 최대 힙(max heap)에 새로운 요소 8을 삽입해보자.  \n![2](https://user-images.githubusercontent.com/108309396/216829093-34a9e50b-f278-4f61-a2ac-145e89c26c23.png)\n\n## C언어를 이용한 최대 힙(max heap) 삽입 연산\n```c\n/* 현재 요소의 개수가 heap_size인 힙 h에 item을 삽입한다. */\n// 최대 힙(max heap) 삽입 함수\nvoid insert_max_heap(HeapType *h, element item){\n  int i;\n  i = ++(h->heap_size); // 힙 크기를 하나 증가\n\n  /* 트리를 거슬러 올라가면서 부모 노드와 비교하는 과정 */\n  // i가 루트 노트(index: 1)이 아니고, 삽입할 item의 값이 i의 부모 노드(index: i/2)보다 크면\n  while((i != 1) && (item.key > h->heap[i/2].key)){\n    // i번째 노드와 부모 노드를 교환환다.\n    h->heap[i] = h->heap[i/2];\n    // 한 레벨 위로 올라간다.\n    i /= 2;\n  }\n  h->heap[i] = item; // 새로운 노드를 삽입\n}\n```\n\n2. 최대 힙(max heap)의 삭제\n- 최대 힙에서 최댓값은 루트 노드이므로 루트 노드가 삭제된다.\n- 최대 힙(max heap)에서 삭제 연산은 최댓값을 가진 요소를 삭제하는 것이다.\n- 삭제된 루트 노드에는 힙의 마지막 노드를 가져온다.\n- 힙을 재구성한다.\n- 아래의 최대 힙(max heap)에서 최댓값을 삭제해보자.  \n![3](https://user-images.githubusercontent.com/108309396/216829094-c55ed29d-dd92-40a7-8ac2-1bcbb1237c10.png)\n\n## C언어를 이용한 최대 힙(max heap) 삭제 연산\n```c\n// 최대 힙(max heap) 삭제 함수\nelement delete_max_heap(HeapType *h){\n  int parent, child;\n  element item, temp;\n\n  item = h->heap[1]; // 루트 노드 값을 반환하기 위해 item에 할당\n  temp = h->heap[(h->heap_size)--]; // 마지막 노드를 temp에 할당하고 힙 크기를 하나 감소\n  parent = 1;\n  child = 2;\n\n  while(child <= h->heap_size){\n    // 현재 노드의 자식 노드 중 더 큰 자식 노드를 찾는다. (루트 노드의 왼쪽 자식 노드(index: 2)부터 비교 시작)\n    if( (child < h->heap_size) && ((h->heap[child].key) < h->heap[child+1].key) ){\n      child++;\n    }\n    // 더 큰 자식 노드보다 마지막 노드가 크면, while문 중지\n    if( temp.key >= h->heap[child].key ){\n      break;\n    }\n\n    // 더 큰 자식 노드보다 마지막 노드가 작으면, 부모 노드와 더 큰 자식 노드를 교환\n    h->heap[parent] = h->heap[child];\n    // 한 단계 아래로 이동\n    parent = child;\n    child *= 2;\n  }\n\n  // 마지막 노드를 재구성한 위치에 삽입\n  h->heap[parent] = temp;\n  // 최댓값(루트 노드 값)을 반환\n  return item;\n}\n```\n\n## 힙 정렬(heap sort) 알고리즘의 예제 및 c언어 코드\n- 배열에 9, 7, 6, 5, 4, 3, 2, 2, 1, 3이 저장되어 있다고 가정하고 자료를 내림차순으로 정렬\n- 위의 최대 힙(max heap)의 삽입, 삭제 c언어 코드를 참고\n```c\n// 우선순위 큐인 힙을 이용한 정렬\nvoid heap_sort(element a[], int n){\n  int i;\n  HeapType h;\n\n  init(&h);\n\n  for(i=0; i<n; i++){\n    insert_max_heap(&h, a[i]);\n  }\n\n  for(i=(n-1); i>=0; i--){\n    a[i] = delete_max_heap(&h);\n  }\n}\n```\n\n\n\n\n\n# Quick Sort\n## 개념 요약\n- **불안정 정렬**에 속하며, 다른 원소와의 비교만으로 정렬을 수행하는 **비교 정렬**에 속한다.\n- 분할 정복 알고리즘의 하나로, 평균적으로 매우 빠른 수행 속도를 자랑하는 정렬 방법\n  - 합병 정렬(merge sort)과 달리 퀵 정렬은 리스트를 **비균등하게 분할**한다.\n- 분할 정복(divide and conquer) 방법\n  - 문제를 작은 2개의 문제로 분리하고 각각을 해결한 다음, 결과를 모아서 원래의 문제를 해결하는 전략이다.\n  - 분할 정복 방법은 대개 순환 호출을 이용하여 구현한다.\n- 과정\n  - 리스트 안에 있는 한 요소를 선택한다. 이렇게 고른 원소를 **피벗(pivot)** 이라고 한다.\n  - 피벗을 기준으로 피벗보다 작은 요소들은 모두 피벗의 왼쪽으로 옮겨지고 피벗보다 큰 요소들은 모두 피벗의 오른쪽으로 옮겨진다.\n  - 피벗을 제외한 왼쪽 리스트와 오른쪽 리스트를 다시 정렬한다.\n    - 분할된 부분 리스트에 대하여 순환 호출 을 이용하여 정렬을 반복한다.\n    - 부분 리스트에서도 다시 피벗을 정하고 피벗을 기준으로 2개의 부분 리스트로 나누는 과정을 반복한다.\n  - 부분 리스트들이 더 이상 분할이 불가능할 때까지 반복한다.\n    - 리스트의 크기가 0이나 1이 될 때까지 반복한다.  \n![1](https://user-images.githubusercontent.com/108309396/216830122-5e571f0a-5b05-4683-8824-2ce9efc6581f.png)\n\n\n\n## 개념\n- 하나의 리스트를 피벗(pivot)을 기준으로 두 개의 비균등한 크기로 분할하고 분할된 부분 리스트를 정렬한 다음, 두 개의 정렬된 부분 리스트를 합하여 전체가 정렬된 리스트가 되게 하는 방법이다.\n- 퀵 정렬은 다음의 단계들로 이루어진다.\n  - 분할(Divide): 입력 배열을 피벗을 기준으로 비균등하게 2개의 부분 배열(피벗을 중심으로 왼쪽: 피벗보다 작은 요소들, 오른쪽: 피벗보다 큰 요소들)로 분할한다.\n  - 정복(Conquer): 부분 배열을 정렬한다. 부분 배열의 크기가 충분히 작지 않으면 순환 호출 을 이용하여 다시 분할 정복 방법을 적용한다.\n  - 결합(Combine): 정렬된 부분 배열들을 하나의 배열에 합병한다.\n  - 순환 호출이 한번 진행될 때마다 최소한 하나의 원소(피벗)는 최종적으로 위치가 정해지므로, 이 알고리즘은 반드시 끝난다는 것을 보장할 수 있다.  \n![2](https://user-images.githubusercontent.com/108309396/216830123-ab8d6730-ce5a-4b7f-88e2-695c32f6069d.png)\n\n## 퀵 정렬(quick sort) 알고리즘의 특징\n- 장점\n  - 속도가 빠르다.\n    - 시간 복잡도가 $O(nlog_2n)$를 가지는 다른 정렬 알고리즘과 비교했을 때도 가장 빠르다.\n  - 추가 메모리 공간을 필요로 하지 않는다.\n    - 퀵 정렬은 $O(log n)$만큼의 메모리를 필요로 한다.\n- 단점\n  - 정렬된 리스트에 대해서는 퀵 정렬의 불균형 분할에 의해 오히려 수행시간이 더 많이 걸린다.\n- 퀵 정렬의 불균형 분할을 방지하기 위하여 피벗을 선택할 때 더욱 리스트를 균등하게 분할할 수 있는 데이터를 선택한다.\n  - EX) 리스트 내의 몇 개의 데이터 중에서 크기순으로 중간 값(medium)을 피벗으로 선택한다.\n\n## 퀵 정렬(quick sort)의 시간복잡도\n1. 최선의 경우\n- 비교 횟수\n  - ![sort-time-complexity-etc4](https://user-images.githubusercontent.com/108309396/216827667-c328b96c-5800-46e3-9e84-11cadf6bc84a.png)\n  - 순환 호출의 깊이\n    - 레코드의 개수 n이 2의 거듭제곱이라고 가정$(n=2^k)$했을 때, $n=2^3$의 경우, $2^3$&rarr;$2^2$&rarr;$2^1$&rarr;$2^0$ 순으로 줄어들어 순환 호출의 깊이가 3임을 알 수 있다. 이것을 일반화하면 $n=2^k$의 경우, $k=log_2n$임을 알 수 있다.\n    - $k=log_2n$\n  - 각 순환 호출 단계의 비교 연산\n    - 각 순환 호출에서는 전체 리스트의 대부분의 레코드를 비교해야 하므로 평균 n번 정도의 비교가 이루어진다.\n    - 평균 n번\n  - 순환 호출의 깊이 * 각 순환 호출 단계의 비교 연산 = $nlog_2n$\n- 이동 횟수\n  - 비교 횟수보다 적으므로 무시할 수 있다.\n- 최선의 경우 $T(n) = O(nlog₂n)$\n\n2. 최악의 경우\n- 리스트가 계속 불균형하게 나누어지는 경우 (특히, 이미 정렬된 리스트에 대하여 퀵 정렬을 실행하는 경우)\n  - ![sort-time-complexity-etc2](https://user-images.githubusercontent.com/108309396/216861849-405be650-09d1-4eab-9854-f4aff9734d45.png)\n- 비교 횟수\n  - 순환 호출의 깊이\n    - 레코드의 개수 n이 2의 거듭제곱이라고 가정$(n=2^k)$했을 때, 순환 호출의 깊이는 $n$임을 알 수 있다.\n    - $n$\n  - 각 순환 호출 단계의 비교 연산\n    - 각 순환 호출에서는 전체 리스트의 대부분의 레코드를 비교해야 하므로 평균 $n$번 정도의 비교가 이루어진다.\n    - 평균 $n$번\n    - 순환 호출의 깊이 * 각 순환 호출 단계의 비교 연산 = $n^2$\n  - 이동 횟수\n    - 비교 횟수보다 적으므로 무시할 수 있다.\n- 최악의 경우 $T(n) = O(n^2)$\n\n1. 평균\n- 평균 $T(n) = O(nlog_2n)$\n- 시간 복잡도가 $O(nlog_2n)$를 가지는 다른 정렬 알고리즘과 비교했을 때도 가장 빠르다.\n- 퀵 정렬이 불필요한 데이터의 이동을 줄이고 먼 거리의 데이터를 교환할 뿐만 아니라, 한 번 결정된 피벗들이 추후 연산에서 제외되는 특성 때문이다.\n\n\n## 퀵 정렬(quick sort) 알고리즘의 예제\n- 배열에 5, 3, 8, 4, 9, 1, 6, 2, 7이 저장되어 있다고 가정하고 자료를 오름차순으로 정렬\n- 퀵 정렬에서 피벗을 기준으로 두 개의 리스트로 나누는 과정(c언어 코드의 partition 함수의 내용)  \n![3](https://user-images.githubusercontent.com/108309396/216830124-68a7d2bc-0031-4588-a0eb-0c7413b53582.png)\n\n- 피벗 값을 입력 리스트의 첫 번째 데이터로 하자. (다른 임의의 값이어도 상관없다.)\n- 2개의 인덱스 변수(low, high)를 이용해서 리스트를 두 개의 부분 리스트로 나눈다.\n- 1회전: 피벗이 5인 경우,\n  - low는 왼쪽에서 오른쪽으로 탐색해가다가 피벗보다 큰 데이터(8)을 찾으면 멈춘다.\n  - high는 오른쪽에서 왼쪽으로 탐색해가다가 피벗보다 작은 데이터(2)를 찾으면 멈춘다.\n  - low와 high가 가리키는 두 데이터를 서로 교환한다.\n  - 이 탐색-교환 과정은 low와 high가 엇갈릴 때까지 반복한다.\n- 2회전: 피벗(1회전의 왼쪽 부분리스트의 첫 번째 데이터)이 1인 경우,\n  - 위와 동일한 방법으로 반복한다.\n- 3회전: 피벗(1회전의 오른쪽 부분리스트의 첫 번째 데이터)이 9인 경우,\n  - 위와 동일한 방법으로 반복한다.\n\n\n## 퀵 정렬(quick sort) c언어 코드\n```c\n# include <stdio.h>\n# define MAX_SIZE 9\n# define SWAP(x, y, temp) ( (temp)=(x), (x)=(y), (y)=(temp) )\n\n// 1. 피벗을 기준으로 2개의 부분 리스트로 나눈다.\n// 2. 피벗보다 작은 값은 모두 왼쪽 부분 리스트로, 큰 값은 오른쪽 부분 리스트로 옮긴다.\n/* 2개의 비균등 배열 list[left...pivot-1]와 list[pivot+1...right]의 합병 과정 */\n/* (실제로 숫자들이 정렬되는 과정) */\nint partition(int list[], int left, int right){\n  int pivot, temp;\n  int low, high;\n\n  low = left;\n  high = right + 1;\n  pivot = list[left]; // 정렬할 리스트의 가장 왼쪽 데이터를 피벗으로 선택(임의의 값을 피벗으로 선택)\n\n  /* low와 high가 교차할 때까지 반복(low<high) */\n  do{\n    /* list[low]가 피벗보다 작으면 계속 low를 증가 */\n    do {\n      low++; // low는 left+1 에서 시작\n    } while (low<=right && list[low]<pivot);\n\n    /* list[high]가 피벗보다 크면 계속 high를 감소 */\n    do {\n      high--; //high는 right 에서 시작\n    } while (high>=left && list[high]>pivot);\n\n    // 만약 low와 high가 교차하지 않았으면 list[low]를 list[high] 교환\n    if(low<high){\n      SWAP(list[low], list[high], temp);\n    }\n  } while (low<high);\n\n  // low와 high가 교차했으면 반복문을 빠져나와 list[left]와 list[high]를 교환\n  SWAP(list[left], list[high], temp);\n\n  // 피벗의 위치인 high를 반환\n  return high;\n}\n\n// 퀵 정렬\nvoid quick_sort(int list[], int left, int right){\n\n  /* 정렬할 범위가 2개 이상의 데이터이면(리스트의 크기가 0이나 1이 아니면) */\n  if(left<right){\n    // partition 함수를 호출하여 피벗을 기준으로 리스트를 비균등 분할 -분할(Divide)\n    int q = partition(list, left, right); // q: 피벗의 위치\n\n    // 피벗은 제외한 2개의 부분 리스트를 대상으로 순환 호출\n    quick_sort(list, left, q-1); // (left ~ 피벗 바로 앞) 앞쪽 부분 리스트 정렬 -정복(Conquer)\n    quick_sort(list, q+1, right); // (피벗 바로 뒤 ~ right) 뒤쪽 부분 리스트 정렬 -정복(Conquer)\n  }\n\n}\n\nvoid main(){\n  int i;\n  int n = MAX_SIZE;\n  int list[n] = {5, 3, 8, 4, 9, 1, 6, 2, 7};\n\n  // 퀵 정렬 수행(left: 배열의 시작 = 0, right: 배열의 끝 = 8)\n  quick_sort(list, 0, n-1);\n\n  // 정렬 결과 출력\n  for(i=0; i<n; i++){\n    printf(\"%d\\n\", list[i]);\n  }\n}\n```\n\n# Tree Sort\n## 개념\n- Binary Search Tree를 만들어 정렬하는 방식.\n- Heap Sort와 비슷해보이지만 정렬될 자료의 각 원소의 크기에 따라 부모노드의 왼쪽 자식이 되느냐, 오른쪽 자식이 되느냐가 다르다.\n- 과정\n  1. 정렬될 배열의 맨 첫 값이 루트 노드가 된다.\n  2. 다음 값부터는 기존 노드 값과 비교한다. 루트 노드에서 출발해서 추가될 노드 값이 기존 노드 값보다 작은 경우는 왼쪽 자식을, 기존 노드 값보다 크거나 같을 경우는 오른쪽 자식을 찾는다. 내림차순은 반대로 기존 노드 값보다 크면 왼쪽, 작거나 같으면 오른쪽을 찾으면 된다.\n  3. 위 2에서 해당 방향의 자식 노드가 없으면 그 방향의 자식 노드로 추가한다. 있으면 그 방향의 자식 노드로 가서 크기를 비교하고 위 2와 같은 방법으로 해당 방향의 자식 노드가 있으면 계속 그 방향으로 가서 조사하고 없으면 그 방향의 자식 노드로 추가한다.\n  4. 모든 값이 노드로 추가되었으면 해당 트리를 **중위 순회 방식**(왼쪽자식-루트-오른쪽자식)으로 순회하여 그 순서대로 값을 정렬해 나간다.  \n  ![캡처](https://user-images.githubusercontent.com/108309396/216869488-3440eb75-4ffc-4c37-bf1b-7f89f258bb82.PNG)\n\n## Tree Sort의 특징\n- 피벗을 기반으로 요소를 재귀적으로 분할한다는 점에서 퀵 정렬과 동일하지만, 퀵 정렬은 in-place 제자리 정렬이고 overhead가 적기 때문에 퀵 정렬에 비해 이점이 없다. \n- self-balancing tree를 사용하면 worst case에서의 시간복잡도가 더 낫지만 overhead는 더 크다.\n\n## 시간복잡도\n- Worst case: $O(n^2)$ (unbalanced)\n- Bese case: $O(nlogn)$ (balanced)\n- Average performance: $O(nlogn)$\n\n# 정렬 알고리즘 시간복잡도 비교\n- 단순(구현 간단)하지만 비효율적인 방법\n  - 삽입 정렬, 선택 정렬, 버블 정렬\n- 복잡하지만 효율적인 방법\n  - 퀵 정렬, 힙 정렬, 합병 정렬, 기수 정렬  \n![sort-time-complexity5](https://user-images.githubusercontent.com/108309396/216828072-770c8dcb-8bba-4cab-91e1-814667fd481e.png)','Merge Sort 개념 요약   안정 정렬 에 속하며, 분할 정복 알고리즘의 하나이다.  분할 정복(divide and conquer) 방법   문제를 작은 2개의 문제로 분리하고 각각을 해결한 다음, 결과를 모아서 원래의 문제를 해결하는 전략이다.  분할 정복 방법은 대개 순환 호출을 이용하여 구현한다.  과정   리스트의 길이가 0 또는 1이면 이미 정렬된 것으로 본다.  그렇지 않은 경우에는 정렬되지 않은 리스트를 절반으로 잘라 비슷한 크기의 두 부분 리스트로 나눈다.  각 부분 리스트를 재귀적으로 합병 정렬을 이용해 정렬한다.  두 부분 리스트를 다시 하나의 정렬된 리스트로 합병한다.    P) 안정정렬이란?**    배열을 정렬했을 때, 동일한 값의 원소 사이의 위치 관계가 변하지 않는 정렬입니다','sort(2)'),(_binary '','2023-11-15 02:09:41.514495',25,74,'2023-11-15 02:34:10.742698',1,'## 투포인터\n- 리스트에 순차적으로 접근해야 할 경우, 두 개의 점(포인터)의 위치를 기록하면서 처리하는 알고리즘\n- 말 그대로 두 가지 포인터를 사용하여 문자열이나 배열에서 원하는 값을 찾거나 반복문을 써야 할 때 쓰기 좋은 방식\n![1](https://user-images.githubusercontent.com/78436899/215311381-88dcfbc1-2eff-4888-8f6b-58c4d4bfaf74.png)\n\n## 투포인터의 대표 예제\n### < 특정한 합을 가지는 부분 연속 수열 찾기 >\n**<예시 문제>**\n\n- **아래 리스트에서 연속되는 값들을 더해 그 합이 5가 되는 경우의 수는 몇가지인가**\n    \n(숫자 리스트가 주어질 때, 리스트의 연속 수열의 합이 특정 값을 가지는 것을 확인하는 문제)\n![2](https://user-images.githubusercontent.com/78436899/215311400-afd59136-41fc-4866-858f-fcca214ebad3.png)\n<결과>\n![3](https://user-images.githubusercontent.com/78436899/215311415-c26e3e2d-8b9f-4494-a3ff-ec8680fb77bf.png)\n- N 개의 자연수로 구성된 수열이 있다.\n- 합이 M인 부분 연속 수열의 개수를 구해라\n\nN = 5\n\nM = 5\n\n결과 : 5개의 데이터가 있을 때, 부분 합이  5인 부분 연속 수열은 3가지 경우가 존재\n\n\n**특정한 합의 부분 연속 수열의 개수를 구하고 싶을 때, 어떠한 방법을 사용할까 ?**\n\n\n\n- **<완전 탐색>**\n    \n    ⇒ 완전탐색을 진행하면 n**2 만큼의 시간이 걸린다\n    \n- **<투포인터>**\n    \n    ⇒ 그래서 우리는 투포인터를 이용해 문제를 해결할 것이다\n    \n    \n<풀이 과정>\n![4](https://user-images.githubusercontent.com/78436899/215311430-a401a9af-e354-443d-a0f4-b5c801593100.jpg)\n위의 과정을 반복하면, 아래의 결과을 도출 할 수 있다\n![5](https://user-images.githubusercontent.com/78436899/215311440-5fc7b4d5-bc6f-4799-b5ea-a733feb1ceec.png)\n\n\n<문제 코드>\n특정 합을 가지는 부분 연속 수열 찾기 코드\n\n\n```python\nn = 5\nm = 5\ndata = [1,2,3,2,5]\n\ncount = 0\ninterval_sum = 0\nend = 0\n\n# start를 차례대로 증가시키며 반복\nfor start in range(n):\n	# end를 가능한 만큼 이동시키기\n	while interval_sum < m and end < n :\n		interval_sum += data[end]\n		end += 1\n	# 부분합이 m일 때 카운트 증가\n	if interval_sum == m:\n		count += 1\n	interval_sum -= data[start]\n\nprint(count)\n```\n\n### [관련강의](https://www.youtube.com/watch?v=ttLRltNDiCo)','투포인터   리스트에 순차적으로 접근해야 할 경우, 두 개의 점(포인터)의 위치를 기록하면서 처리하는 알고리즘  말 그대로 두 가지 포인터를 사용하여 문자열이나 배열에서 원하는 값을 찾거나 반복문을 써야 할 때 쓰기 좋은 방식 1  투포인터의 대표 예제 < 특정한 합을 가지는 부분 연속 수열 찾기 > <예시 문제>    아래 리스트에서 연속되는 값들을 더해 그 합이 5가 되는 경우의 수는 몇가지인가  (숫자 리스트가 주어질 때, 리스트의 연속 수열의 합이 특정 값을 가지는 것을 확인하는 문제) 2 <결과> 3 - N 개의 자연수로 구성된 수열이 있다. - 합이 M인 부분 연속 수열의 개수를 구해라  N = 5  M = 5  결과 : 5개의 데이터가 있을 때, 부분 합이  5인 부분 연속 수열은 3가지 경우가','two_pointer'),(_binary '','2023-11-15 02:10:57.659943',26,75,'2023-11-15 02:34:18.332078',1,'# Binary Tree\n\n- 개념 요약\n    - 각각의 노드가 최대 두 개의 자식 노드를 가지는 트리(그림을 뒤집었을 때 트리모양) 자료구조\n- 트리(Tree) 개념 상세\n    \n    ![Untitled](https://user-images.githubusercontent.com/90077061/216817120-6fcbc56b-1756-43a8-8765-6d26f6b5549e.png)\n    \n    - 검정색 동그라미 : 노드(node), 여기에 데이터가 담김.\n    - 노드와 노드 사이를 이어주는 선을 엣지(edge)라고 함.\n    - 경로(path)란 엣지로 연결된, 즉 인접한 노드들로 이뤄진 시퀀스(sequence)를 가리킴.\n    - 트리의 높이(height)는 루트노드에서 말단노드에 이르는 가장 긴 경로의 엣지 수\n    - 잎새노드(leaf node) 또는 말단노드 : 자식노드가 없는 노드\n    - internal node : 잎새노드를 제외한 노드\n    - root node : 부모노드가 없는 노드\n- 특성\n    - 임의의 노드에서 다른 노드로 가는 경로는 유일하다\n    - 회로가 존재하지 않는다\n    - 모든 노드는 서로 연결되어있다\n    - 엣지를 하나 자르면 트리가 두 개로 분리된다\n    - 엣지의 수는 노드의 수에서 1을 뺀 것과 같다\n- 종류\n    - 정 이진트리(Full Binary Tree)\n        - 모든 노드가 0개, 혹은 2개의 자식노드를 가지는 트리.   \n       ![image](https://user-images.githubusercontent.com/74289372/218610388-472968f4-fbd0-48e1-b1f0-aeabbff878e3.png)\n\n\n\n\n    - 포화 이진트리(Perfect Binary Tree)\n        - 모든 레벨에서 노드들이 꽉 채워진(잎새노드를 제외한 모든 노드가 2개의 자식노드를 가짐) 트리\n        \n        ![Untitled 1](https://user-images.githubusercontent.com/90077061/216817131-7a1b5452-38f2-46b9-9136-d0ab2cc47ca1.png)\n        \n        - 레벨(k)에 따른 노드의 숫자 : $2^k$\n    - 완전 이진트리(Complete Binary Tree)\n        - 마지막 레벨을 제외한 모든 레벨이서 노드들이 꽉 채워진 이진트리\n        \n        ![Untitled 2](https://user-images.githubusercontent.com/90077061/216817140-0525c485-004d-4a20-ab78-e8773cbf9876.png)\n        \n    정이진트리와 완전이진트리는 다음처럼 1차원 배열(array)로도 표현이 가능\n    \n    ![Untitled 3](https://user-images.githubusercontent.com/90077061/216817144-8a767e99-3e82-419a-97ec-7ec7174cd874.png)\n    \n    ```python\n    left_index = index * 2\n    right_index = index * 2 + 1\n    ```\n    \n- 트리 순회\n    - 트리의 각 노드를 체계적인 방법으로 방문하는 과정\n    \n    ![Untitled 4](https://user-images.githubusercontent.com/90077061/216817167-07bb6990-9aa3-4d82-b7c4-caab1755a2bc.png)\n    \n    - 전위 순회(preorder)\n        - 1, 2, 4, 5, 3\n    - 중위 순회(inorder)\n        - 4, 2, 5, 1, 3\n    - 후위 순회(postorder)\n        - 4, 5, 2, 3, 1\n\n# Heap\n\n- 개념 요약\n    - 완전 이진트리의 일종으로, 우선순위 큐를 위하여 만들어진 자료\n    - 여러 개의 값들 중에서 최댓값이나 최솟값을 빠르게 찾아내도록 만들어진 자료구조\n    - 힙은 일종의 반정렬 상태를 유지\n        - 큰 값이 상위 레벨에 있고, 작은 값이 하위 레벨에 있다는 정도\n        - 간단히 말하면 **부모 노드의 키 값이 자식 노드의 키 값보다 항상 큰(작은) 이진 트리**\n    - 힙 트리에서는 중복값 허용(이진 탐색 트리에서는 중복값 허용X\n- 힙의 종류\n    \n    ![Untitled 5](https://user-images.githubusercontent.com/90077061/216817179-f1ee37bb-2653-4272-8e0f-500d916d65ea.png)\n\n    - 최대 힙(Max Heap)\n        - 부모 노드의 키 값이 자식 노드의 키 값보다 크거나 같은 완전 이진 트리\n    - 최소 힙(Min Heap)\n        - 부모 노드의 키 값이 자식 노드의 키 값보다 작거나 같은 완전 이진 트리\n- 구현\n    - 힙을 저장하는 표준적인 자료구조는 **배열**\n    - 배열의 첫 번째 인덱스인 0은 사용 X\n    - 특정 위치의 노드 번호는 새로운 노드가 추가되어도 변하지 않음\n        - (루트 노드의 오른쪽 노드의 번호는 항상 3)\n    - 힙에서의 부모 노드와 자식 노드의 관계\n        - 왼쪽 자식의 인덱스 = (부모 인덱스) * 2\n        - 오른쪽 자식의 인덱스 = (부모 인덱스) * 2 + 1\n        - 부모 인덱스 = (자식 인덱스) / 2\n    \n    ```python\n    import heapq\n    \n    heap = []\n    \n    heapq.heappush(heap, 10)\n    heapq.heappush(heap, 6)\n    heapq.heappush(heap, 13)\n    heapq.heappush(heap, 5)\n    \n    print(heap) # [5, 6, 10, 13]\n    \n    print(heapq.heappop(heap))  # 5\n    print(heap) # [6, 10, 13]\n    \n    # heapify\n    x = [4, 3, 1, 2, 5, 6]\n    print(x) # [4, 3, 1, 2, 5, 6]\n    heapq.heapify(x)\n    print(x) # [1, 2, 4, 3, 5, 6]\n    ```\n    \n- 저장 과정\n    \n    ![Untitled 6](https://user-images.githubusercontent.com/90077061/216817184-dc810d77-1d03-46eb-8df9-aec7f777b7b2.png)\n    \n- 삭제 과정(heapify)\n    \n    ![Untitled 7](https://user-images.githubusercontent.com/90077061/216817198-575a16ef-b7cd-491f-8c6d-d448e0f42671.png)\n    \n# Priority Queue\n\n- 개념 요약\n    - 우선순위의 개념을 큐에 도입한 자료 구조\n    - 데이터들이 우선순위를 가지고 있고, 우선순위가 높은 데이터가 먼저 나간다\n        \n        \n        | 자료구조 | 삭제되는 요소 |\n        | --- | --- |\n        | 스택(Stack) | 가장 최근에 들어온 데이터 |\n        | 큐(Queue) | 가장 먼저 들어온 데이터 |\n        | 우선순위 큐(Priority Queue) | 가장 우선순위가 높은 데이터 |\n- 연산(python)\n    - put : 맨 끝 위치에 값을 저장\n        - 부모 노드와 비교하며, 조건을 만족하는지 확인\n            - 만족하지 않는다면, 서로 위치를 변경(Heap - 저장 과정 참조)\n    - pop : 가장 우선순위가 높은 값을 삭제\n        - 맨 끝의 노드를 비어있는 루트 노드로 끌어옴\n        - 루트 노드의 자식 노드들과 값을 비교, 위치 변경\n            - 위치를 만족할 때 까지 자식 노드와 위치를 변경하며 올바른 위치까지 이동\n- 구현\n    - 일반적으로 배열 사용 - 완전 이진 트리 이므로 중간에 비어있는 요소가 없기 때문\n    \n    ```python\n    from queue import PriorityQueue\n    \n    q = PriorityQueue()\n    q1 = PriorityQueue(maxsize=10)  # maxsize를 활용하여 크기 제한 가능\n    \n    # put\n    q.put(3)\n    q.put(4)\n    q.put(1)\n    \n    q1.put((1, \'apple\'))    # (우선순위, 값)의 형태로 저장 할 수도 있음\n    \n    # get\n    print(q.get())  # 1\n    \n    # (우선순위, 값)의 형태에서 값 반환\n    print(q1.get()[1]) # apple\n    ```\n    \n\n# Indexed Tree\n\n- 개념 요약\n    - 포화 이진 트리 형태의 자료구조\n    - 잎새 노드(리프 노드)는 배열에 적혀 있는 수를 의미\n    - 내부 노드는 왼쪽 자식과 오른쪽 자식의 합을 이야기한다\n- 사용 용도\n    - 부분합(또는 구간 Max값)을 계속해서 구해야 할 때\n    - 특정 인덱스의 변경 또한 계속 일어날 수 있을 때\n- 예제\n    - [8, 3, 26, 1, 7, 2, 4, 10] 이라는 숫자들 중 3-5인덱스의 합을 구하려는 상황\n        \n        ![Untitled 8](https://user-images.githubusercontent.com/90077061/216817210-5fe57469-a928-4af1-9ed5-4da57205203d.png)\n        \n    - 필요한 구간 노드까지만 탐색해서 최종합을 반환\n- 코드 구현\n\n# Segment Tree\n\n- 개념 요약\n    - 여러 개의 데이터가 존재할 때 특정 구간의 합(최솟값, 최댓값, 곱 등)을 구하는데 사용하는 자료구조\n    - 트리 종류 중 하나로 이진 트리의 형태, 특정 구간의 합을 가장 빠르게 구할 수 있음\n- 예제\n    - [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]의 구간 합 구하기\n    \n    ```python\n    arr = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n    \n    # arr 크기보다 큰 가장 가까운 N의 제곱수를 구하고, 그 값의 2배에 해당하는 값을 크기로 선언\n    # N이 10으로 가장 가까운 제곱수는 4^2=16으로 16*2=32개의 크기가 필요\n    tree = [0] * (len(arr) * 4)\n    ```\n    \n    - 트리 초기화\n    \n    ![Untitled 9](https://user-images.githubusercontent.com/90077061/216817220-e751bc0d-633f-462c-ab21-e8d90dc3dfeb.png)\n    \n    `보통 리스트의 인덱스는 0번부터 시작하는데, 세그먼트 트리는 1번부터 시작하는지 의문이 생길 수 있다. 세그먼트 트리의 인덱스가 1번부터 시작하는 이유는 재귀적으로 편하게 세그먼트 트리를 생성하기 위해서이다. 1부터 시작하게 되면 2를 곱했을 때는 왼쪽 자식 노드를 가리키고, 2를 곱하고 1을 더하면 오른쪽 자식 노드를 가리키게 되어 효과적임`\n    \n    ```python\n    # <세그먼트 트리를 배열의 각 구간 합으로 채워주기>\n    # start : 배열의 시작 인덱스, end : 배열의 마지막 인덱스\n    # index : 세그먼트 트리의 인덱스 (무조건 1부터 시작)\n    def init(start, end, index):\n        # 가장 끝에 도달했으면 arr 삽입\n        if start == end:\n            tree[index] = arr[start]\n            return tree[index]\n        mid = (start + end) // 2\n        # 좌측 노드와 우측 노드를 채워주면서 부모 노드의 값도 채워준다.\n        tree[index] = init(start, mid, index * 2) + init(mid + 1, end, index * 2 + 1)\n        return tree[index]\n    \n    init(0, 9, 1)\n    \n    print(tree)\n    # [0, 55, 15, 40, 6, 9, 21, 19, 3, 3, 4, 5, 13, 8, 9, 10, 1, 2, 0, 0, 0, 0, 0, 0, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n    ```\n    \n    - 트리 구간 합 구하기\n    \n    ![Untitled 10](https://user-images.githubusercontent.com/90077061/216817240-f6471dc5-83b7-42be-be48-7f82cf803b3c.png)\n    \n    `6-9 범위의 구간합을 구한다고 가정 시 그림처럼 3개의 빨간색 노드의 합만 구해주면 된다.`\n    \n    ```python\n    # <구간 합을 구하는 함수>\n    # start : 시작 인덱스, end : 마지막 인덱스\n    # left, right : 구간 합을 구하고자 하는 범위\n    def interval_sum(start, end, index, left, right):\n        # 범위 밖에 있는 경우\n        if left > end or right < start:\n            return 0\n        # 범위 안에 있는 경우\n        if left <= start and right >= end:\n            return tree[index]\n        # 그렇지 않다면 두 부분으로 나누어 합을 구하기\n        mid = (start + end) // 2\n        # start와 end가 변하면서 구간 합인 부분을 더해준다고 생각하면 된다.\n        return interval_sum(start, mid, index * 2, left, right) + interval_sum(mid + 1, end, index * 2 + 1, left, right)\n    \n    print(interval_sum(0, 9, 1, 6, 9))\n    # 34\n    ```\n    \n    - 원소 값 수정\n    \n    ![Untitled 11](https://user-images.githubusercontent.com/90077061/216817251-410979a7-2676-4835-a576-b2579c3c23ab.png)\n    \n    `특정 원소의 값을 수정할 때는 **해당 원소를 포함하고 있는 모든 구간 합 노드들을 갱신**\n    해주면 됨. 즉, 세그먼트 트리의 모든 노드를 변경하는 것이 아닌 해당 원소를 포함하고 있는 부분적인 노드들만 바꿔주면 되는 것`\n    \n    `예를들어 인덱스 6의 arr값을 수정한다고 가정 시 5개의 구간 합 노드를 모두 수정`\n    \n    ```python\n    # <특정 원소의 값을 수정하는 함수>\n    # start : 시작 인덱스, end : 마지막 인덱스\n    # what : 구간 합을 수정하고자 하는 노드\n    # value : 수정할 값\n    def update(start, end, index, what, value):\n        # 범위 밖에 있는 경우\n        if what < start or what > end:\n            return\n        # 범위 안에 있으면 내려가면서 다른 원소도 갱신\n        tree[index] += value\n        if start == end:\n            return\n        mid = (start + end) // 2\n        update(start, mid, index * 2, what, value)\n        update(mid + 1, end, index * 2 + 1, what, value)\n    \n    print(tree)\n    # [0, 55, 15, 40, 6, 9, 21, 19, 3, 3, 4, 5, 13, 8, 9, 10, 1, 2, 0, 0, 0, 0, 0, 0, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n    update(0, 9, 1, 6, 10)\n    print(tree)\n    # [0, 65, 15, 50, 6, 9, 31, 19, 3, 3, 4, 5, 23, 8, 9, 10, 1, 2, 0, 0, 0, 0, 0, 0, 6, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n    ```\n    \n\n## Segment Tree와 Indexed Tree 차이점\n\n- Segment Tree\n    - 세그먼트 트리는 어떤 배열이 주어졌을 때, 각 구간의 대푯값을 빠르게 구할 수 있는 자료구조\n    - 배열의 크기가 N일 때, 임의의 구간에 대한 쿼리를 O(logN)에 수행 가능\n    - 필요한 리프노드만 채움, 불완전 트리라서 특정 인덱스(node)로 지정 탐색이 어려움.\n    - 업데이트도 지정 업데이트가 불가능(루트노드부터 업데이트 필요)\n- Indexed Tree\n    - 팬윅 트리라고도 하며, 세그먼트 트리처럼 각 구간의 대푯값을 따르게 구할 수 있다\n    - 세그먼트 트리보다 구현이 간단하고 속도가 빠르다\n    - 리프노드를 모두 채워서 만듦,  특정 인덱스(node)로 지정 탐색이 가능.\n    - 업데이트도 지정 업데이트 가능(리프노드부터 업데이트 가능)\n    \n    **⇒ 문제에서 인덱스가 주어지는 경우 인덱스 트리를 사용하는 것이 용이**\n    \n    **⇒ 구간 업데이트가 빈번한 경우 세그먼트 트리를 사용하는 것이 용이**','Binary Tree   개념 요약   각각의 노드가 최대 두 개의 자식 노드를 가지는 트리(그림을 뒤집었을 때 트리모양) 자료구조  트리(Tree) 개념 상세  Untitled    검정색 동그라미 : 노드(node), 여기에 데이터가 담김.  노드와 노드 사이를 이어주는 선을 엣지(edge)라고 함.  경로(path)란 엣지로 연결된, 즉 인접한 노드들로 이뤄진 시퀀스(sequence)를 가리킴.  트리의 높이(height)는 루트노드에서 말단노드에 이르는 가장 긴 경로의 엣지 수  잎새노드(leaf node) 또는 말단노드 : 자식노드가 없는 노드  internal node : 잎새노드를 제외한 노드  root node : 부모노드가 없는 노드  특성   임의의 노드에서 다른 노드로 가는 경로는 유일하','non_linear'),(_binary '','2023-11-15 02:11:15.946104',26,76,'2023-11-15 02:34:13.996047',1,'# Graph\n\n그래프는 정점(Vertex)과 간선(Edge)로 이루어진 자료구조이다.\n\n\n- 그래프 용어\n\n<center>\n\n|명칭 | 내용|\n|---|---|\n|정점(Vertex)|노드(node) 라고도 하며 정점에는 데이터가 저장된다.|\n|간선(Edge)|정점(노드)를 연결하는 선으로 link, branch 라고도 부른다.|\n|인접 정점(adjacent Vertex)|간선에 의해 직접 연결된 정점|\n|단순 경로(simple path)|경로 중에서 반복되는 정점이 없는 경우.|\n|차수(degree)|무방향 그래프에서 하나의 정점에 인접한 정점의 수|\n|진출 차수(in-degree)|방향 그래프에서 외부로 향하는 간선의 수|\n|진입 차수(out-degree)|방향 그래프에서 외부에서 들어오는 간선의 수|\n|경로 길이(path length)|경로를 구성하는데 사용된 간선의 수|\n|사이클(cycle)|단순 경로의 시작 정점과 종료 정점이 동일한 경우|\n</center> \n\n- 그래프 종류\n\n간선 방향의 유무, 간선 가중치의 유무, 사이클의 유무, 단절 여부에 따라 다양하게 구분할 수 있다. 모든 정점이 연결되어 있는 경우 완전 그래프라고 부른다. \n\n![](./src/graph.png)\n\n\n앞서 다룬 트리 자료구조는 그래프의 일종이라고 할 수 있다.\n\n![](./src/graph-vs-tree.png)\n\n\n\n\n\n\n- 구현 \n\n구현은 인접 리스트(Adjacency List), 인접 행렬(Adjacency Matrix)2가지로 할 수 있다. \n\n1. 인접 리스트\n![](./src/ad_list.png)\n\n    각 정점에 대해 연결된 정점을 인접 리스트로 만들고, 이 인접리스트를 리스트로 표현. 연결된 정점만 기록한다는 특징이 있다.\n\n    - 메모리 낭비가 적다.\n    - 인접 노드 순회가 용이하다.\n    - 간선 정보 확인시 O(N = 간선 수)  -> 불필요한 탐색시간 발생가능.\n    \n- 간선이 적으면 유리하다.\n\n<br><br>\n\n2. 인접 행렬\n![](./src/ad_Matrix.png)\n\n    2차원 배열로 그래프를 표현한다. matrix[i][j]는 i, j의 연결 여부(0/1)나, 가중치로 표현 가능하다. \n\n    - 간선 정보 확인이 매우 용이하다. O(1)\n    - 메모리가 필요 이상으로 사용 될 수 있다.\n    - 생성시 오래 걸린다.\n- 간선이 Dense하게 주어질 때 용이하다.\n\n---\n- 예제 코드\n\n```python\nn = 4\ne = 5\nnodes = [[2, 1], [2, 4], [1, 4], [2, 3], [3, 4]]\n\n#인접 리스트\nadj_list = [[] for _ in range(n)]\nfor src, dst in nodes:\n    adj_list[src-1].append(dst-1)\n    adj_list[dst-1].append(src-1)\n\n#인접 행렬\nadj_matrix = [[0 for _ in range(n)] for _ in range(n)]\nfor src, dst in nodes:\n    adj_matrix[src-1][dst-1] = 1\n    adj_matrix[dst-1][src-1] = 1\n\n```','Graph 그래프는 정점(Vertex)과 간선(Edge)로 이루어진 자료구조이다.    그래프 용어   명칭  내용 정점(Vertex)노드(node) 라고도 하며 정점에는 데이터가 저장된다. 간선(Edge)정점(노드)를 연결하는 선으로 link, branch 라고도 부른다. 인접 정점(adjacent Vertex)간선에 의해 직접 연결된 정점 단순 경로(simple path)경로 중에서 반복되는 정점이 없는 경우. 차수(degree)무방향 그래프에서 하나의 정점에 인접한 정점의 수 진출 차수(in-degree)방향 그래프에서 외부로 향하는 간선의 수 진입 차수(out-degree)방향 그래프에서 외부에서 들어오는 간선의 수 경로 길이(path length)경로를 구성하는데 사용된 간선의 수 사이클(cycle','graph'),(_binary '','2023-11-15 02:11:31.257909',26,77,'2023-11-15 02:34:23.603129',1,'# Trie\n\n![](./src/Trie_example.png)\n\n\n트라이(Trie)는 트리 자료구조 중 하나로, Digital Tree, Retrieval Tree, Prefix Tree 라고 불린다. 문자열을 저장하고 탐색하기 용이한 구조로 특징은 다음과 같다.\n\n- Binary Tree와 달리 여러 갈래로 나뉘는 M-way tree이다. \n\n- 문자열(단어)의 각 문자가 노드가 되며, 접두어를 공유할 수 있다.\n\n    - ex) hello 와 hey는 he 노드를 공유한다.\n<br><br>\n\n- 문자열의 길이를 L, 문자열의 개수를 N이라고 하면 다음과 같은 복잡도는 가진다. \n\n<center>\n\n|연산|시간 복잡도|공간 복잡도|\n|------|---|---|\n|삽입|O(L)|O(N*L)|\n|탐색|O(L)|O(1)|\n</center> \n\n---\n- 예제 코드\n\n```python\nclass Trie:\n    head = {}\n    def add(self, word):        \n        cur = self.head\n        for ch in word:         \n            if ch not in cur:\n                cur[ch] = {}\n            cur = cur[ch]\n        cur[\'*\'] = True\n    \n    def search(self, word):\n        cur = self.head\n\n        for ch in word:\n            if ch not in cur:\n                return False\n            cur = cur[ch]\n        if \'*\' in cur:\n            return True\n        else:\n            return False\ntr1 = Trie()\ntr1.add(\"affa\")\ntr1.add(\"af\")\nprint(tr1.search(\"af\"))\n```\n\n\n```python\nclass Node:\n   def __init__(self):\n       self.children = {}  \n       self.value = None\n\ndef find(node, key):\n  for char in key:\n    if char in node.children:\n      node = node.children[char]\n    else:\n      return None\n  return node.value\n\ndef insert(node, key, value) -> None:\n    for char in key:\n        if char not in node.children:\n            node.children[char] = Node()\n        node = node.children[char]\n    node.value = value\n\ntr2 = Node()\ng = 1\ninsert(tr2, \"asd\", 4264)\nprint(find(tr2, \"asd\"))\n```','Trie   트라이(Trie)는 트리 자료구조 중 하나로, Digital Tree, Retrieval Tree, Prefix Tree 라고 불린다. 문자열을 저장하고 탐색하기 용이한 구조로 특징은 다음과 같다.    Binary Tree와 달리 여러 갈래로 나뉘는 M-way tree이다.   문자열(단어)의 각 문자가 노드가 되며, 접두어를 공유할 수 있다.    ex) hello 와 hey는 he 노드를 공유한다.    문자열의 길이를 L, 문자열의 개수를 N이라고 하면 다음과 같은 복잡도는 가진다.   연산시간 복잡도공간 복잡도 삽입O(L)O(N*L) 탐색O(L)O(1)      예제 코드  class Trie:     head = {}     def add(self, word):             ','trie'),(_binary '','2023-11-15 02:11:57.945061',26,79,'2023-11-15 02:34:16.283223',1,'# 선형 자료구조\n\n생성일: 2023년 1월 30일 오전 8:01\n작성자: 석철신\n태그: Array, LinkedList, Queue, Stack\n\n### 자료구조\n\n자료구조는 대량의 데이터를 효율적으로 관리할 수 있는 데이터 구조를 의미\n\n대표적인 자료구조에는 **배열, 스택, 큐, 연결리스트, 해쉬 테이블, 힙** 등\n\n**많은 자료구조를 알아두면, 특정 문제를 해결하는 데에 가장 적합한 자료구조를 빠르게 찾아 데이터를 정리하고 활용하여 문제를 빠르고 정확하게 해결할 수 있다.**\n\n![Untitled](./src/Untitled.png)\n\n### 배열\n\n같은 종류의 데이터를 효율적으로 관리하기 위해 사용하는 개념\n\n같은 타입의 데이터를 연속된 공간에 나열하고 index를 부여\n\n- 학교나 반을 배정 받고 학번을 배정 받는 것 역시 배열과 비슷한 개념\n- 회사에서는 부서를 배정 받고 사번을 받는다\n\n파이썬의 배열은 리스트 , 튜플과 같은 자료형\n\n**1) 장점**\n\n인덱스를 통해 빠른 접근이 가능\n\n**2) 단점**\n\n미리 배열의 최대 크기를 정해 놔야 해서 데이터 추가/삭제가 어렵다\n\n→ (C와 C++ 한정 파이썬은 해당 안된다)\n\n**<배열의 기본 구조>**\n\n![Untitled](./src/Untitled%201.png)\n\n![Untitled](./src/Untitled%202.png)\n\n**2차원 배열**\n\n![Untitled](./src/Untitled%203.png)\n\n2차원 배열과 zip\n\n```python\n```python\nT = int(input())\n\ndef check(arr):\n    count = 0\n    result = 0\n\n    for i in range(N):\n        for j in range(N):\n            if arr[i][j] == 1:\n                count += 1      # 1이면 count +1\n            if (arr[i][j] == 0) or (j == N - 1):\n                if count == K:  # 0을 만났거나 줄의 마지막일때 count가 K값과 같으면\n                    result += 1 # 리턴값 +1\n                count = 0       # 아닐 경우 count 초기화\n    return result\n\nfor test_case in range(1, T + 1):\n    N, K = map(int, input().split())\n    puzzle = [(list(map(int, input().split()))) for i in range(N)]\n    # zip(*(arr)) : 전치행렬\n    print(f\'#{test_case} {check(puzzle) + check(list(zip(*puzzle)))}\')\n```\n```\n\n### Linked List\n\n링크드연결 리스트라고 불리는 자료구조\n쉽게 말해 링크를 통해 리스트를 만든다는 말이다\n\n![Untitled](./src/Untitled%204.png)\n\n- Node : 데이터와 다음 데이터를 가리키는 주소(포인터)로 이루어져 있다.\n- Pointer : 각 노드에서 다음 데이터를 가리키는 주소값을 가진다.\n- Head : 링크드리스트에서 가장 시작점인 데이터를 의미한다.\n- Tail : 링크드리스트에서 가장 마지막 데이터를 의미\n- Next=None(또는 Null) : 다음 데이터가 없을 경우 포인터의 주소값은 None(또는 Null)이다.\n\n**링크드리스트(Linked List) 장단점**\n\nC언어에서의 장,단점이라고 이해하면 된다.\n파이썬은 기본적으로 리스트가 링크드리스트의 모든 기능을 지원한다.\n\n**1) 장점**\n\n- 배열은 미리 데이터 공간을 할당해야 하지만, 링크드리스트는 미리 할당할 필요가 없다. \n(유동적으로 데이터 추가,삭제 가능)\n\n**2) 단점**\n\n- 다음 데이터를 연결하기 위해선 별도의 주소 공간을 가져야 하기 때문에 저장 공간 효율이 높지 않음\n- 배열은 인덱스를 통해 데이터에 접근하므로 시간복잡도 O(1)을 갖지만 링크드리스트의 경우 O(n)을 갖는다. \n즉, 연결 된 정보를 찾기 위해 주소를 확인하고 다음 데이터를 탐색하는 시간이 있기 때문에 접근 속도가 느리다.\n- 중간 데이터를 삭제시, 앞뒤 데이터를 연결하고 재구성하는 코드가 추가로 필요하다.\n\nLinked List의 종류\n\n1. 단일 연결 리스트\n    \n    ![as.png](./src/as.png)\n    \n    각 노드 당 한 개의 포인터가 있고 포인터는 다음 노드의 위치를 가리킨다\n    테일은 가장 마지막이므로 다음을 가리키는 포인터를 갖지 않습니다.\n    \n2. 이중 연결 리스트\n    \n    ![Untitled](./src/Untitled%205.png)\n    \n    단일 연결 리스트는 포인터를 한 개 가지고 있어 다음 노드만 가리킬 수 있었다면\n    이중 연결 리스트는 포인터를 두 개 가지고 있어 이전 노드와 다음 노드를 가리킨다.\n    \n3. 원형 연결 리스트\n    \n    ![Untitled](./src/Untitled%206.png)\n    \n    단일 연결 리스트의 테일에 포인터가 추가된 형태로 테일의 포인터는 헤더를 가르켜 원형이 된다\n    \n- 연결 리스트 생성\n    \n    **<노드 생성>**\n    \n    ```python\n    #Node 정의\n    class Node:\n        def __init__(self, data, next=None):  #data 만 입력시 next 초기값은 None이다.\n            self.data = data #다음 데이터 주소 초기값 = None\n            self.next = next\n    \n    #Node 생성해보기(data = 1)\n    node1 = Node(1)\n    \n    #Node의 값과 포인터 출력하기\n    print(node1.data)\n    print(node1.next)\n    \n    >\n    1\n    None\n    ```\n    \n    **<노드 연결>**\n    \n    ```python\n    #Node1 생성해보기\n    node1 = Node(1)\n    #Node2 생성해보기\n    node2 = Node(3)\n    #Node 연결하기\n    node1.next = node2\n    #가장 맨 앞 Node를 알기 위해 head 지정\n    head = node1\n    \n    #node1을 통해 연결한 결과 확인(밑에 2줄은 동일한 결과를 가리킨다)\n    print(node1.next.data)\n    print(node2.data)\n    \n    >\n    3\n    3\n    ```\n    \n    **<노드 뒤에 값을 추가 하는 함수>**\n    \n    ```python\n    #Node 정의\n    class Node:\n        def __init__(self, data, next=None):  #data 만 입력시 next 초기값은 None이다.\n            self.data = data #다음 데이터 주소 초기값 = None\n            self.next = next\n    \n    def add(data):\n        node = head\n        while node.next: #node의 next가 있을 경우만 실행\n            node = node.next #다음 노드가 있는지 계속 반복\n        node.next = Node(data) #다음 노드가 없을 경우 루프를 빠져나와 새로운 노드 생성\n    \n    #Node1 생성해보기\n    node1 = Node(1)\n    #가장 맨 앞 Node를 알기 위해 head 지정\n    head = node1\n    #add 함수 통해 신규 노드 추가하기\n    add(3)\n    #추가한 값을 node1 통해 next로 출력해보기\n    print(node1.next.data)\n    \n    >\n    1\n    3\n    ```\n    \n    **<노드 전체 출력>**\n    \n    ```python\n    #Node1 생성해보기\n    node1 = Node(1)\n    #가장 맨 앞 Node를 알기 위해 head 지정\n    head = node1\n    #add 함수 통해 신규 노드 추가하기\n    add(3)\n    add(4)\n    add(5)\n    \n    #추가한 값을 node1 통해 next로 출력해보기\n    node = head\n    while node.next: #node.next =None이 아닐 경우. 즉, node의 next가 있는 경우 실행\n        print(node.data)\n        node=node.next #node의 next가 없을 때까지 반복\n    print(node.data)\n    \n    >\n    1\n    3\n    4\n    5\n    ```\n    \n    배열은 인덱스를 통해 빠른 접근이 가능한게 장점이지만, 처음에 최대 크기를 정해놔야 해서 데이터를 추가/삭제하는 과정이 어려움\n    \n    링크드리스트는 배열의 단점을 개선하기 위해 생긴 자료구조\n    \n    파이썬은 리스트가 링크드리스트의 모든 기능을 지원(배열 이어붙이기, 중간 삽입, 삭제 등)\n    \n\n### Stack 스택\n\n나중에 입력 된 데이터가 먼저 출력 되는 자료구조\nLIFO(Last In, First Out)\n\nPush : 데이터를 입력하기\n\nPop : 데이터를 꺼내기(마지막으로 입력 된 순서부터)\n\n![Untitled](./src/Untitled%207.png)\n\n<코드>\n\n```python\n#빈 리스트 선언\nstack = []\n\n#2,5,8 차례대로 리스트에 추가하기(=Push)\nstack.append(2)\nstack.append(5)\nstack.append(8)\n\n#값이 모두 입력된 리스트 출력하기\nprint(\"stack : \", stack)\n\n#리스트 pop함수 통해 마지막으로 입력된 데이터 순 출력\nprint(\"첫번째 pop\")\nprint(stack.pop())\nprint(stack)\n\nprint(\"두번째 pop\")\nprint(stack.pop())\nprint(stack)\n\nprint(\"세번째 pop\")\nprint(stack.pop())\nprint(stack)\n\n>\nstack :  [2, 5, 8]\n\n첫번째 pop\n8\n[2, 5]\n\n두번째 pop\n5\n[2]\n\n세번째 pop\n2\n[]\n```\n\npop( ) 한번 실행할 때마다 리스트의 마지막 요소가 출력 되고 없어지는 것을 확인\n\n### Queue 큐\n\n가장 먼저 입력 된 데이터가 가장 먼저 출력되는 자료구조 \nFIFO(First In, First Out)\n\n- Enqueue : 큐에서 데이터를 입력하는 기능\n- Dequeue : 큐에서 데이터를 꺼내는 기능\n\n파이썬에서는 queue라는 내장 모듈을 제공\n- put( )은 큐에 데이터를 넣을 때 사용하는 메서드\n- get( )은 큐에서 데이터를 꺼내는 메서드\n\n![Untitled](./src/Untitled%208.png)\n\n<코드>\n\n```python\nimport queue\n\n#큐 모듈의 큐 클래스 객체 선언\ndata = queue.Queue()\nprint(type(data))\n\n#선언 된 큐 객체에 3개 데이터 입력하기 : 2,5,8\ndata.put(2)\ndata.put(5)\ndata.put(8)\n\n#큐 객체에서 입력된 객체 하나씩 꺼내기 :FIFO\nprint(data.get())\nprint(data.get())\nprint(data.get())\n\n>\n<class \'queue.Queue\'>\n2\n5\n8\n```\n\n**숫자 2,5,8을 순서대로 넣고 get( )을 3번 하면 먼저 입력 된 순서대로 출력**','선형 자료구조 생성일: 2023년 1월 30일 오전 8:01 작성자: 석철신 태그: Array, LinkedList, Queue, Stack  자료구조 자료구조는 대량의 데이터를 효율적으로 관리할 수 있는 데이터 구조를 의미  대표적인 자료구조에는 배열, 스택, 큐, 연결리스트, 해쉬 테이블, 힙 등  많은 자료구조를 알아두면, 특정 문제를 해결하는 데에 가장 적합한 자료구조를 빠르게 찾아 데이터를 정리하고 활용하여 문제를 빠르고 정확하게 해결할 수 있다.  Untitled  배열 같은 종류의 데이터를 효율적으로 관리하기 위해 사용하는 개념  같은 타입의 데이터를 연속된 공간에 나열하고 index를 부여    학교나 반을 배정 받고 학번을 배정 받는 것 역시 배열과 비슷한 개념  회사에서는 부서를 배정 받고','linear'),(_binary '','2023-11-15 02:12:58.915882',27,80,'2023-11-15 02:34:38.342467',1,'# 편집 거리(Edit Distance)\n\n### 📝 편집 거리란?\n\n서로 다른 두 문자열이 주어졌을 때, 두 문자열이 서로 같게 만들기 위해 요구되는 문자 수정, 삽입, 삭제의 최소 횟수를 가리킨다.\n\n### 예시\n\n👍 BOOK → COOK이 되기 위해서는 **수정** 한 번이 필요하다.\n\n☝️ PENNY → PEN이 되려면 **삭제** 두 번이 필요하다.\n\n🖕 FORM → FORMAT이 되려면 **삽입** 두 번이 필요하다.\n\n### 💁‍♂️ 편집 거리를 구하는 알고리즘\n\n두 문자열의 편집 거리는 2차원 DP 배열을 이용해 구할 수 있다. Shimmer와 Hammer라는 두 문자열을 입력으로 받았다고 가정하자. 두 문자열을 가지고 다음과 같은 이중 배열  `dp` 를 만들 수 있다.\n\n| DP | {} | S | H | I | M | M | E | R |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| {} | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 |\n| H | 1 |  |  |  |  |  |  |  |\n| A | 2 |  |  |  |  |  |  |  |\n| M | 3 |  |  |  |  |  |  |  |\n| M | 4 |  |  |  |  |  |  |  |\n| E | 5 |  |  |  |  |  |  |  |\n| R | 6 |  |  |  |  |  |  |  |\n\n이제부터는 배열을 채워 나가보자. “HAMMER”를 담은 문자열을 `hammer`, “SHIMMER”를 담은 문자열을 `shimmer` 라고 하자. 배열은 다음과 같이 채워 나가면 된다.\n\n$$\ndp[i][j] = \\begin{cases}    dp[i-1][j-1]\\,& \\text{if } hammer[i] == shimmer[j]\\\\\n   min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1]) + 1,              & \\text{otherwise}\n\\end{cases}\n$$\n\n두 문자열에 대해, 그 자리의 문자가 서로 같다면, 해당 자리의 편집 거리는 그 좌상의 편집 거리와 같다. 한편 두 문자가 서로 다르다면, 해당 자리의 편집 거리는 위, 왼쪽, 왼쪽 위 중 가장 작은 값 + 1과 같다. \n\n이제 배열을 채워보면\n\n| DP | {} | S | H | I | M | M | E | R |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| {} | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 |\n| H | 1 | 1 | 1 | 2 | 3 | 4 | 5 | 6 |\n| A | 2 | 2 | 2 | 2 | 3 | 4 | 5 | 6 |\n| M | 3 | 3 | 3 | 3 | 2 | 3 | 4 | 5 |\n| M | 4 | 4 | 4 | 4 | 3 | 2 | 3 | 4 |\n| E | 5 | 5 | 5 | 5 | 4 | 3 | 2 | 3 |\n| R | 6 | 6 | 6 | 6 | 5 | 4 | 3 | 2 |\n\n이렇게 얻어낸 dp[6][7]이 바로 HAMMER와 SHIMMER의 최소 편집 거리이다.\n\n(SHIMMER에서 S를 없애고 I→A로 수정)','편집 거리(Edit Distance) 📝 편집 거리란? 서로 다른 두 문자열이 주어졌을 때, 두 문자열이 서로 같게 만들기 위해 요구되는 문자 수정, 삽입, 삭제의 최소 횟수를 가리킨다.  예시 👍 BOOK → COOK이 되기 위해서는 수정 한 번이 필요하다.  ☝️ PENNY → PEN이 되려면 삭제 두 번이 필요하다.  🖕 FORM → FORMAT이 되려면 삽입 두 번이 필요하다.  💁‍♂️ 편집 거리를 구하는 알고리즘 두 문자열의 편집 거리는 2차원 DP 배열을 이용해 구할 수 있다. Shimmer와 Hammer라는 두 문자열을 입력으로 받았다고 가정하자. 두 문자열을 가지고 다음과 같은 이중 배열  dp 를 만들 수 있다.   DP  {}  S  H  I  M  M  E  R   {}  0  ','edit_distance'),(_binary '','2023-11-16 12:58:56.582365',27,81,'2023-11-15 02:34:29.012043',1,'# LCS : Longest Common Subsequence\n\n# 최장 공통 부분 수열\n\n`두 수열이 주어졌을 때, 모두의 부분 수열이 되는 수열 중 **가장 긴 것**을 찾는 알고리즘`\n\n- 주로 **최장 공통 부분 수열**(Longest Common Subsequence)을 말하지만, **최장 공통 문자열**(Longest Common Substring)을 말하기도 한다\n- ex) ABCDEF & GBCDFE\n    - Longest Common Subsequence : BCDF or BCDE (부분수열이기 때문에 문자 사이를 건너뛰어 공통되면서 가장 긴 부분 문자열)\n    - Longest Common Substing : BCD (한번에 이어져있는 문자열만 가능)\n\n---\n\n# 최장 공통 문자열(Longest Common Substring)\n\n- 점화식\n\n```python\nif i == 0 or j == 0:  # 마진 설정\n	LCS[i][j] = 0\nelif string_A[i] == string_B[j]:\n	LCS[i][j] = LCS[i - 1][j - 1] + 1\nelse:\n	LCS[i][j] = 0\n```\n\n- LCS라는 2차원 배열을 이용하여 두 문자열을 행, 열에 매칭\n- 편의상 i, j가 0일 때는 모두 0을 넣어줘 마진값을 설정\n- 이후, i, j가 1 이상일 때부터 검사를  시작\n    1. 문자열 A, 문자열 B의 한 글자씩 비교\n    2. 두 문자가 **다르다면** `LCS[i][j]` 에 `0` 을 표시\n    3. 두 문자가 **같다면** `LCS[i-1][j-1]` 값을 찾아 `+1` \n    4. 1, 2, 3 반복\n- 공통 문자열은 연속 되어야 함!\n- 두 문자의 앞 글자까지가 공통 문자열 이라면 계속 공통 문자열이 이어질 것\n- 아니라면 본인부터 다시 공통 문자열을 만들어 가게 될 것\n\n## 구현 과정\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/blob/main/Dynamic-Programming/LCS/Untitled.png?raw=true)\n\n1. 앞 마진이 0인 2차원 배열을 생성, ABCDEF 문자열과 GBCDFE 문자열을 한 글자 씩 비교\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%201.png)\n\n1. G를 ABCDEF와 한 글자 씩 비교, 같은 문자가 없기 때문에 `LCS[i][j]` 값은 모두 0으로 채워짐\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%202.png)\n\n1. 다음으로 B를 ABCDEF와 한 글자 씩 비교, 같은 문자가 존재하면 `LCS[i][j]` 값은 `LCS[i-1][j-1] + 1` \n    - `LCS[1][1] = 0`\n    - `LCS[2][2] = 0 + 1 = 1`\n    \n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%203.png)\n\n1. 다음으로 C를 ABCDEF와 한 글자 씩 비교, 같은 문자가 존재하면 `LCS[i][j]` 값은 `LCS[i-1][j-1] + 1` \n    - `LCS[2][2] = 1`\n    - `LCS[3][3] = 1 + 1 = 2`\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%204.png)\n\n1. 다음으로 D를 ABCDEF와 한 글자 씩 비교, 같은 문자가 존재하면 `LCS[i][j]` 값은 `LCS[i-1][j-1] + 1` \n    - `LCS[3][3] = 2`\n    - `LCS[4][4] = 2 + 1 = 3`\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%205.png)\n\n1. 다음으로 F를 ABCDEF와 한 글자 씩 비교, 같은 문자가 존재하면 `LCS[i][j]` 값은 `LCS[i-1][j-1] + 1` \n    - `LCS[4][5] = 0`\n    - `LCS[5][6] = 0 + 1 = 1`\n    - (i가 가로축, j가 세로축임에 유의)\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%206.png)\n\n1. 다음으로 E를 ABCDEF와 한 글자 씩 비교, 같은 문자가 존재하면 `LCS[i][j]` 값은 `LCS[i-1][j-1] + 1` \n    - `LCS[4][5] = 0`\n    - `LCS[5][6] = 0 + 1 = 1`\n    - (i가 가로축, j가 세로축임에 유의)\n    \n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%207.png)\n\n1. 최댓값을 찾으면 Longest Common Substring 종료\n\n---\n\n# 최장 공통 부분수열(Longest Common Subsequence) 길이 구하기\n\n- 점화식\n\n```python\nif i == 0 or j == 0:  # 마진 설정\n	LCS[i][j] = 0\nelif string_A[i] == string_B[j]:\n	LCS[i][j] = LCS[i - 1][j - 1] + 1\nelse:\n	LCS[i][j] = max(LCS[i - 1][j], LCS[i][j - 1])\n```\n\n- 위와 마찬가지로 LCS라는 2차원 배열에 매칭하고 마진값을 설정한 후 검사\n    1. 문자열 A, 문자열 B의 한 글자씩 비교\n    2. 두 문자가 다르다면 `LCS[i-1][j]` 와 `LCS[i][j-1]` 중에 큰 값을 표시\n    3. 두 문자가 같다면 `LCS[i-1][j-1]` 값을 찾아 `+1` \n    4. 1, 2, 3 반복\n\n최장 공통 문자열을 구하는 과정과 다른부분은 **비교하는 두 문자가 다를 때**\n\n### 1. `LCS[i-1][j]` 와 `LCS[i][j-1]`\n\n- **부분 수열은 연속된 값이 아님 →** 현재의 문자를 비교하는 과정 이전의 LCS는 **계속해서 유지.**\n    \n    현재의 문자를 비교하는 과정 이전의 과정이 `LCS[i-1][j]` 와 `LCS[i][j-1]`\n    \n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%208.png)\n\nex) 문자열 AB와 GBC를 비교하는 과정\n\n- AB와 GBC의 최대 공통 부분 수열이 B라는 것을 알기 위해서는 문자열 A와 GBC를 비교하는 과정, 문자열 AB와 GB를 비교하는 과정이 필요.\n- 문자열 AB와 GB의 비교 과정에서 최대 공통 부분수열이 B임을 확인했기 때문에 문자열 AB와 GBC의 최대 공통 부분 수열 역시 B가 됨.\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%209.png)\n\n### 2. 왜 문자가 같으면 `LCS[i][j] = LCS[i - 1][j - 1] + 1` ?\n\n- 두 문자가 같은 상황이 오면 지금까지의 최대 공통 부분 수열에 1을 더해주는 것\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%2010.png)\n\nex) 문자열 ABC와 GBC를 비교하는 과정\n\n- LCS 배열은 `LCS[i-1][j]` 와 `LCS[i][j-1]` 의 비교를 통해 언제나 본인까지의 최대 공통 부분 수열 값을 갖고 있음\n- 문자열 AB와 GB를 비교할 때와 문자열 ABC와 GBC를 비교할 때 달라진 점은 두 문자열 모두에 C가 추가된 점\n- 때문에 기존의 최대 공통 부분 수열이 B에 C를 더한 BC가 최대 공통 부분 수열이 되는 것\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%2011.png)\n\n## 구현과정\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%2012.png)\n\n1. 앞 마진이 0인 2차원 배열을 생성, ABCDEF 문자열과 GBCDFE 문자열을 한 글자 씩 비교\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%2013.png)\n\n1. G를 ABCDEF와 한 글자 씩 비교, 문자가 같지 않다면 `LCS[i][j]` 값은 `max(LCS[i-1][j], LCS[i][j-1])`\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%2014.png)\n\n1. 다음으로 B를 ABCDEF와 한 글자 씩 비교, 같은 문자가 존재하면 `LCS[i][j]` 값은 `LCS[i-1][j-1]) + 1` \n    - `LCS[1][1] = 0`\n    - `LCS[2][2] = 0 + 1 = 1`\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%2015.png)\n\n1. 다음으로 C를 ABCDEF와 한 글자 씩 비교, 같은 문자가 존재하면 `LCS[i][j]` 값은 `LCS[i-1][j-1]) + 1` , 문자가 같지 않다면 `LCS[i][j]` 값은 `max(LCS[i-1][j], LCS[i][j-1])`\n    - `LCS[2][2] = 1`\n    - `LCS[3][3] = 1 + 1 = 2`\n    \n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%2016.png)\n\n1. 다음으로 D를 ABCDEF와 한 글자 씩 비교, 같은 문자가 존재하면 `LCS[i][j]` 값은 `LCS[i-1][j-1]) + 1` , 문자가 같지 않다면 `LCS[i][j]` 값은 `max(LCS[i-1][j], LCS[i][j-1])`\n    - `LCS[3][3] = 2`\n    - `LCS[4][4] = 2 + 1 = 3`\n    \n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%2017.png)\n\n1. 다음으로 F를 ABCDEF와 한 글자 씩 비교, 같은 문자가 존재하면 `LCS[i][j]` 값은 `LCS[i-1][j-1]) + 1` , 문자가 같지 않다면 `LCS[i][j]` 값은 `max(LCS[i-1][j], LCS[i][j-1])`\n    - `LCS[4][5] = 3`\n    - `LCS[5][6] = 3 + 1 = 4`\n    \n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%2018.png)\n\n1. 최댓값을 찾으면 Longest Common Subsequence 탐색 종료\n\n---\n\n# 최장 공통 부분수열(Longest Common Subsequence) 찾기\n\n1. LCS 배열의 **가장 마지막 값**에서 시작. 결과값을 저장할 `result` 배열 준비\n2. `LCS[i - 1][j]`와 `LCS[i][j - 1]` 중 현재 값과 같은 값을 찾습니다.2-1. 만약 **같은 값이 있다면 해당 값으로 이동**합니다.2-2. 만약 **같은 값이 없다면 `result`배열에 해당 문자를 넣고 `LCS[i -1][j - 1]`로 이동**합니다.\n3. 2번 과정을 반복하다가 0으로 이동하게 되면 종료합니다. `result` 배열의 역순이 **LCS** 입니다.\n\n## 구현과정\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%2019.png)\n\n1. LCS 배열의 가장 마지막 값에서 시작하여 `LCS[i-1][j]` 와 `LCS[i][j-1]` 중 현재 값과 같은 값 찾기\n    - `result = [ , , , ]`\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%2020.png)\n\n1. 값을 찾았으면 해당 값으로 이동, 다시 `LCS[i-1][j]` 와 `LCS[i][j-1]` 중 현재 값과 같은 값 찾기\n    - `result = [ , , , ]`\n    \n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%2021.png)\n\n1. 현재 값과 같은 값이 없으므로 LCS[i-1][j-1]로 이동, `result` 배열에 해당 문자 추가\n    \n    다시 `LCS[i-1][j]` 와 `LCS[i][j-1]` 중 현재 값과 같은 값 찾기\n    \n    - `result = [**F**, , , ]`\n    \n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%2022.png)\n\n1. 값을 찾았으면 해당 값으로 이동, 다시 `LCS[i-1][j]` 와 `LCS[i][j-1]` 중 현재 값과 같은 값 찾기\n    - `result = [**F**, , , ]`\n    \n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%2023.png)\n\n1. 현재 값과 같은 값이 없으므로 LCS[i-1][j-1]로 이동, `result` 배열에 해당 문자 추가\n    \n    다시 `LCS[i-1][j]` 와 `LCS[i][j-1]` 중 현재 값과 같은 값 찾기\n    \n    - `result = [**F, D, ,** ]`\n    \n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%2024.png)\n\n1. 현재 값과 같은 값이 없으므로 LCS[i-1][j-1]로 이동, `result` 배열에 해당 문자 추가\n    \n    다시 `LCS[i-1][j]` 와 `LCS[i][j-1]` 중 현재 값과 같은 값 찾기\n    \n    - `result = [**F, D, C,** ]`\n    \n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LCS/Untitled%2025.png)\n\n1. 현재 값과 같은 값이 없으므로 LCS[i-1][j-1]로 이동, `result` 배열에 해당 문자 추가\n    \n    0으로 이동했기 때문에 종료하고, 배열을 뒤집으면 LCS 탐색 완료\n    \n    - `result = [**F, D, C, B**]`','LCS : Longest Common Subsequence 최장 공통 부분 수열 두 수열이 주어졌을 때, 모두의 부분 수열이 되는 수열 중 **가장 긴 것**을 찾는 알고리즘    주로 최장 공통 부분 수열(Longest Common Subsequence)을 말하지만, 최장 공통 문자열(Longest Common Substring)을 말하기도 한다  ex) ABCDEF & GBCDFE   Longest Common Subsequence : BCDF or BCDE (부분수열이기 때문에 문자 사이를 건너뛰어 공통되면서 가장 긴 부분 문자열)  Longest Common Substing : BCD (한번에 이어져있는 문자열만 가능)   최장 공통 문자열(Longest Common Substring)   점화식  ','LCS'),(_binary '','2023-11-16 13:03:51.253926',27,82,'2023-11-15 02:34:32.261424',1,'# LIS : Longest Increasing Subsequence\n\n# **최장 증가 부분 수열**\n\n`원소가 n개인 배열의 일부 원소를 골라내서 만든 **부분 수열** 중, 각 원소가 이전 원소보다 크다는 조건을 만족하고, 그 길이가 최대인 부분 수열`\n\n---\n\n## DP를 활용한 LIS\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LIS/Untitled.png)\n\n증가 부분 수열의 길이는 1부터 시작\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LIS/Untitled%201.png)\n\narray의 값과 비교했을 때 작으므로 dp[1]에는 1\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LIS/Untitled%202.png)\n\narray[2] 역시 앞의 array 값들과 비교했을 때 작으므로 dp[2]에는 1\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LIS/Untitled%203.png)\n\narray[3]은 array[1]과 array[2]에 비해 큰 값. dp[1]과 dp[2]는 값이 1로 같으므로 dp[3]에는 1(array[1]과 array[2] 중 최댓값) + 1인 2.\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LIS/Untitled%204.png)\n\narray[4]는 array[1]과 array[2]에 비해 큰 값. dp[1]과 dp[2]는 값이 1로 같으므로 dp[3]에는 1 + 1인 2.\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LIS/Untitled%205.png)\n\n마지막 array[5]는 array[1], array[2], array[3], array[4]에 비해 큰 값, dp[3]과 dp[4]가 2로 가장 큰 값이므로 dp[5]에는 2 + 1인 3\n\n```python\narray = [5, 2, 1, 4, 3, 5]\ndp = [1 for _ in range(len(array))] \n\nfor i in range(1, len(array)):\n    for j in range(i): # array의 처음부터 i-1번째 인덱스까지\n        if array[i] > array[j]: # 숫자의 크기를 비교하여 현재 값이 더 크면\n            dp[i] = max(dp[i], dp[j] + 1) # dp 배열의 값을 더 큰 값으로 갱신\n```\n\n수열의 값을 하나씩 비교해가며 길이를 구하기 때문에 O(N^2) → **굉장히 비효율적**\n\n---\n\n## 이분탐색을 활용한 LIS\n\nLIS의 형태를 유지하기 위해 주어진 배열의 인덱스를 하나씩 살펴보면서\n\n**그 숫자가 들어갈 위치를 이분탐색으로 탐색해서 넣는다.**\n\n이분탐색은 일반적으로 시간복잡도가 O(logn)으로 알려져 있으므로, 위의 문제를 O(nlogn)의 시간복잡도로 해결할 수 있게 된다.\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LIS/Untitled%206.png)\n\n1. dp[0]에 1을 넣어주고 x[0]에는 array의 첫 번째 값인 5로 초기화\n2. array[1]의 값이 x 배열에서 어디에 들어갈 수 있는지 이분탐색\n3. 2는 x 배열의 0번째 인덱스에 들어갈 수 있으며 x[0]에 있는 5보다 작다. 이렇게 해당 인덱스에 있는 x 배열의 값보다 현재 값이 작은 경우 x 배열의 값을 갱신 → **x[0]에 5 대신 2 갱신**\n    \n    → 길이가 1인 증가 부분 수열이 {5}와 {2}가 있는데 이 수열 중에서 끝 값이 더 작은 2를 x 배열에 저장한다는 뜻\n    \n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LIS/Untitled%207.png)\n\n이제 array[2]의 값인 1을 살펴보면 역시 x의 0번째에 들어갈 수 있고 이는 현재 x[0]의 값인 2보다 작기 때문에 x[0]을 1로 갱신\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LIS/Untitled%208.png)\n\narray[3]의 값인 4는 x 배열의 마지막 값인 1보다 크므로 새롭게 x 배열에 추가해 줄 수 있다. x[1]에 4를 추가해 주고 dp[1]에는 dp[0] + 1인 2를 넣어줌 → 증가 부분 수열의 길이가 2인 수열 중 끝이 4로 끝나는 수열이 있다는 의미\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LIS/Untitled%209.png)\n\narray[4]의 값인 3은 x 배열에서 1번째 인덱스에 들어갈 수 있으며 현재 x[1]의 값인 4보다 작다. x[1]의 값을 3으로 갱신해 준다. → 증가 부분 수열의 길이가 2인 수열 중 끝이 4와 3인 수열 중 더 작은 값인 3을 x 배열에 저장해 놓는다는 의미\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LIS/Untitled%2010.png)\n\narray[5]의 값인 5를 x 배열의 몇 번째에 넣을 수 있는지를 이분탐색을 통해 찾는다. x 배열의 마지막 값인 3보다 크므로 x 배열에 새롭게 5를 추가해 주고 dp 배열에는 dp 배열의 마지막 값에 + 1을 해주어 3을 추가 → 증가 부분 수열의 길이가 3인 수열 중 끝이 5인 수열이 있다는 것을 의미\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LIS/Untitled%2011.png)\n\n이렇게 array의 마지막까지 탐색을 끝내고 나면 위와같이 dp 배열과 x 배열이 완성, LIS의 길이는 3\n\nx 배열은 항상 오름차순으로 정렬되어 있기 때문에 array의 값이 x 배열의 어느 위치에 들어갈 수 있는지를 이분 탐색을 활용하여 찾을 수 있으며, Python에서 bisect를 사용하여 쉽게 구현 가능함\n\n```python\nfrom bisect import bisect_left\n\narray = [5, 2, 1, 4, 3, 5]\ndp = [1]\nx = [array[0]]\n\nfor i in range(1, len(array)):\n    if array[i] > x[-1]: # 현재 값이 x 배열의 마지막 값보다 클 경우\n        x.append(array[i]) # x 배열에 현재 값을 추가해 주고\n        dp.append(dp[-1] + 1) # 증가 부분 수열의 길이를 1 증가시킨다.\n    else: # 그렇지 않을 경우\n        idx = bisect_left(x, array[i]) # 현재 값이 x 배열의 몇 번째 인덱스에 들어갈 수 있는지를 찾아서\n        x[idx] = array[i] # x 배열의 idx 위치에 현재 값을 넣어준다.\n```\n\n### 참고 - bisect 사용\n\n**`from bisect import bisect, bisect_left, bisect_right`** 를 통해 불러올 수 있다.\n\n- `bisect.bisect(a, x)` : 오름차순으로 정렬된 리스트 \'a\'에 value \'x\'가 삽입 될 가장 오른쪽 index를 리턴한다.\n- `bisect.bisect_left(a, x)` : 오름차순으로 정렬된 리스트 \'a\'에 value \'x\'가 삽입 될 가장 왼쪽 index를 리턴한다.\n- `bisect.bisect_right(a, x)` : 오름차순으로 정렬된 리스트 \'a\'에 value \'x\'가 삽입 될 가장 오른쪽 index를 리턴한다.\n- 가장 오른쪽, 가장 왼쪽을 나누는 이유 : 삽입할 값인 x와 동일한 값이 리스트 a에 이미 존재하는 경우가 있기 때문\n\n---\n\n## **실제 LIS를 구하는 방법????**\n\n1. 각 수가 LIS 배열에 들어갈 때 몇번째 인덱스에 들어가는지를 record라는 리스트에 저장을 한다.\n2. 이후에 record가 다 차면 record의 최대값으로부터 역순으로 순회하여 그 인덱스에 해당하는 값을 LIS Result에 저장한다.\n3. LIS Result를 오름차순으로 정렬한다.\n4. 실제 LIS가 완성된다.\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LIS/Untitled%2012.png)\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/LIS/Untitled%2013.png)\n\n```python\n# 전깃줄 - 2 https://www.acmicpc.net/problem/2568\n\ndef Lower_Bound(lst, num):\n    low = 0\n    high = len(lst) - 1\n    while (low < high):\n        mid = int((low + high) / 2)\n        if num <= lst[mid]:\n            high = mid\n        elif num > lst[mid]:\n            low = mid + 1\n    return high\n \n \ndic = {}\nlst = []\nlis = [-1]\nresult = []\nbacktrace = []\nn = int(input())\nfor i in range(n):\n    a, b = map(int, input().split(\' \'))\n    dic[b] = a\ntemp = sorted(dic)\nfor i in temp:\n    lst.append(dic.get(i))\nfor i in lst:\n    if i > lis[-1]:\n        lis.append(i)\n    else:\n        lis[Lower_Bound(lis, i)] = i\n    result.append(lis.index(i)+1)\nlisLength = len(lis)\nfor i in range(len(lst)-1,-1,-1):\n    if result[i] == lisLength:\n        backtrace.append(lst[i])\n        lisLength-=1\nprint(n - (len(lis) - 1))\nlst.sort()\nfor i in backtrace:\n    lst.remove(i)\nfor i in lst:\n    print(i)\n```','LIS : Longest Increasing Subsequence 최장 증가 부분 수열 원소가 n개인 배열의 일부 원소를 골라내서 만든 **부분 수열** 중, 각 원소가 이전 원소보다 크다는 조건을 만족하고, 그 길이가 최대인 부분 수열   DP를 활용한 LIS Untitled  증가 부분 수열의 길이는 1부터 시작  Untitled  array의 값과 비교했을 때 작으므로 dp1에는 1  Untitled  array2 역시 앞의 array 값들과 비교했을 때 작으므로 dp2에는 1  Untitled  array3은 array1과 array2에 비해 큰 값. dp1과 dp2는 값이 1로 같으므로 dp3에는 1(array1과 array2 중 최댓값) + 1인 2.  Untitled  array4는 array1','LIS'),(_binary '','2023-11-15 02:14:57.912266',27,83,'2023-11-15 02:34:40.896415',1,'# Matrix Chain Multiplication\n---\n## Intro\n\n연쇄 행렬 곱셈.\n\n연쇄 행렬 곱셈 문제는 주어진 행렬을 가장 효율적으로 곱하는 방법을 찾는 최적화 문제이다. \n\n다음 차수를 가진 행렬을 생각해 보자\n\n    A = 2 x 3\n    B = 3 x 4\n    C = 4 x 5\n\n\n행렬 곱 (AB)C 와 A(BC)는 곱셈 연산횟수가 다르다.\n\n- (AB)C : \n  - 23 34 행렬 곱 -> 24 행렬\n  - 24 45 행렬 곱\n  \n  2 x 3 x 4 + 2 x 4 x 5 = 64\n\n- A(BC) : \n  - 34 45 행렬 곱 -> 35 행렬\n  - 23 35 행렬 곱\n  \n  3 x 4 x 5 + 2 x 3 x 5 = 90\n\n---\n\n## Brute - force\n\n가령 n 개의 연쇄 행렬 곱을 처리해야 된다고 하자. \n\n![](src/mcm1.PNG)\n\n$A_1A_2...A_n$\n\n행열의 곱은 행열이 되므로, 위와 같이 연쇄행열을 곱하는 경우의 수는 괄호로 선행연산을 구분하여 표현하게 된다.\n\n가령 ABCD를 연산하는 경우는 다음과 같고, \n\n    ((AB)(CD))\n    (A((BC)D))\n    (((AB)C)D)\n    (A(B(CD)))\n    ((A(BC))D)\n    (A(B(C(D))))\n    (((A(B))C)D)\n\n이는 $2^{n-1}$ 가지 이다. \n$O(2^{n-1})$\n\n\n## Dynamic Programming \n\n위의 방식이 n개를 나누어 가면서 어떤 행열을 선행연산 할지를 결정했다면, 2개씩 부터 길이를 늘려가며 연산량만 저장하는 방법을 생각 할 수 있다.\n\n![](src/mcm3.PNG)\n\n경우의 수가 줄어드는 이유는 구간내 연산량을 비교해서 최소값만 저장하기 때문이다. 즉, 행열이 1차원 리스트로 앞뒤 순서가 존재하기 때문에 구간의 최적해를 구할 수 있다.\n\n구간의 길이는 2부터 구하고자하는 전체 구간 n 까지이고, 작은 구간들 부터 최적해를 구해나가는 과정을 겪는다. \n\n따라서 부분 문제의 수는 n^2 이고, 각 부분 문제를 푸는 데 n만큼 걸리므로(i~j구간을 어떻게 나눌지 j-i 가지)\n총 시간복잡도는 $O(n^3)$ 이다.\n\n```python\ndef matrix_chain_multiplication(dims):\n    n = len(dims) - 1\n    # C[i][j]: i번째부터 j번째까지의 행렬을 곱하는 데 필요한 최소 곱셈 횟수\n    C = [[0] * n for _ in range(n)]\n    for gap in range(1, n):\n        for i in range(n - gap):\n            j = i + gap\n            C[i][j] = float(\'inf\')\n            for k in range(i, j):\n                cost = C[i][k] + C[k+1][j] + dims[i] * dims[k+1] * dims[j+1]\n                if cost < C[i][j]:\n                    C[i][j] = cost\n    return C[0][n-1]\n\n```\n\n','Matrix Chain Multiplication  Intro 연쇄 행렬 곱셈.  연쇄 행렬 곱셈 문제는 주어진 행렬을 가장 효율적으로 곱하는 방법을 찾는 최적화 문제이다.  다음 차수를 가진 행렬을 생각해 보자      A = 2 x 3 B = 3 x 4 C = 4 x 5  행렬 곱 (AB)C 와 A(BC)는 곱셈 연산횟수가 다르다.    (AB)C :  23 34 행렬 곱 -> 24 행렬  24 45 행렬 곱  2 x 3 x 4 + 2 x 4 x 5 = 64    A(BC) :  34 45 행렬 곱 -> 35 행렬  23 35 행렬 곱  3 x 4 x 5 + 2 x 3 x 5 = 90   Brute - force 가령 n 개의 연쇄 행렬 곱을 처리해야 된다고 하자.    $A_1A_2...A_n$  행열','matrix_chain_multiplication'),(_binary '','2023-11-15 02:14:46.216594',27,84,'2023-11-15 02:34:43.237161',1,'# Memoization\n- 동일한 연산을 반복적으로 해야 할 때, **이전에 게산한 값을 메모리에 저장**함으로써 중복되는 계산을 제거하여 실행 속도를 빠르게 해주는 기법\n- DP(Dynamic Programming, 동적계획법)의 핵심이 됨\n- 메모리 공간을 희생하고 수행 속도를 향상\n\n### [ 수행 가능한 조건 ]\n1. 연산에 있어 많은 메모리를 사용하지 않는 함수\n2. 같은 입력에 대해 같은 출력을 내는 함수\n3. 반복되는 함수 결과 값 사용\n\n# Recursive Function\n- 내부적으로 자기 자신을 호출하는 함수\n- **반드시 종료조건이 필요함**\n- 재귀 호출을 너무 많이 하게 되면 stack overflow 발생\n\n### [ 재귀함수를 구현할 때 고려할 것 ]\n1. 결과를 향한 방향 \n  - 정방향/역방향\n2. 반환값 \n  - 있음/없음\n3. 종료 조건\n\n\n# 피보나치 수열 예제\n![image](https://user-images.githubusercontent.com/108309396/228179231-fb1ac314-b4c1-4c89-93df-e3353eda551a.png)  \n&rarr; 연산이 중복됨\n\n## Memoization\n```python\ndic = {1:1, 2:1}\ndef fib_memoization(n):\n  if n in dic:\n    return dic[n]\n  \n  dic[n] = fib_memoization(n-1) + fib_memoization(n-2)\n  return dic[n]\n```\n\n## Recursive Function\n```python\ndef fib_recursive(n):\n  if n == 1:\n    return 1\n  elif n == 2:\n    return 1\n  else:\n    return fib_recursive(n-1) + fib_recursive(n-2)\n```','Memoization   동일한 연산을 반복적으로 해야 할 때, 이전에 게산한 값을 메모리에 저장함으로써 중복되는 계산을 제거하여 실행 속도를 빠르게 해주는 기법  DP(Dynamic Programming, 동적계획법)의 핵심이 됨  메모리 공간을 희생하고 수행 속도를 향상  수행 가능한 조건   연산에 있어 많은 메모리를 사용하지 않는 함수  같은 입력에 대해 같은 출력을 내는 함수  반복되는 함수 결과 값 사용  Recursive Function   내부적으로 자기 자신을 호출하는 함수  반드시 종료조건이 필요함  재귀 호출을 너무 많이 하게 되면 stack overflow 발생  재귀함수를 구현할 때 고려할 것   결과를 향한 방향   정방향/역방향   반환값   있음/없음   종료 조건  피보나치 수','memoization'),(_binary '','2023-11-16 13:05:26.764427',27,86,'2023-11-15 02:34:35.472440',1,'# 외판원 순회 문제(Travelling Salesman Problem)\n\n\n### 💵 외판원 순회 문제란?\n\n외판원 순회 문제는 **한 정점에서 시작해서 다른 모든 정점을 한 번씩만 방문해서 시작 정점으로 돌아오려 할 때 가능한 최소 비용 및 방문 순서**를 찾는 문제이다.\n\n### 🗒️NOTE\n\n외판원 순회 문제에서는 시작점이 주어질 수도, 그렇지 않을 수도 있지만 어느 경우든 문제가 없다. 최단 순회 경로가 존재한다면 이는 **사이클**을 이룰 것이고, 따라서 어떤 정점으로부터 시작하든 자기 자신으로 돌아오기 위한 **최소 비용은 동일**할 것이기 때문이다. 어떤 정점이든 자신으로 돌아오는 경로 또한 동일한 사이클 안에 있다. \n\n### ✏️ 풀이(1) 완전 탐색 [[외판원 순회 2](https://www.acmicpc.net/problem/10971)]\n\n가장 먼저 생각해 볼 수 있는 풀이법은 가능한 방문 순서를 고려해 모두 확인해보는 것이다.\n\nN개의 정점과 간선의 정보가 주어졌다고 해보자. 이 N개의 정점에 대해 가능한 방문 순서는 당연히 N!이 될 것이다. 하지만 앞서 말한 것과 같이 어떤 정점으로부터 시작하든 최단 순회 경로는 항상 동일할 것이다. 따라서 시작 정점은 임의로 지정해줘도 되고, 우리가 탐색해야 할 것들은 나머지 N-1개 정점의 순서이다. 즉 외판원 순회 문제는 (N-1)!의 시간 복잡도 내에 풀 수 있다.\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Dynamic-Programming/TSP/Untitled%201.png)\n\n0~4번 정점들이 있고, 그 간선 정보들 또한 주어졌다고 하자. 이때 0번 정점을 임의로 시작 정점으로 지정한다면, 남은 일은 나머지 정점들로 순열을 만들고 주어진 간선 0→1, 1→2, 2→3, 3→4, 4→0들의 길이를 확인하는 것 뿐이다.\n\n\n이를 마지막 순열까지 반복한다면 가능한 모든 경우들을 고려한 것이므로 답을 찾을 수 있다.\n\n문제는 11!(=39916800) 정도까지는 완전 탐색으로 풀어볼 만하지만, 12!(=479001600)부터는 완전 탐색을 적용할 수 없다는 것이다.\n\n---\n\n### ✏️ 풀이(2) DP [[외판원 순회](https://www.acmicpc.net/problem/2098)]\n\n완전 탐색으로 풀 수 있는 것보다 좀 더 큰 경우에는 DP를 이용해 풀 수 있다. 기본적인 아이디어는 DFS로, 현재 방문 중인 정점, 이때까지 방문한 정점 및 최소 비용을 알고 있을 때, 방문 가능한 미방문 정점들을 방문해보는 것이다. 여기서 정보들은 비트마스킹을 이용해 dp 배열에 다음과 같이 저장된다.\n\n                 **dp[방문 중인 정점][현재까지 방문한 정점들] = 최소 비용**\n\n- 왜 **비트 마스킹**을 이용하는지?\n    \n    비트 연산은 다음의 이점을 가진다.\n    \n    - 1) 빠른 속도\n    - 2) 적은 메모리\n    - 3) **멋**\n\n* 만약 비트마스킹을 사용하지 않고 위의 방문 배열을 만든다면 다음과 같이 만들 수도 있을 것 같다.\n\n**dp[16][2][2][2][2]…[2][2][2][2]**\n\n혹은 key-value 값으로??\n\n자세한 건 코드를 통해서 \n\n```cpp\n//N은 정점의 개수, W[a][b]는 a->b의 간선이다.\n//dp[16][1<<16] : 정점의 개수는 최대 16개.\n\nint N, W[16][16], dp[16][65536]{ 0, };\nint main() {\n	scanf(\"%d\", &N);\n	for (int i = 0; i < N; i++) {\n		for (int j = 0; j < N; j++) scanf(\"%d\", &W[i][j]);\n	}\n	printf(\"%d\", TSP(0, 1));\n	//0번째 정점을 시작 정점으로 생각하자.\n	//시작 정점인 0번 정점이 방문됐으니 0번째 비트를 1로 만든다.\n}\n```\n\n---\n\n```cpp\n//아래는 일반적인 DFS와 유사하다.\nint TSP(int cur, int visited) {\n	if (visited == (1 << N) - 1) {//(1 << N) - 1이면 모든 N개의 정점이 방문되었다는 것이다.\n		if (W[cur][0]) return W[cur][0]; //이 경우, 시작 정점으로 돌아가는 간선이 있다면 반환하고\n		else return INF; //없다면 무한대를 반환한다.\n	}\n	\n  /*\n		int ret이 아니라 int &ret을 쓰는 이유는?\n		여기서 변경되어야 할 값은 dp[cur][visited]이기 때문이다.\n    쉽게 말해 dp[cur][visited]를 일일이 쓰지 않고 ret으로 줄여쓰기 위함이라 생각해도 좋다.\n	*/\n	int &ret = dp[cur][visited]; //현재 정점까지, visited의 정점들을 거쳐서 온 최솟값이\n	if (ret) return ret; //있다면 그것을 반환하고,\n	\n	ret = INF; //없다면 아직 방문을 하지 않은 경우이므로 무한대를 넣어준다.\n\n	for (int i = 0; i < N; i++) {//모든 정점들에 대해\n		if (!W[cur][i]) continue; //현재 정점에서 갈 수 없는 정점이거나\n		if (visited & (1 << i)) continue; //이미 방문한 정점이라면 패스한다.\n		ret = min(ret, TSP(i,visited|(1<<i)) + W[cur][i]);\n	  //그렇지 않으면 해당 정점으로 가는 간선을 더하면서 해당 정점에 방문하면서 최솟값을 갱신해나간다.\n	}\n	return ret;\n}\n\n```','외판원 순회 문제(Travelling Salesman Problem) 💵 외판원 순회 문제란? 외판원 순회 문제는 한 정점에서 시작해서 다른 모든 정점을 한 번씩만 방문해서 시작 정점으로 돌아오려 할 때 가능한 최소 비용 및 방문 순서를 찾는 문제이다.  🗒️NOTE 외판원 순회 문제에서는 시작점이 주어질 수도, 그렇지 않을 수도 있지만 어느 경우든 문제가 없다. 최단 순회 경로가 존재한다면 이는 사이클을 이룰 것이고, 따라서 어떤 정점으로부터 시작하든 자기 자신으로 돌아오기 위한 최소 비용은 동일할 것이기 때문이다. 어떤 정점이든 자신으로 돌아오는 경로 또한 동일한 사이클 안에 있다.  ✏️ 풀이(1) 완전 탐색 [외판원 순회 2] 가장 먼저 생각해 볼 수 있는 풀이법은 가능한 방문 순서를 고려해 모두','Travelling Salesman Problem'),(_binary '','2023-11-16 13:08:56.922090',28,87,'2023-11-15 02:34:46.517881',1,'# 조합론, 그래프\n태그: LCA, Permutation\n\n# 최소 공통 조상(Lowest Common Ancestor, LCA)\n\n이런 트리가 주어졌을 때, 4번, 10번 노드의 **공통 조상**들에는 2번, 1번 노드가 있다.\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Graph/img/Untitled.png)\n\n이 중 가장 아래에 있는 ******2번 노드******를 가리켜 4번, 10번 노드의 **최소 공통 조상**(LCA)이라고 한다.\n\n---\n\n## LCA 알고리즘 (1) (문제 :  [가장 가까운 공통 조상](https://www.acmicpc.net/problem/3584))\n\n(**i**) 간선 정보가 주어질 때, 각 노드의 깊이와 해당 노드의 부모 노드를 저장하며 트리를 만든다.\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Graph/img/Untitled%201.png)\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Graph/img/Untitled%202.png)\n\n(ii) 최소 공통 조상을 구해야 하는 두 노드가 주어지면 우선 두 노드의 깊이를 확인한다.\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Graph/img/Untitled%203.png)\n\n(iii) 만약 두 노드의 깊이가 서로 다르다면 좀 더 깊이 있는 노드를 루트 방향으로 거슬러 올라가면서 두 노드의 깊이를 맞추어 준다.\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Graph/img/Untitled%204.png)\n\n(iv) 만약 여전히 두 노드가 서로 다르다면 두 노드가 서로 같은 노드가 될 때까지 둘을 모두 위로 올려본다.\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Graph/img/Untitled%205.png)\n\n(v)  언젠가 두 노드가 서로 같은 노드가 된다면 그 노드가 입력된 두 노드의 최소 공통 조상이 된다.\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Graph/img/Untitled%206.png)\n\n위 트리의 최대 깊이를 $d$라고 할 때, 위 알고리즘의 시간 복잡도는 $O(d)$가 된다.\n\n```cpp\nint findLSA(int u, int v){\n	if (depth[u] < depth[v]) swap(u, v); // 좀 더 깊이 있는 노드를 선택한다.\n\n	while (depth[u] != depth[v]) {       // 두 노드의 깊이가 서로 같아질 때까지 더 깊이 있는 노드의 조상을 찾아보자\n		u = parent[u]; \n	}\n	while (u != v){                      // 깊이가 서로 같음에도 두 노드가 서로 다르다면\n		u = parent[u];                     // 이번에는 두 노드를 함께 위로 올려준다.\n		v = parent[v];                     // 두 노드는 언제나 루트 노드의 자손들이므로 이 과정이 끝나지 않는 경우는 발생하지 않는다.\n	}\n	return u;                            // 최소 공통 조상을 리턴\n}\n```\n\n---\n\n## LCA 알고리즘 (2) Sparse Table (문제 : [LCA 2](https://www.acmicpc.net/problem/11438))\n\n위의 **LCA 알고리즘(1)**의 시간 복잡도가 $O(d)$($d$는 트리의 최대 깊이)라면, 노드가 아주 많이 주어지는 경우에는 어떻게 될까?\n\n만약 트리의 균형이 깨져 다음과 같은 트리가 만들어졌다고 해보자\n\n![Untitled](./img/Untitled%207.png)\n\n여기에서 1번 노드와 9,223,372,036,854,775,807$(=2^{63}-1)$번 노드의 공통 조상을 찾기 위해서 위 **LCA 알고리즘(1)**을 사용한다면 반드시 시간 초과에 빠지게 될 것이다. 다행히 노드가 꽤 많이 주어지는 경우에도 특정 두 노드의 최소 공통 조상을 $\\log d$의 시간에 찾아낼 수 있는 방법이 있다. \n\n(**i**) 알고리즘의 전체적인 맥락은 첫 번째 알고리즘과 동일하지만, 1차원 배열에 자신의 **부모 노드**만을 저장했던 첫 번째와는 달리 이번에는 **2차원 배열에 자신의 $2^i$번째 조상을 저장한다.(이를 가리켜 Sparse Table이라 함)**\n\n \n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Graph/img/Untitled%208.png)\n\n즉 parent[j]에는 j번 노드의 1, 2, 4, 8, 16, … 번째 조상이 무엇인지가 저장되어 있다.\n\n(i**i**) 이번에도 5번, 12번 노드의 LCA를 찾아보자\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Graph/img/Untitled%209.png)\n\n12번 노드가 더 깊이 있으므로 이번에도 5번 노드와 같은 높이로 올려줘야 한다.\n\n만약 12번 노드의 3번째 부모를 찾으려면 어떻게 해야할까? 3을 이진수로 나타내면 $11_{(2)}$이므로 12번 노드의 3번째 부모를 찾으려면 12번 노드의 $2^0$번째 조상의 $2^1$번째 조상을 찾으면 된다. 즉 12번 노드의 $n$ 번째 조상을 찾으려면 $n$의 0번째, 1번째, …. 비트를 돌면서 1인 비트 자리($k$)를 찾아서 $2^k$번째 조상을 찾아나가면 된다. \n\n배열 `parent[12]` 에는 12번 노드의 $2^0, 2^1,...$번째 조상들이 저장되어있으니 이를 보면서  $n$번째 조상을 찾을 수 있다.\n\n5번 노드와 12번 노드의 깊이의 차이는 2이고 이를 2진수로 나타내면 $10_{(2)}$이다. 바로 $2^1$번째 조상을 찾아가자\n\n```cpp\nif (depth[a] < depth[b]) swap(a, b);\n	int diff = depth[a] - depth[b];				// 두 노드의 깊이 차이\n\n	for (int i = 0; i < MAX_DEPTH; i++){\n		if (diff & (1 << i)) a = parent[a][i];		// 깊이 차이만큼 올려주기\n	}\n}\n```\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Graph/img/Untitled%2010.png)\n\n(i**ii**) 두 노드의 높이를 맞췄는데 두 노드가 서로 다른 노드라면 이번에는 둘을 함께 올려주면 된다. 어떻게 올릴 수 있을까? \n\n아래와 같은 트리가 있고 8번, 9번 노드의 LCA를 구하고 싶다고 하자. \n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Graph/img/Untitled%2011.png)\n\n이 트리에서 확인할 수 있는 것은 8, 9번의 LCA인 5번 노드의 조상 노드들은 모두 8, 9번 노드의 공통 조상 노드이기도 하다는 것이다. \n\n따라서 8, 9번 노드와 LCA까지의 깊이 차이를 $d$라고 할 때, 다음과 같은 두 경우가 있을 수 있다.\n\n1) 만약 8번 노드의 $2^i$번째 노드와 9번 노드의 $2^i$번째 노드가 동일하다면, $d \\leq 2^i$이다. \n\n2) 한편 8번 노드의 $2^i$번째 노드와 9번 노드의 $2^i$번째 노드가 동일하지 않다면, $d > 2^i$가 될 것이다.\n\n만약 두 번째 경우라면, 8, 9번 노드는 각각 $2^i$만큼 위로 올려 줘도 괜찮다. 이를 반복하면 두 노드는 두 노드의 최소 공통 조상의 정확히 아래에 위치하게 된다. (즉 $d-1$번째 조상!)\n\n```cpp\nif (a != b) {\n	for (int j = MAX_DEPTH - 1; j >= 0; j--) {			// 조상들을 보면서\n		if (parent[a][j] && parent[a][j] != parent[b][j]) {	// 2^j 조상이 있고, 그것들이 서로 다른 경우\n			a = parent[a][j];				// 두 노드는 2^j만큼 위로 올려줘도 좋다.\n          		b = parent[b][j];                                   \n		}\n	}\n	a = parent[a][0];						// 이 두 노드가 LCA의 정확히 아래에 위치하므로 그 부모를 찾으면 그 노드가 바로 LCA이다.\n}\n```\n\n## LCA 알고리즘 (3) Euler Tour Technique\n\n[오일러 투어](https://en.wikipedia.org/wiki/Euler_tour_technique)를 이용해서 LCA를 찾아보자\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Graph/img/Untitled%2012.png)\n\n위 트리의 정점들을 오일러 투어로 방문한 순서대로 저장하면 다음과 같은 길이 $2 N-1$의 배열을 얻을 수 있다.\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Graph/img/Untitled%2013.png)\n\n5번 노드와 12번 노드의 LCA를 찾으려고 한다면 배열 `node` 에서 5와 12가 가장 먼저 등장하는 구간에서 depth가 가장 작은 노드(여기서 답은 1)를 찾으면 된다.\n\n![Untitled](https://github.com/Al9-Mor9/Concepts/raw/main/Graph/img/Untitled%2014.png)\n\n주어진 특정 구간에서 최솟값을 찾을 때에는 세그먼트 트리를 쓰면 되고 그 시간 복잡도는 $O(\\log N)$이다.','조합론, 그래프 태그: LCA, Permutation  최소 공통 조상(Lowest Common Ancestor, LCA) 이런 트리가 주어졌을 때, 4번, 10번 노드의 공통 조상들에는 2번, 1번 노드가 있다.  Untitled  이 중 가장 아래에 있는 ******2번 노드******를 가리켜 4번, 10번 노드의 최소 공통 조상(LCA)이라고 한다.   LCA 알고리즘 (1) (문제 :  가장 가까운 공통 조상) (i) 간선 정보가 주어질 때, 각 노드의 깊이와 해당 노드의 부모 노드를 저장하며 트리를 만든다.  Untitled  Untitled  (ii) 최소 공통 조상을 구해야 하는 두 노드가 주어지면 우선 두 노드의 깊이를 확인한다.  Untitled  (iii) 만약 두 노드의 깊이가 서로 다','LCA'),(_binary '','2023-11-15 02:22:39.823017',28,88,'2023-11-15 02:34:49.306720',1,'# Bellman Ford Algorithm\n## 📌요약\n![Bellman–Ford_algorithm_example](https://user-images.githubusercontent.com/108309396/224858733-ce1ddd0b-c5c4-466b-9973-50bad7c40aee.gif)\n- E번의 매 단계마다 모든 간선을 전부 확인하면서 하나의 정점에서 모든 정점으로 가는 최단 거리를 구함\n  - 다익스트라와 차이점은 매 반복마다 \"모든\" 간선을 확인한다는 점이다.\n  - 다익스트라는 방문하지 않은 노드 중에서 최단 거리가 가장 가까운 노드만을 방문함\n- 음수 간선이 있어도 최적의 해를 찾을 수 있다.\n  - 음수 간선의 순환 감지 가능\n- 시간 복잡도가 느림 &rarr; $O(VE)$\n  - V번 반복에 대해서 해당 정점과 연결되어 있는 모든 간선(E)를 탐색하기 때문\n\n## 📌벨만-포드 알고리즘 수행과정\n1. 출발 노드 설정\n2. 최단 거리 테이블 초기화\n3. 다음 과정을 V-1(=E)번 반복\n   1. 모든 간선 E개를 하나씩 확인\n   2. 각 간선을 거쳐 다른 노드로 가는 비용을 계산하여 최단 거리 테이블 갱신\n   3. V-1까지 단계를 진행하면 모든 노드에 대한 최단 거리가 확정된다.\n\\* 음수 간선이 발생하는지 확인하고 싶다면 3번 과정을 \"한 번 더\" 수행  \n&rarr; 이 때 최단 거리 테이블이 갱신된다면 음수 간선 순환이 존재하는 것이다. \n\n## 📌Implement (Answer of BOJ 11657)\n```python\nimport sys\n\ninput = sys.stdin.readline\nINF = int(1e9)\n\n# 노드의 개수, 간선의 개수를 입력\nv, e = map(int, input().split())\n# 모든 간선에 대한 정보를 담는 리스트 만들기\nedges = []\n# 최단 거리 테이블을 모두 무한으로 초기화\ndistance = [INF] * (v + 1)\n\n# 모든 간선의 정보 입력\nfor _ in range(e):\n    a, b, c = map(int, input().split())\n    # a번 노드에서 b번 노드로 가는 비용이 c라는 의미 (a -> b 의 비용이 c)\n    edges.append((a, b, c))\n\n\ndef bellman_ford(start):\n    # 시작 노드에 대해서 초기화\n    distance[start] = 0\n    # 전체 v - 1번의 라운드(round)를 반복\n    for i in range(v):\n        # 매 반복마다 \'모든 간선\'을 확인한다.\n        for j in range(e):\n            cur_node = edges[j][0]\n            next_node = edges[j][1]\n            edge_cost = edges[j][2]\n            # 현재 간선을 거쳐서 다른 노드로 이동하는 거리가 더 짧은 경우\n            if distance[cur_node] != INF and distance[next_node] > distance[cur_node] + edge_cost:\n                distance[next_node] = distance[cur_node] + edge_cost\n                # v번째 라운드에서도 값이 갱신된다면 음수 순환이 존재\n                if i == v - 1:\n                    return True\n    return False\n\n\n# 벨만 포드 알고리즘 수행\nnegative_cycle = bellman_ford(1)\n\n# 음수 순환이 존재하면 -1 출력\nif negative_cycle:\n    print(\"-1\")\nelse:\n    # 1번 노드를 제외한 다른 모든 노드로 가기 위한 최단 거리를 출력\n    for i in range(2, v + 1):\n        # 도달할 수 없는 경우, -1 출력\n        if distance[i] == INF:\n            print(\"-1\")\n        # 도달할 수 있으면 거리 출력\n        else:\n            print(distance[i])\n```\n\n\n# Floyd-Warshall Algorithm\n## 📌요약\n- 한 번 실행하여 모든 노드 간 최단 경로를 구하는 알고리즘\n- 음의 간선이 포함된 그래프에서도 사용 가능\n- 알고리즘은 여러 라운드로 구성\n  - 라운드마다 각 경로에서 새로운 중간 노드를 선택하고, 더 짧은 길이를 선택하는 과정을 반복\n- 시간 복잡도는 $O(V^3)$\n\n## 📌플로이드-워셜 알고리즘 수행과정\n1. 모든 노드 간 최단 거리를 구해야 하므로 2차원 인접 행렬 구성\n  - 방향이 없을 경우 (1, 4), (4, 1)에 모두 적용, 방향이 있을 경우 (1, 4)에만 적용\n2. 그래프의 노드와 간선에 따라 최단 거리 테이블을 갱신한다.\n3. 점화식을 적용하며 매 라운드마다 최단 거리 테이블을 갱신한다. a는 출발노드, b는 도착노드, k는 중간노드\n![image](https://user-images.githubusercontent.com/108309396/224861005-e1a19e02-01c1-49ef-97e0-acbe78174006.png)\n\n### [step 0] 초기 그래프의 노드와 간선에 따라  최단 거리 테이블을 갱신한다.\n![image](https://user-images.githubusercontent.com/108309396/224861119-6f6a2e86-1f37-460f-b09c-787e4c23bfd4.png)  \n- 이동 가능한 간선이 없을 시 INF, 제자리는 0\n### [step 1] 1번 노드를 거쳐 가는 경우를 고려하여 테이블을 갱신한다.\n![image](https://user-images.githubusercontent.com/108309396/224861128-b0b83bc3-5d2e-43f6-bbca-a82eee53c4dd.png)\n### [step 2] 2번 노드를 거쳐 가는 경우를 고려하여 테이블을 갱신한다.\n![image](https://user-images.githubusercontent.com/108309396/224861133-ddec7923-042b-4c43-91c6-71dbec6a5fc5.png)\n### [step ~] 3번, 4번, ... 노드를 거쳐 가는 경우를 고려하여 테이블을 갱신한다.\n![image](https://user-images.githubusercontent.com/108309396/224861140-7a252e4b-68b6-4f35-9d7f-481d266fe532.png)  \n![image](https://user-images.githubusercontent.com/108309396/224861155-68e1bf54-394f-44bf-b92c-a13807dfdb09.png)\n\n\n## 📌Implement\n```python\nimport sys\n\ninput = sys.stdin.readline\nINF = int(1e9)\n\n# 노드의 개수(n)과 간선의 개수(m) 입력\nn = int(input())\nm = int(input())\n\n# 2차원 리스트 (그래프 표현) 만들고, 무한대로 초기화\ngraph = [[INF] * (n + 1) for _ in range(n + 1)]\n\n# 자기 자신에서 자기 자신으로 가는 비용은 0으로 초기화\nfor a in range(1, n + 1):\n    for b in range(1, n + 1):\n        if a == b:\n            graph[a][b] = 0\n\n# 각 간선에 대한 정보를 입력받아, 그 값으로 초기화\nfor _ in range(m):\n    # A -> B로 가는 비용을 C라고 설정\n    a, b, c = map(int, input().split())\n    graph[a][b] = c\n\n# 점화식에 따라 플로이드 워셜 알고리즘을 수행\nfor k in range(1, n + 1):\n    for a in range(1, n + 1):\n        for b in range(1, n + 1):\n            graph[a][b] = min(graph[a][b], graph[a][k] + graph[k][b])\n\n# 수행된 결과를 출력\nfor a in range(1, n + 1):\n    for b in range(1, n + 1):\n        if graph[a][b] == INF:\n            print(\'INFINITY\', end=\' \')\n        else:\n            print(graph[a][b], end=\' \')\n    print()\n```\n\n# 다익스트라 vs 벨만 포드 vs 플로이드 워셜\n## 📌다익스트라\n- 시간 복잡도는 $O(ElogE)$\n- 하나의 정점에서 모든 정점으로 가는 최단거리를 구함.\n- 우선순위 큐 사용\n   1. 시작 노드 결정 0으로 초기화 후 우선순위 큐에 담음\n   2. 나머지 노드 무한대로 초기화\n   3. 우선순위 큐에서 pop한 후 그 노드에서 갈 수 있는 노드를 확인\n   4. 더 빠르다면 갱신하고 우선순위 큐에 넣는다.\n   5. 방문했거나, 더 느리다면 continue\n   6. 우선순위 큐가 빌 때까지 3-5번을 반복한다.\n\n## 📌벨만 포드\n- 시간 복잡도는 $O(V*E) \\~= O(V^3)$\n- 하나의 정점에서 모든 정점으로 가는 최단거리를 구함.\n- 가중치가 음수인 경우도 적용 가능\n- 가중치가 사이클을 이루는 경우 체크 가능\n   1. 시작 노드 결정 0으로 초기화\n   2. 나머지 노드 무한대로 초기화\n   3. 나머지 노드 방문하며 주변 노드에 방문하는 최단거리 갱신 (v-1 번 반복)\n   4. 한 번 더 방문하면 업데이트 되는지 확인 (사이클 확인, 사이클이 있다면 false)\n\n## 📌플로이드 워셜\n- 시간 복잡도는 $O(V^3)$\n- 모든 정점에서 모든 정점으로 가는 최단거리를 구함.\n- 그러므로 그래프는 2차원 배열\n- 가중치가 음수인 경우도 적용 가능\n   1. 인접행렬을 저장할 2차원 배열을 만들고 무한대로 초기화\n   2. 간선정보저장, 제자리 0으로 초기화\n   3. 경유지를 기준으로, 해당 경우지를 거쳐가는게 빠르다면 갱신\n     (i 가 경유지라면, A[j][k] = min(A[j][k],A[j][i]+A[i][k]) )\n   4. 모든 정점을 경유지로 선정해 3번 반복','Bellman Ford Algorithm 📌요약 Bellman–Ford_algorithm_example](https://user-images.githubusercontent.com/108309396/224858733-ce1ddd0b-c5c4-466b-9973-50bad7c40aee.gif) - E번의 매 단계마다 모든 간선을 전부 확인하면서 하나의 정점에서 모든 정점으로 가는 최단 거리를 구함 - 다익스트라와 차이점은 매 반복마다 모든 간선을 확인한다는 점이다. - 다익스트라는 방문하지 않은 노드 중에서 최단 거리가 가장 가까운 노드만을 방문함 - 음수 간선이 있어도 최적의 해를 찾을 수 있다. - 음수 간선의 순환 감지 가능 - 시간 복잡도가 느림 → $O(VE)$ - V번 반복에 대해서 해당 정점과 연','Shortest Path Algorithm'),(_binary '','2023-11-15 02:23:12.251135',28,89,'2023-11-15 02:34:51.907387',1,'# Topological sort\n---\n\n## DAG(Directed Acyclic Graph)\n<br>\n\n- DAG는 사이클이 없는 방향(유향) 그래프이다.\n\n- 트리는 DAG에 속한다. (DAG는 루트가 여러개일 수 있다.)\n\n- DAG를 구성하는 작업(Vertex)들의 특징은 선, 후 관계를 가지는것 이다.\n\nDAG의 예시로는 선수강 과목, 작업 순서 등 순서가 있고 Acyclic한 트랜잭션을 표현할 수 있다.\n\n<br>\n\n## Topological sort\n\n선/후 관계만 표현되어있는 업무들을 순서대로 배치하기 위해 위상 정렬을 한다. 선/후 관계가 위배되지 않도록 정렬하기 때문에, 다양한 해를 가질 수 있다.\n\n![DAG_sort](./img/topo1.png)\n\n위상 정렬에는 2 가지 방법이 있다.\n\n1. 진입 차수와 BFS - Queue\n2. DFS - Stack\n \n두 알고리즘 모두 간선과 노드만큼 반복하여 시간복잡도가 O(V + E) 이다.\n\n<br>\n\n### Topological Sort - BFS\n\n가장 앞에 두어야할 노드는 진입하는 간선이 없는 노드가 되어야 한다. 즉 진입 차수(in-degree)가 0인 놈을 기준으로 정렬해나가는 개념이다.\n\n---\n- 사전에 진입 차수를 구해 놓는다.\n- 다음 반복\n   1. 진입 차수 0인 노드를 Queue에 넣는다. \n       - 정답 Array에 저장한다.\n\n   2. cur(pop in Queue)에서 진출되는 노드들의 진입 차수를 줄여준다. (진입 차수 0을 만드는 행위.)\n---\n\n코드로 구현하면 다음과 같다.\n\n```python \nfrom collections import deque\n\nans = []\nv, e = map(int, input().split())\nin_degree = [0] * (v + 1)\ngraph = [[] for _ in range(v + 1)]\nqueue = deque()\n\nfor i in range(e):\n    a, b = map(int, input().split())\n    graph[a].append(b)\n    in_degree[b] += 1   # 진입 차수를 저장하자.\n\nfor i in range(1, v + 1):\n    if in_degree[i] == 0:\n        queue.append(i) # 진입 차수 0인 것들을 queue에 삽입.\n\nwhile queue:\n    cur = queue.popleft()\n    ans.append(cur)\n\n    for node in graph[cur]:\n        in_degree[node] -= 1    # 정렬된 노드에 대한 정보를 지운다.\n        if not in_degree[node]:\n            queue.append(node)\n\nprint(ans)\n```\n\n<br>\n\n### Topological Sort - DFS\n\n\n위상 정렬된 그래프를 보면, 임의의 중간 노드에서 끝까지 위상정렬되어 있는 부분 집합으로 볼 수 있다.\n임의의 노드로 DFS를 진행하며 위상 정렬하고, 방문하지 않은 노드로 다시 DFS하는데, 선행 노드로 취급하여 앞에다 두면 된다.\n\n가장 깊은 놈을 stack에 넣고 빠지면서\nstack의 LIFO를 생각하면 쉽게 구현할 수 있다.\n\n---\n다음 반복\n  - 방문하지 않은 임의의 노드를 선택한다.\n  - 노드를 기준으로 DFS를 하는데, __깊은 곳에서 나오면서__ stack에 넣는다. (깊은 놈이 먼저 들어가게)\n  - 모두 방문했다면, stack을 역순으로 뒤집는다.\n  \n(DFS를 할 때, 재귀나 stack중 편한 것을 사용하면 된다. stack을 쓸 경우 기존 stack과 구분하여 사용해야 한다.)\n\n---\n\n\n코드로 구현하면 다음과 같다.\n\n```python \n\n# 재귀를 이용한 DFS\ndef dfs_recursive(v):\n    visited[v] = 1\n    for node in graph[v]:\n        if not visited[node]:\n            dfs_recursive(node)\n    # 가장 깊이 들어간 후, 나오면서 stack에 적재.\n    stack.append(v)\n\n\n# 스택을 이용한 DFS\ndef dfs_stack(v):\n    tmp = [v]\n\n    while tmp:\n        cur = tmp[-1]\n        visited[cur] = 1\n        for node in graph[cur]:\n            if not visited[node]:\n                tmp.append(node)\n                break\n        else:\n            # 들어갈 곳이 없을 때, 나오면서 넣어준다.\n            cur = tmp.pop()\n            stack.append(cur)\n        \nans = []\nv, e = map(int, input().split())\nvisited = [0] * (v + 1)\ngraph = [[] for _ in range(v + 1)]\nstack = []\n\nfor i in range(e):\n    s, e = map(int, input().split())\n    graph[s].append(e)\n\n\nfor node in range(1, v + 1):\n    if not visited[node]:\n        # 둘 중 하나를 고르면 된다.\n        dfs_recursive(node)\n        dfs_stack(node)\n\nwhile stack:\n    ans.append(stack.pop())\n\nprint(ans)\n```','Topological sort  DAG(Directed Acyclic Graph)     DAG는 사이클이 없는 방향(유향) 그래프이다.   트리는 DAG에 속한다. (DAG는 루트가 여러개일 수 있다.)   DAG를 구성하는 작업(Vertex)들의 특징은 선, 후 관계를 가지는것 이다.  DAG의 예시로는 선수강 과목, 작업 순서 등 순서가 있고 Acyclic한 트랜잭션을 표현할 수 있다.    Topological sort 선/후 관계만 표현되어있는 업무들을 순서대로 배치하기 위해 위상 정렬을 한다. 선/후 관계가 위배되지 않도록 정렬하기 때문에, 다양한 해를 가질 수 있다.  DAG_sort  위상 정렬에는 2 가지 방법이 있다.    진입 차수와 BFS - Queue  DFS - Stack  두 알고','Topological_sort'),(_binary '','2023-11-15 02:24:52.843855',29,90,'2023-11-15 02:34:56.981591',1,'# Prime Number\n\n## 소수 판별 알고리즘\n\n특정 정수 N 이 주어졌을 때, 소수인지 여부를 판별하고자 한다. 몇 가지 방법을 정리해보자. \n\n### 0. Brute Force\n\n가장 쉬운 방법은 N을 1 부터 N - 1 까지 나누어 보는 것이다. 직관적이지만 매우 오래 걸린다. \n\n### 1. Square Root\n\nN이 a, b  (a < b)  로 나누어 진다고 가정해보면, 다음이 성립한다.\n\n$$a < \\sqrt N < b $$\n<br>\n \n$$18: 1, 2, 3, 6, 9, 18 $$ \n$$ \\sqrt N = 4.xx $$\n<br>\n\n$$36: 1, 2, 3, 4, 6, 9, 12, 18, 36 $$\n$$ \\sqrt N = 6 $$\n\n$\\sqrt N$ 보다 작은 수만 탐색해 보면 된다. \n- 시간 복잡도: $O(logN)$\n<br><br>\n\n\n---\n## 에라토스 테네스의 체\n\n- N의 소수 판별뿐만 아니라, N보다 작은 소수를 찾고 싶다면?\n\n다음과 같은 방법을 통해 합성수를 걸러나가자.\n\n- n - 1개 정수 리스트 할당.\n- 2의 배수 모두 제거\n    - 다음 최소값을 선택하고, 배수를 모두 제거 (2 다음은 3)\n    - $\\sqrt N$ 까지 반복\n\n- 시간 복잡도: $O(N log(logN))$\n[시간 복잡도](https://medium.com/@chenfelix/time-complexity-sieve-of-eratosthenes-fb0184da81dc)\n\n```python\nimport math\n\nn = 1000 \narr = [True for i in range(n + 1)] \nfor i in range(2, int(math.sqrt(n)) + 1): \n    if arr[i] == True: \n\n        j = 2 \n        while i * j <= n:\n            arr[i * j] = False\n            j += 1\n\nfor i in range(2, n + 1):\n    if arr[i]:\n        print(i, end=\' \')\n\n```\n\n## 오일러 피\n\n오일러 피 함수는 n이하의 자연수 중 n과 서로소인 수의 개수를 구하는 함수이다. 다음 4가지 식을 이해하면(외우거나) 서로소의 개수를 구하기 편하다.\n\n소수 p와 자연수 a에 대해,\n\n$$ φ(p) = p - 1$$ \n\n$$ φ(p^a) = p^a - p^{a-1} = p^a(1-{1\\over p}) $$ \n\n서로소 n, m에 대해\n\n$$ φ(mn) = φ(m)φ(n)$$\n\n따라서 소수 p, q와 자연수 a, b에 대해\n\n$$ φ( p^a q^b) = (p^a - p^{a-1})(q^b - q^{b-1}) = p^a(1-{1\\over p})q^b(1-{1\\over q}) $$\n\n<br><br>\n\n>간단하게 해석하면, n이하의 자연수 중 n과 서로수인 수의 개수는 n을 구성하는 소인수의 연산으로 정의할 수 있다는 것이다.\n- $ n = p_1^{k_1}p_2^{k_2}...p_r^{k_r} $ 일 때,\n\n![](./src/oiler_pi.PNG)\n\n\n```python \nop = N\nfor i in range(2, int(N**0.5) + 1):\n    if N % i == 0:\n        while N % i == 0:\n            N //= i\n \n        op -= op / i\n \nif N > 1:\n    op -= op / N\n\n```','Prime Number 소수 판별 알고리즘 특정 정수 N 이 주어졌을 때, 소수인지 여부를 판별하고자 한다. 몇 가지 방법을 정리해보자.  0. Brute Force 가장 쉬운 방법은 N을 1 부터 N - 1 까지 나누어 보는 것이다. 직관적이지만 매우 오래 걸린다.  1. Square Root N이 a, b  (a < b)  로 나누어 진다고 가정해보면, 다음이 성립한다.  $$a < \\sqrt N < b $$   $$18: 1, 2, 3, 6, 9, 18 $$ $$ \\sqrt N = 4.xx $$   $$36: 1, 2, 3, 4, 6, 9, 12, 18, 36 $$ $$ \\sqrt N = 6 $$  $\\sqrt N$ 보다 작은 수만 탐색해 보면 된다. - 시간 복잡도: $O(logN)$    에라토스 ','prime_number'),(_binary '','2023-11-16 00:53:21.364189',30,92,'2023-11-15 04:03:34.416999',1,'# 1. Introduction to Operating Systems\n- OS: 컴퓨터 시스템의 **자원을 효율적으로 관리**\n  - resource(자원): CPU, Memory, I/O Device\n\n# 컴퓨터 시스템의 요소\n1. 하드웨어 - CPU, Memory, I/O device 등등의 기본 computing resources\n2. 운영체제 - 하드웨어 제어, 응용프로그램 간의 컴퓨팅 자원 사용 조정\n3. 어플리케이션 - word processors, spreadsheets, compilers\n4. 사용자  \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/8b39305b-16a4-4656-8b67-d05217dc7cda)\n\n\n# 운영체제란?\n- 컴퓨터 하드웨어 바로 위에 설치되어 **사용자 및 다른 소프트웨어와 하드웨어를 연결**하는 소프트웨어 계층\n- 협의의 운영체제 &rarr; **커널**: OS의 핵심부분으로 *메모리에 상주*하는 부분\n- 광의의 운영체제: 커널 뿐 아니라 *각종 주변 시스템 유틸리티를 포함*한 개념\n  - 커널 + 미들웨어 프레임워크 + 시스템 프로그램\n  - 미들웨어란? 응용 프로그램과 OS 또는 다른 응용 프로그램 간의 상호 작용을 돕는 소프트웨어 계층\n  - 시스템 프로그램? 주로 OS와 관련된 작업을 수행하며, 시스템 자원을 관리하고 제어. \n\n# 운영체제의 목적\n1. 자원 관리(Resource allocator)\n   - CPU, Memory, I/O Device 등의 효율적 관리\n     - 사용자 간의 형평성 있는 자원 분배\n     - 최대한의 성능\n   - 사용자 및 OS 자신의 보호\n   - Process, File, 메시지 등을 관리\n2. 컴퓨터 시스템을 편리하게 사용할 수 있는 환경을 제공(Ease of use)\n   - **Virtualization(가상화): 각 프로그램들이 독자적 컴퓨터에서 수행되는 것 같은 환상을 제공**\n   - 하드웨어를 직접 다루는 복잡한 부분은 OS가 대행\n\n# 운영체제의 분류\n1. 동시 작업 가능 여부\n   - Single tasking: 한 번에 하나의 작업만 처리 ex) MS-DOS\n   - Multi tasking: 동시에 두 개 이상의 작업 처리 &rarr; 현재 대부분의 OS ex) UNIX\n2. 사용자의 수\n   - Single user: MS-DOS\n   - Multi user: UNIX\n3. 처리 방식\n   - 일괄 처리(Batch processing)\n   - **시분할(Timesharing)**: 여러 작업을 수행할 때 OS가 시간 단위로 분할하여 사용\n     - interactive service 가능\n   - 실시간(Realtime OS): 정해진 시간 안에 어떠한 일이 반드시 종료됨이 보장되어야 함\n\n# 운영체제의 예\n1. UNIX\n   - 서버를 위해 만들어짐\n   - 코드의 대부분을 C언어로 작성\n   - 높은 이식성\n   - 최소한의 커널 구조\n   - 복잡한 시스템에 맞게 확장 용이\n   - 소스 코드 공개\n   - 프로그램 개발에 용이\n   - 다양한 버전: Linux, Solaris..\n2. MS Windows\n   - MS사의 다중 작업용 GUI 기반 운영 체제\n   - 네트워크 환경 강화\n   - DOS용 응용 프로그램과 호환성 제공\n   - 불안정성(초창기)\n   - 풍부한 지원 소프트웨어','1. Introduction to Operating Systems   OS: 컴퓨터 시스템의 자원을 효율적으로 관리  resource(자원): CPU, Memory, I/O Device  컴퓨터 시스템의 요소   하드웨어 - CPU, Memory, I/O device 등등의 기본 computing resources  운영체제 - 하드웨어 제어, 응용프로그램 간의 컴퓨팅 자원 사용 조정  어플리케이션 - word processors, spreadsheets, compilers  사용자 image  운영체제란?   컴퓨터 하드웨어 바로 위에 설치되어 사용자 및 다른 소프트웨어와 하드웨어를 연결하는 소프트웨어 계층  협의의 운영체제 → 커널: OS의 핵심부분으로 메모리에 상주하는 부분  광의의 운영체제: 커널 뿐','1. Introduction to Operating Systems'),(_binary '','2023-11-16 00:53:42.818449',30,93,'2023-11-15 04:03:36.710513',1,'# 컴퓨터 시스템 구조\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/28f2c956-9242-439f-8650-1855ae7a834c)\n1. CPU: 매 clock cycle마다 memory에서 instruction을 읽어 실행\n   - mode bit: kernel mode / user mode\n   - interrupt line: instruction 한 줄 수행 후 interrupt line을 확인해 들어온 interrupt가 있는지 확인\n   - registers: memory보다 빠르면서 정보를 저장할 수 있는 작은 공간\n2. Memory: CPU의 작업 공간\n3. I/O Device: disk, keyboard, ...\n   - 각각 device controller와 local buffer가 존재\n   - device controller: I/O Device의 작은 CPU 역할, 작업 완료 후 CPU에 interrupt\n   - local buffer: device controller의 작업 공간\n4. timer: 특정 프로그램이 CPU를 독점하는 것을 막음\n- CPU의 처리속도가 가장 빠르고 I/O device의 처리속도가 가장 느림\n\n# Interrupt\n- interrupt 당한 시점의 register와 program counter(PC)를 save한 후 CPU의 제어를 interrupt handler에 넘긴다\n- **Interrupt**(hardware interrupt): 하드웨어(키보드, 하드디스크..)가 발생시킨 interrupt\n- **Trap**(software interrupt): Exception, System call(user program이 커널 함수 호출)\n- interrupt 관련 용어\n   - **interrupt vector**: 해당 interrupt handler의 주소를 가지고 있음\n   - **interrupt handler** = interrupt service routine: 해당 interrupt를 처리하는 kernel 함수\n\n# Mode bit\n- user program의 잘못된 수행으로 다른 프로그램 및 운영체제에 피해가 가지 않도록 하기 위한 보호 장치\n- mode bit = 0: **Kernel mode** - previleged instruction 수행\n  - Interrupt나 Exception 발생 시 하드웨어가 mode bit을 0으로 바꿈\n  - user program에게 CPU를 넘기기 전에 mode bit을 1로 set\n- mode bit = 1: **User mode** - 제한된 instruction 수행\n\n# Timer\n- 정해진 시간이 흐른 뒤 OS에게 제어권이 넘어가도록 interrupt를 발생시킴\n- 타이머 값이 매 clock 1씩 감소하다가 0이 되면 timer interrupt 발생\n- **특정 프로그램이 CPU를 독점하는 것을 막음**\n- *time sharing* 구현, 현재 시간 계산 등을 위해 사용\n\n# DMA Controller(Direct Memory Access)\n- 원인: I/O interrupt가 자주 들어오는 경우, CPU에 Interrupt를 걸면 CPU의 overhead가 커짐\n- 목적: 빠른 I/O device를 메모리에 가까운 속도로 처리하기 위해 사용\n- 과정\n   1. CPU의 중재 없이 device controller가 device의 buffer storage의 내용을 메모리에 block 단위로 직접 전송\n   2. 바이트 단위가 아니라 block 단위로 interrupt 발생시킴\n   3. DMA controller가 I/O interrupt를 받아 메모리에 복사하고 CPU에는 한 번만 interrupt 발생시킴\n- CPU와 DMA 둘 다 Memory에 접근 가능 &rarr; Memory controller: CPU, DMA 동시 접근 시 control\n\n# I/O Device Controller\n- 해당 I/O device를 관리하는 일종의 작은 CPU\n- control register, status register\n- local buffer = 일종의 data register\n- I/O는 실제 device와 local buffer 사이에서 일어남\n- I/O가 끝났을 경우 interrupt로 CPU에 알림(Hardware interrupt)\n- **device driver**: OS 코드 중 각 장치별 처리 루틴(handler) &rarr; Software\n- **device controller**: 각 장치를 통제하는 작은 CPU &rarr; Hardware\n\n# I/O Execution\n- 모든 I/O instruction은 privileged instruction\n- user program은 어떻게 I/O를 하는가?\n   - **system call**: OS에게 I/O request를 보냄(Trap - software interrupt)\n   - trap을 사용하여 interrupt vector의 특정 위치로 이동\n   - 제어권이 interrupt vector가 가리키는 interrupt handler로 이동\n   - 올바른 I/O request인지 확인 후 I/O 진행\n   - I/O 완료 시 제어권을 system call 다음 instruction으로 넘김\n\n# System Call\n- user program이 OS의 서비스를 받기 위해 **커널 함수를 호출**\n- **CPU 제어권이 OS에게** 넘어감\n\n# Synchronous I/O & Asynchronous I/O\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/b6cda4d5-78f7-413f-b482-afd8955a0278)\n1. Synchronous I/O\n   - I/O request 후 입출력 작업이 완료된 후에야 제어가 user program에 넘어감\n   1. 구현 방법 1\n     - I/O가 끝날 때까지 CPU를 낭비시킴\n     - 매 시점 하나의 I/O만 일어날 수 있음\n   2. 구현 방법 2\n     - I/O가 완료될 때까지 해당 프로그램에게서 CPU를 빼앗음\n     - I/O 처리를 기다리는 줄에 그 프로그램을 줄 세움\n     - 다른 프로그램에게 CPU를 줌\n2. Asynchronous I/O\n   - I/O가 시작된 후 입출력 작업이 끝나기를 기다리지 않고 제어가 user program에 즉시 넘어감\n- 두 경우 모두 I/O의 완료는 interrupt로 알려줌\n\n# Memory Mapped I/O\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/837bfb06-7894-4aba-bf68-503e90647166)  \n1. 일반적인 I/O 처리 방법\n   - 메모리 상에 I/O 처리를 위한 별도의 instruction이 존재\n   - 해당 instruction을 실행하여 I/O 처리\n   - 일반적으로 입출력 장치와 메모리 간에 데이터를 주고받기 위해 별도의 명령어나 포트를 사용\n2. Memory Mapped I/O\n   - I/O 처리를 위한 instruction을 메모리 주소의 연장선 상에 놓는 방법\n   - 입출력 장치를 다루는 소프트웨어 코드를 단순화하고 다른 메모리 위치와 구별할 필요 없이 일관된 방식으로 접근 가능\n\n# 저장장치 계층 구조\n- ![image](https://github.com/Al9-Mor9/CS-study/assets/108309396/c46646cc-5a89-4353-a101-b656462dc1d7)\n- 위로 갈 수록 speed&uarr;, cost&uarr;, 용량&darr;\n- DRAM, Cache memory(SRAM), Registers &rarr; volatile\n- Primary(executable) 계층: byte 단위로 접근 가능한, CPU가 직접 접근 가능, 휘발성\n- Secondary 계층: sector 단위로 접근 가능, CPU가 직접 접근 불가, 비휘발성\n- caching: copying information into faster storage system &rarr; 데이터의 재사용성 목적\n\n# Program Execution\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/e8b5630f-1ae3-441b-a972-815474c53861)  \n- 실행파일 A, B 실행 시 각각 독자적인 virtual memory가 생성됨(각 프로세스 별 address space 존재)\n- address translation을 통해 필요한 부분만 Physical memory에 올림\n- 구성\n  1. Virtual memory: 프로그램을 실행하는 시점에 해당 프로그램만의 독자적인 address space를 생성하는 것\n     - stack: 함수를 호출하거나 리턴할때 사용하는 영역\n     - data: 변수 등 프로그램이 사용하는 데이터들을 담고 있는 영역\n     - code: CPU에서 실행할 기계어 코드를 담고 있는 영역\n  2. Physical memory\n     - Address Space 중에서 당장 필요한 부분이 물리적 메모리에 남음\n     - 당장 필요하지 않은 것은 swap area로 내려감\n  3. Kernal Address Space\n     - code: CPU가 수행할 기계어들이 모인 부분. 실행 파일에서의 코드들이 올라옴\n     - data: 전역 변수, 정적 변수, 상수 등의 데이터가 저장\n     - stack: 함수 호출 및 임시 데이터 저장에 사용\n  4. Swap area: 경우에 따라서 프로그램이 종료되기 전까지 보관해야 할 부분은 disk의 swap area에 내려놓음, 메모리의 연장 공간\n\n# Kernel Address Space contents\n![image](https://github.com/Al9-Mor9/CS-study/assets/108309396/079e2885-d11f-4137-9fe1-5e93efbca0ef)\n\n# Funtion\n1. 사용자 정의 함수 : 내가 프로그램에 정의한 함수\n2. 라이브러리 함수 : 다른사람이 만들어 놓은 함수이지만 내 프로그램의 실행 파일에 포함되어 있는 함수\n3. 커널 함수 : 운영체제 프로그램의 함수, 커널 함수의 호출 = System call\n- 사용자 정의 함수든 라이브러리 함수든 컴파일해서 실행파일을 만들게 되면 내 프로그램 안에 들어있는 함수이기 때문에 언제든 자유롭게 실행할 수 있음\n- 반면 커널함수의 경우 내 프로그램의 함수가 아니라 커널코드에 포함된 함수이기 때문에 시스템 콜을 통해서 CPU 제어권을 넘겨야만 실행이 가능\n','컴퓨터 시스템 구조   image   CPU: 매 clock cycle마다 memory에서 instruction을 읽어 실행   mode bit: kernel mode / user mode  interrupt line: instruction 한 줄 수행 후 interrupt line을 확인해 들어온 interrupt가 있는지 확인  registers: memory보다 빠르면서 정보를 저장할 수 있는 작은 공간   Memory: CPU의 작업 공간  I/O Device: disk, keyboard, ...   각각 device controller와 local buffer가 존재  device controller: I/O Device의 작은 CPU 역할, 작업 완료 후 CPU에 interrupt  local b','2. System Structure & Program Execution'),(_binary '','2023-11-15 04:44:26.821205',30,94,'2023-11-15 04:03:39.517996',1,'- **\"Process is a program in execution\"**\n- Context? 현재 시점의 상태를 규명하기 위해 필요한 요소들(timesharing 구현을 위해 필요)\n  1. CPU 수행 상태를 나타내는 hardware context: Program Counter, 각종 register\n  2. 프로세스의 address space: code, data, stack\n  3. 프로세스 관련 kernel data structure: PCB, kernel stack(프로세스 별로 보유)\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/0b9d2f45-ddc5-4ade-84c5-f7c87b075b61)\n\n# Process Control Block(PCB)\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/742c2a5b-3e8f-4dde-a9aa-54a5bd2fd801)  \n- OS가 각 프로세스를 관리하기 위해 프로세스 당 유지하는 정보\n- 구조체로 유지\n1. OS가 관리 상 사용하는 정보: Process state, PID, scheduling information, priority\n2. CPU 수행 관련 하드웨어 값: PC, registers\n3. 메모리 관련: code, data, stack의 위치 정보\n4. 파일 관련: Open file descriptors\n\n# Kernel Stack\n- **Kernel Stack**이란?\n  - kernel mode에서 실행되는 code와 data를 저장하는 stack\n- Kernel stack의 목적\n  1. 커널 함수 호출: 함수가 실행되는 동안 필요한 데이터와 정보를 스택에 저장\n  2. interrupt 처리: interrupt 처리에 필요한 데이터 및 register 상태 등을 저장\n  3. context switching: 현재 실행 중인 프로세스의 state 정보를 저장하고 다음 작업의 state 정보를 로드\n\n# Process State\n- 프로세스는 state가 변경되며 수행됨\n1. **Running**: CPU 소유권을 가지고 instruction을 수행 중인 상태\n2. **Ready**: CPU를: CPU를 기다리는 상태(메모리 등 다른 조건 모두 만족)\n3. **Blocked**(wait, sleep)\n   - CPU를 주어도 당장 instruction을 수행할 수 없는 상태\n   - Process 자신이 요청한 event(I/O 등)이 즉시 만족되지 않아 이를 기다리는 상태\n   - ex) 디스크에서 file을 읽어와야 하는 경우\n4. **Suspended**(stopped)\n   - 외부적인 이유로 프로세스의 수행이 정지된 상태\n   - 프로세스는 통째로 디스크에 swap out된다\n   - ex) 사용자가 프로그램을 일시 정지시킨 경우(break key)\n   - ex) 시스템이 여러 이유로 프로세스를 잠시 중단시킴(메모리에 너무 많은 프로세스가 올라와 있을 때) \n5. New: 프로세스가 생성 중인 상태\n6. Terminated: execution이 끝난 상태 \n\n## Blocked vs Suspended\n- Blocked: 자신이 요청한 event가 만족되면 Ready\n- Suspended: 외부에서 resume해주어야 active\n\n## Process State Diagram\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/7be4d252-fb31-446b-b80d-b4f7ca3d5e8d)  \n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/57675129-62ad-43ee-b4a9-774363ced87c)  \n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/554ddfd7-da46-4a3a-a723-e4ca12137f2f)  \n\n# Context Switching\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/b332724e-54f9-4db0-8a7c-6dbb551bcb1f)  \n- Context Switching: CPU를 한 프로세스에서 다른 프로세스로 넘겨주는 과정\n  1. CPU를 내어주는 프로세스의 상태를 그 프로세스의 PCB에 저장\n  2. CPU를 새롭게 얻는 프로세스의 상태를 PCB에서 읽어옴\n- Memory map의 역할\n   - 현재 실행 중인 프로세스의 address space를 저장하고 새로운 프로세스의 address space을 로드함으로써\n→ logical address와 physical address 간의 매핑 유지\n   - 페이지 테이블 갱신\n   - 보호 및 권한 설정 → 메모리 보호와 가상 메모리 관리\n\n## Context Switching 주의사항\n- System call이나 interrupt 발생 시 반드시 context switching이 일어나는 것 X\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/94ca7922-226c-4336-a3c0-ea622e7bbdc5)\n- (1)의 경우에도 CPU 수행 정보 등 context의 일부를 PCB에 save\n- But! context switching을 하는 (2)의 경우 부담이 훨씬 큼(cache memory flush)\n  - cache memory flush: A 프로세스를 위해 사용하던 캐시 메모리를 모두 비우는 것 &rarr; 다시 프로세스 A로 돌아왔을 때 비어있음\n\n# Queue for Process Scheduling\n1. Job queue: 현재 시스템 내에 있는 모든 프로세스의 집합\n2. Ready queue: 현재 메모리 내에 있으면서 CPU를 잡아서 실행되기를 기다리는 프로세스의 집합\n3. Device queue: I/O device의 처리를 기다리는 프로세스의 집합\n\n## Ready queue와 device queue\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/8a5eb98b-54cf-418e-8607-1fc4c43091c3)  \n- 실제 시스템에서 큐가 어떻게 관리되는지를 자료구조의 형태로 나타낸 그림\n- ready queue에 process들이 순서대로 대기 중\n- magetic tape는 대기엹X, disk에 process 대기 중\n- PCB에는 pointer 존재 &rarr; 포인터를 연결하여 큐 생성\n- head : Queue에서 데이터가 제거되는 위치를 가리키는 포인터\n- tail : Queue에서 데이터가 추가되는 위치를 가리키는 포인터\n\n## Process Scheduling Queue\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/4de2666d-22ed-4bfc-a70d-92f2a139e906)\n- 프로그램이 실행되면 Ready Queue가서 줄 섬\n- 언젠가 자기 차례가 되어 CPU를 얻음\n- I/O와 같이 시간이 오래걸리는 작업을 수행하면 해당 작업을 수행하는 Queue로 가서 줄서서 처리(Blocked)\n- 완료 후 돌아와서 다시 Ready Queue\n- CPU를 얻은 상황에서 timer interrupt 발생 시 다시 Ready Queue에 가서 줄 섬\n- fork() 자식 프로세스가 생성 &rarr; 본인은 CPU를 놓고 ready queue로 가서 줄 섬\n- interrupt 발생 시 Interrupt Service Routine 호출 및 처리 완료 시 실행 재개\n- interrupt 처리 중 다른 프로세스가 CPU를 사용할 수도 있음\n- 본인의 작업이 끝나면 CPU 밖으로 빠져나감\n\n# Scheduler\n1. **Long-term scheduler**(job scheduler)\n   - new 프로세스 중 어떤 것들을 ready queue로 보낼지 결정\n   - *프로세스에 memory(및 각종 resource)를 주는 문제*\n   - degree of multiprogramming(메모리에 여러 프로세스를 올림)을 제어\n   - timesharing system에는 보통 장기 스케줄러가 없음(무조건 ready)\n   - 요새는 이런 스케줄러가 없고 메모리에 다 올리는데 너무 많아지면 중기 스케줄러에서 제어함\n2. **Short-term sceduler**(CPU scheduler)\n   - 어떤 프로세스를 다음 번에 running시킬 지 결정\n   - *프로세스에 CPU를 주는 문제*\n   - 충분히 빨라야 함(ms 단위)\n3. **Medium-Term Scheduler**(Swapper)\n   - 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫒아냄\n   - *프로세스에게서 memory를 뺏는 문제*\n   - degree of multiprogramming을 제어\n\n# 현대 OS에서 Long-term Scheduler를 사용하지 않는 이유\n1. 다중 사용자와 다중 프로그래밍 환경\n   - 현대의 OS는 다중 사용자 환경을 지원하며, 여러 개의 프로세스가 동시에 실행될 수 있음\n   - 이러한 환경에서는 중간 단계의 스케줄링이 필요하지 않을 수 있음\n   - 따라서 대부분의 OS는 중기 스케줄러를 사용하여 실행 가능한 프로세스를 선택하고 실행\n2. 시분할 시스템\n   - 현대의 운영 체제는 대부분 시분할 시스템을 지원\n   - 이를 위해 단기 스케줄러가 사용되며, 장기 스케줄러의 역할은 상대적으로 줄어들었음\n\n# Thread\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/2749c5ef-3d84-47e1-9d4e-0e368801f7bb)\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/11e7ca31-ce5c-4da4-9397-a3f4dd5ec9d1)  \n- **\"A thread(or lightweight process) is a basic unit of CPU utilization\"**\n- Thread란?\n  - 프로세스의 컨텍스트 내에서 돌아가는 논리흐름\n  - 프로세스 내부에 여럿 있을 수 있는, **프로세스보다 작은 CPU 수행 단위**\n- 같은 일을 하는 프로세스가 여러 개 필요한 경우, 한 프로세스에 여러 쓰레드를 두어 서로 다른 부분을 수행할 수 있게 한다.\n  - 하나의 스레드만 가지는 프로세스: heavyweight process\n  - 여러 개의 스레드를 가지는 프로세스: lightweight process\n  - 현대 시스템은 다수의 쓰레드가 한 프로세스에서 동시에 돌아가는 프로그램을 작성할 수 있게 해준다.\n\n# Thread의 구조\n- 한 프로세스 안의 여러 쓰레드들은 최대한 공유할 수 있는 부분들을 공유한다.\n  - PCB는 하나만 만들어진다.\n  - 공유하는 부분: code, data section, OS resources, process state\n  - 독립적인 부분: PC, register set, stack space\n    - 고유의 TID, 스택, 스택 포인터, PC, 범용 레지스터, 조건 코드 등을 포함하는 자신만의 thread context를 가짐\n- main thread: 맨 처음에 만들어지는 thread\n- peer thread: 다른 thread들에 의해 만들어지는 thread\n- *부모-자식의 계층 구조를 가지는 프로세스와 달리 각 쓰레드들은 서로 동등한 위치에 있음*\n\n# TCB와 Thread Context Switching\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/893d6697-0494-4930-8edc-ee410d07dd6d)\n- Thread Context Switching이란? 한 프로세스 내에서 thread의 TCB(Thread Control Block)를 바꾸는 것\n- Process Context Switching과 달리 공유되는 하나의 virtual memory space에서 이루어진다\n- Thread Context Switching은 Kernel에 의해 스케쥴링되거나, 혹은 라이브러리에 의해 스케쥴링됨\n\n# Thread의 장점\n- 동일한 일을 수행하는 다중 스레드가 협력하여 높은 처리율(throughput)과 성능 향상을 얻을 수 있음\n- 스레드를 사용하면 병렬성을 높일 수 있음(multiprocessor computer 한정)\n1. Responsiveness(응답성)\n   - multi-threaded Web: if one thread is blocked(network) another thread continues(display)\n   - 다중 스레드로 구성된 태스크 구조에서, 한 스레드가 BLOCKED 상태인 동안에도 동일한 태스크의 다른 스레드는 RUNNING 상태가 되어 빠른 처리가 가능하다.\n2. Resource Sharing(자원 절약)\n   - n threads can share binary code, data, resource of the process\n3. Economy(빠르다)\n   - creating & CPU switching thread (rather than a process)\n   - thread context는 process context보다 훨씬 더 작기 때문에 thread context switching은 process보다 더 빠르다.\n4. Utilization of MP(Multiprocessor) Architectures\n   - each thread may be running in parallel on a different processor\n\n# Thread의 단점\n- 공유 변수, 전역 변수 등에 대해 동시에 접근하는 쓰레드들이 있다면 동기화 문제(Concurrency)가 발생할 수 있다.\n  - 예를 들어, 쓰레드 간에 공유되는 변수 a == 0가 있고, 각 쓰레드에서 처리될 어떤 함수는 a에 1을 더하는 함수라 하자.\n  - 100개의 쓰레드를 통해 a == 100이라는 결과를 얻고 싶다.\n  - 그러나 쓰레드는 동시에 작동하므로, 특정 시점에 여러 쓰레드가 같은 a값을 가질 수도 있다.\n  - 이 경우 100개의 쓰레드를 거치더라도 a == 100이라는 결과를 얻지 못할 수도 있다.\n- 한 쓰레드에서의 문제가 전체 프로세스의 문제로 이어질 수도 있다.\n\n\n# Implementation of Threads\n1. Kernel Threads\n   - Kernel에 의해 지원되는 thread\n   - 커널이 프로세스에 여러 thread가 있음을 앎\n   - 하나의 thread에서 다른 thread로 CPU 제어권이 넘어가는 것을 OS가 제어함\n2. User Threads\n   - Library에 의해 지원되는 thread\n   - 커널은 여러 thread의 존재를 모름\n   - User program이 스스로 thread의 CPU를 제어함\n3. real-time threads\n\n# Kernel-level Threads\n- thread를 생성하고 스케쥴링하는 주체가 커널이다.\n- 장점 \n  1. 커널이 각 스레드를 개별적으로 관리\n  2. 동작 중인 스레드가 System Call(커널 호출)해도 해당 프로세스 내 다른 스레드가 계속 실행될 수 있다.\n- 단점\n  1. 스케쥴링과 동기화를 위해 System Call(커널 호출)하는데 오래 걸린다.\n  2. 유저 모드와 커널 모드 간 전환이 빈번하여 성능 저하로 이어질 수 있다.\n  3. 구현이 어렵고 자원을 더 많이 소비하는 경향이 있다.\n\n# User-level Threads\n- 커널에 의존하지 않으면서 thread의 기능을 제공하는 라이브러리들을 이용해 구현된다.\n- 따라서 커널은 이 thread들의 존재를 알지 못한다.\n- 장점\n  1. 커널이 thread들의 존재를 알지 못하므로 커널에 의한 context switching도 일어나지 않는다. (한 프로세스로 보기에)\n  2. 따라서 모드 전환도 이루어지지 않고, overhead도 적으며 성능에서의 이득을 얻을 수 있다.\n- 단점\n  1. 커널에 의한 스케줄링 우선 순위가 제공되지 않아서 어떤 thread가 먼저 실행될지 알 수 없다.\n  2. 커널의 입장에서는 이 모든 thread들이 하나의 프로세스이기에, 한 thread에서 System Call이 발생하면 모든 thread들이 멈추게 된다.','Process is a program in execution  Context? 현재 시점의 상태를 규명하기 위해 필요한 요소들(timesharing 구현을 위해 필요)   CPU 수행 상태를 나타내는 hardware context: Program Counter, 각종 register  프로세스의 address space: code, data, stack  프로세스 관련 kernel data structure: PCB, kernel stack(프로세스 별로 보유)   image  Process Control Block(PCB)   image  OS가 각 프로세스를 관리하기 위해 프로세스 당 유지하는 정보  구조체로 유지   OS가 관리 상 사용하는 정보: Process state, PID, scheduling','3. Process'),(_binary '','2023-11-15 04:44:36.858230',30,95,'2023-11-15 04:03:43.789698',1,'# 프로세스 생성(Process Creation)\n- 부모 프로세스가 자식 프로세스를 생성함\n- 프로세스 생성 시 트리(계층 구조) 형성\n- 프로세스는 자원을 필요로 함 &rarr; 자원은 OS로부터 받음\n- 자원의 공유에 따른 분류\n  1. 부모와 자식이 모든 자원을 공유하는 모델\n  2. 일부를 공유하는 모델\n  3. 전혀 공유하지 않는 모델: 원칙적으로는 서로 다른 프로세스이므로 자원을 부모와 공유하지 않음 \n- execution에 따른 분류\n  1. 부모와 자식이 공존하며 수행되는 모델\n  2. 자식이 종료(terminate)될 때까지 부모가 기다리는(wait) 모델\n- Address space\n  - 자식은 부모의 공간을 복사함(binary and OS data)\n  - 자식은 그 공간에 새로운 프로그램을 올림\n\n## PID란?\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/37d4edbb-0dac-4631-b255-f45553b940c4)\n- PID = Process ID\n  - 운영체제에서 프로세스를 식별하기 위해 부여하는 번호를 의미\n- PID 의 최대값: 32768\n  - 32768 인 이유는 16bit signed integer 를 사용하기 때문\n- PID 의 ID 할당 방식\n  - 최근 할당된 PID 에 1을 더한 값으로 할당\n  - 순서대로 1씩 할당되다가 32768 을 넘어가면 다시 1부터 시작\n\n## 프로세스 생성 과정\n- UNIX의 예\n  1. **fork()**: 복제단계\n     - **fork()**가 새로운 프로세스를 생성\n     - 부모를 그대로 복사(OS data except PID + binary) &rarr; context 복사\n     - address space 할당\n  2. **exec()**: 새로운 프로그램을 덮어씌우는 단계\n     - fork() 다음에 이어지는 **exec()**을 통해 새로운 프로그램을 메모리에 올림\n\n## Copy-On-Write(COW)\n- 최적화 방식\n- write 발생 전까지는 부모와 자원 공유\n- write 발생 시(변화 생김) 부모 프로세스 복제 후 새로운 프로그램을 올림\n\n# 프로세스 종료(Process Termination)\n1. 자발적 종료: 프로세스가 마지막 명령을 수행한 후 OS에게 이를 알려줌 **exit()**\n   - 자식이 부모에게 Output data를 보냄(via **wait()**)\n   - 프로세스의 각종 자원들이 OS에게 반납됨\n2. 강제 종료: 부모 프로세스가 자식의 수행을 종료시킴 **abort()**\n   - 자식이 할당 자원의 한계치를 넘어섬\n   - 자식에게 할당시킬 task가 없거나 더 이상 필요하지 않음\n   - 부모 프로세스가 종료(exit)되는 경우\n     - OS는 부모 프로세스가 exit하는 경우 자식이 더 이상 수행되도록 두지 않음\n     - 단계적인 종료(leaf node &rarr; root node 방향) \n\n# fork()\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/04660658-7154-46f0-ab76-9fd325b1d238)  \n- Parent process: pid > 0\n- Child process: pid = 0\n- child process는 parent의 PC값을 복제하기 때문에 fork() 이후부터 실행 \n```c\n#include <sys/types.h>\n#include <unistd.h>\n\n//Returns: 0 to child, PID of child to parent, −1 on error\npid_t fork(void); //pid_t는 int값임\n```\n\n# exec()\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/31a48cd0-12c6-4bf1-a10c-0f094f5697ac)  \n- exec() 시 추가해준 해당 프로그램의 main 함수 처음부터 실시\n- exec() 시 되돌리기는 불가능\n- echo &rarr; 뒤에 나오는 argument를 그대로 화면에 출력함 \n```c\n#include <unistd.h>\n\n//Does not return if OK; returns −1 on error\nint execve(const char *filename, const char *argv[], const char *envp[]);\n```\n\n# wait()\n- 프로세스 A가 wait() 시스템 콜을 호출하면\n  - 커널은 child가 종료될 때까지 프로세스 A를 sleep시킨다 (blocked)\n  - child process가 종료되면 커널은 프로세스 A를 깨운다 (ready)\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/004ae769-e90c-4b95-b354-90cc3da68ae3)\n```c\n#include <sys/types.h>\n#include <sys/wait.h>\n\n//Returns: PID of child if OK or −1 on error\npid_t wait(int *statusp); // 포인터를 넣어서 자식 프로세스가 종료될 때 어떤 상태였는지를 확인할 수 있게 함\n```\n\n## wait()의 사용목적\n1. 자식 프로세스가 종료되기 전에 부모 프로세스가 종료되는 일을 막음\n2. 자식 프로세스의 종료 상태에 따라 부모 프로세스에서 처리\n3. 동시성을 제어하는 데에도 사용할 수 있음\n\n# exit()\n- 자발적 종료 **exit()**\n  - 마지막 statement 수행 후 exit() 시스템 콜을 통해\n  - 프로그램에 명시적으로 적어주지 않아도 main 함수가 리턴되는 위치에 컴파일러가 넣어줌\n- 비자발적 종료 **abort()**\n  - 수업에서는 abort를 부모 프로세스에서 자식 프로세스를 종료시키는 것이라 했지만\n  - 사실은 현재 프로세스에서 SIGABRT 시그널을 발생 &rarr; 해당 시그널을 받은 커널이 종료시키는 것\n  - 비자발적 종료 상황\n    1. 부모 프로세스가 자식 프로세스를 강제 종료시킴\n      - 자식 프로세스가 한계치를 넘어서는 자원 요청\n      - 자식에게 할당된 태스크가 더 이상 필요하지 않음\n    2. 키보드로 kill, break 등을 친 경우\n    3. 부모가 종료하는 경우\n      - 부모 프로세스가 종료하기 전에 자식들이 먼저 종료됨\n```c\n#include <stdlib.h>\n\nvoid exit(int status); //종료될 때 부모 프로세스에 알려줄 자신의 status를 parameter로 가짐 \nvoid abort(void);          //SIGABRT 시그널을 발생\n\n```\n\n# 프로세스와 관련된 System call\n1. **fork()** - create a child(copy)\n2. **exec()** - overlay new image\n3. **wait()** - sleep until child is done\n4. **exit()** - frees all the resources, notify parent\n\n# 프로세스 간 협력\n1. 독립적 프로세스(Independent process)\n   - 프로세스는 각자의 주소 공간을 가지고 수행되므로 원칙적으로 하나의 프로세스는 다른 프로세스의 수행에 영향을 미치지 못 함\n2. 협력 프로세스(Cooperating process)\n   - 프로세스 협력 메커니즘을 통해 하나의 프로세스가 다른 프로세스의 수행에 영향을 미칠 수 있음\n3. 프로세스 간 협력 매커니즘(IPC: Interprocess Communication)\n   1. 메시지를 전달하는 방법\n     - **message passing**: process 사이에 공유 변수를 일체 사용하지 않고, process들은 서로 독립적이므로 커널을 통해 메시지 전달\n   2. 주소 공간을 공유하는 방법\n     - **shared memory**: 서로 다른 프로세스 간에도 일부 주소 공간을 공유하게 하는 shared memory\n     - **thread**: 사실 상 하나의 프로세스이므로 프로세스 간 협력으로 보기는 어렵지만 동일한 process를 구성하는 thread 간에는 주소 공간을 공유하므로 협력이 가능\n   3. UNIX pipe\n     - 부모-자식 프로세스 간 통신을 위한 *단방향* 데이터 채널\n     - 가장 오래되고 가장 간단한 IPC 메커니즘\n\n\n# Message passing\n- Message system\n  - 프로세스 사이에 shared variable를 일체 사용하지 않고 통신하는 시스템\n  - 반드시 kernel을 통해서 전달\n- Message란?\n  - 두 프로세스에서 주고 받을 데이터로, 구조체의 형태를 가지고 있음\n  - 이 구조체를 양쪽에 선언해놓고 사용\n1. Direct Communication\n   - 통신하려는 프로세스의 이름을 **명시적으로** 표시\n   - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/28a1004b-1f14-475e-a8b4-6fbd3dda8683)\n2. Indirect Communication\n   - mailbox(또는 port)를 통해 메시지를 간접 전달\n   - 누가 받을지는 **명시하지 않음**\n   - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/1f22d4da-9f6f-4862-976b-5b37f636d872)\n\n# Shared Memory\n- 물리적 메모리에 매핑될 때 일부 주소 공간을 공유하도록 매핑\n- 처음 주소 공간을 공유할 때에는 kernel의 도움을 받지만, 이후 협력에서는 kernel을 거치지 않고서도 가능\n- 제한 사항: 두 프로세스가 동시에 한 주소 공간에 write하는 경우가 없어야 함 (충돌 가능성 있음)\n\n# UNIX Pipe\n- 부모-자식 프로세스 간 통신을 위한 *단방향* 데이터 채널\n- 가장 오래되고 가장 간단한 IPC 메커니즘\n- *부모-자식 관계의 프로세스 사이의 데이터 교환*을 가능하게 함\n- 파이프 생성 과정\n   - 부모 프로세스에서 파이프를 하나 만든다. (`int pipe(int fd[2]);`)\n   - 이 파이프는 양 끝을 가지는데, 한 쪽(`fd[1]`)은 쓰기용, 한 쪽은 읽기용(`fd[0]`)이다.\n   - `fd`는 file descriptor를 의미\n   - `fork()`를 통해 만들어진 자식 프로세스는 부모와 같은 file descriptor를 가진다.(복제)\n- 부모가 쓰고 자식이 읽는 경우, 부모는 읽기 파이프를 닫고, 자식은 쓰기 파이프를 닫는다.\n   - 부모가 쓰기 파이프에 쓰면 자식은 읽기 파이프로 그 내용을 읽을 수 있게 된다.\n   - 양방향으로 구현하고 싶을 땐 pipe를 2개 생성 후 각각 닫고 열면 됨\n\n# Message passing vs Shared memory\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/9c145094-3d76-4d5f-8604-623b88d32724)','프로세스 생성(Process Creation)   부모 프로세스가 자식 프로세스를 생성함  프로세스 생성 시 트리(계층 구조) 형성  프로세스는 자원을 필요로 함 → 자원은 OS로부터 받음  자원의 공유에 따른 분류   부모와 자식이 모든 자원을 공유하는 모델  일부를 공유하는 모델  전혀 공유하지 않는 모델: 원칙적으로는 서로 다른 프로세스이므로 자원을 부모와 공유하지 않음   execution에 따른 분류   부모와 자식이 공존하며 수행되는 모델  자식이 종료(terminate)될 때까지 부모가 기다리는(wait) 모델   Address space  자식은 부모의 공간을 복사함(binary and OS data)  자식은 그 공간에 새로운 프로그램을 올림  PID란?   image  PID = Proce','4. Process Management'),(_binary '','2023-11-15 04:44:52.857163',30,96,'2023-11-15 04:03:47.142203',1,'## Bursts\n- continued actions, 한 번에 전송되는 data block, Period\n- 프로세스 관점에서\n   1. CPU Burst - CPU를 사용할 때 \n   2. I/O Burst - 입출력 대기할 때\n- CPU-I/O Burst Cycle이 존재\n\n# 프로세스의 특성 분류\n1. I/O-bound process: CPU를 잡고 계산하는 시간보다 I/O에 많은 시간이 필요한 job(many short CPU bursts)\n2. CPU-bound process: 계산 위주의 job(few very long CPU bursts)\n\n# CPU Scheduler & Dispatcher\n1. CPU Scheduler\n   - **Ready 상태의 프로세스 중에서 이번에 CPU를 줄 프로세스를 고른다**\n   - OS 안에서 scheduling하는 코드를 scheduler라고 부름\n2. Dispatcher\n   - **CPU의 제어권을 CPU scheduler에 의해 선택된 프로세스에게 넘긴다**\n   - OS 안에서 dispatch하는 코드를 dispatcher라고 부름\n   - == context switching\n   - dispatch latency: context switching에 소요되는 시간\n- CPU 스케줄링이 필요한 경우: 프로세스의 상태 변화가 다음과 같을 때\n   1. Running &rarr; Blocked : I/O request system call\n   2. Running &rarr; Ready : timer interrupt\n   3. Blocked &rarr; Ready : I/O 완료 후 interrupt\n   4. Terminate\n- 1, 4에서의 스케줄링: 바로 Ready Queue의 새로운 프로세스를 실행 &rarr; Nonpreemptive (=강제로 빼앗지 않고 자진반납)\n- 나머지는 모두 Preemptive (= 스케줄링하여 강제로 빼앗음)\n\n# Scheduling Criteria\n## Performance Measure 성능 척도\n- 매 CPU burst마다 계산하는 것\n1. 시스템 관점에서의 성능 척도\n   - **CPU utilization(이용률)**: 전체 시간 중 CPU가 일한 시간 &rarr; UNIX 시스템에서 top 명령을 사용하여 CPU 이용률을 얻을 수 있음\n   - **Throughput(처리량)**: 단위 시간 당 완료한 프로세스의 수\n2. 프로세스 관점에서의 성능 척도\n   - **Turnaround time(소요 시간, 반환 시간)**: 총 대기 시간 + 수행하는 데 걸린 시간\n   - **Waiting time(대기 시간)**\n   - **Response time(응답 시간)**: Ready Queue에 들어와서 처음 CPU를 얻기까지 걸린 시간\n     - for time-sharing environment\n\n# Scheduling Algorithms\n## 1. FCFS(First-Come First-Served) \n- **먼저 온 프로세스를 먼저 처리**\n- Nonpreemptive\n- problem. **Convoy effect** - short process behind long process\n\n## 2. SJF(Shortest-Job-First)\n- **CPU burst time이 가장 짧은 프로세스를 가장 먼저 스케줄링**\n- Nonpreemptive: 일단 CPU를 잡으면 더 짧은 CPU burst time을 가지는 process가 오더라도 완료될 때까지 넘기지 않음\n- Preemptive: 더 짧은 CPU burst time을 가지는 process가 오면 CPU를 빼앗김 &rarr; SRTF(Shortest-Remaining-Time-First)\n- *SRTF is optimal*: minimum avereage waiting time을 보장\n- problem 1. **Starvation** CPU burst time이 긴 프로세스는 영원히 CPU를 얻지 못 함\n- problem 2. **CPU burst time을 미리 알 수 없음** - 과거 사용 이력을 통해 예측은 가능(exponential averaging 사용)\n\n### Exponential Averaging\n- $t_n$ = actual length of $n^th$ CPU burst\n- $\\tau_{n+1}$ = predicted value for the next CPU burst\n- $0 \\le \\alpha \\le 1$\n- Define: $\\tau_{n+1} = \\alpha t_n + (1-\\alpha)\\tau_n$\n- $\\alpha = 0$ \n   - $\\tau_{n+1} = \\tau_n$: Recent history does not count\n- $\\alpha = 1$\n   - $\\tau_{n+1} = t_n$: Only the actual last CPU burst counts\n- 식을 풀면 다음과 같다\n  - $\\tau_{n+1} = \\alpha t_n + (1-\\alpha)\\alpha t_{n-1} + ... + (1-\\alpha)^j \\alpha t_{n-j} + ... + (1-\\alpha)^{n+1}\\tau_0$\n- $\\alpha$ 와 $(1-\\alpha)$가 둘다 1 이하이므로 후속 term은 선행 term보다 적은 가중치 값을 가진다\n- 요약하면 최근 실행된 CPU burst를 오래된 CPU burst보다 많이 반영\n\n## 3. Priority Scheduling\n- **highest priority를 가진 프로세스에게 CPU 할당**(smallest integer - highest priority)\n- Nonpreemtive: 일단 우선순위 높은 프로세스에게 CPU를 주면 더 높은 우선순위의 프로세스가 와도 뺏지 않음\n- Preemptive: 중간에 들어온 우선순위가 더 높은 프로세스에게 CPU를 준다\n- problem: **Starvation** low priority processes may **never execute**\n- solution: **Aging** as time progresses **increases the priority** of the process\n- priority 기준 예시: 작업의 중요도, 요청된 서비스의 종류, 프로세스의 실행 시간\n\n## 4. Round Robin(RR)\n- 현대적인 CPU scheduling\n- 각 프로세스는 동일한 크기의 **time quantum**을 가짐(일반적으로 10~100ms)\n- 할당 시간이 끝나면 프로세스는 preempted 당하고 ready queue의 제일 뒤에 가서 다시 줄을 선다\n- n개의 프로세스가 ready queue에 있고 할당 시간이 q time unit인 경우 각 프로세스는 최대 q단위로 CPU 시간의 1/n을 얻는다.\n  - 어떤 프로세스도 q(n-1) time unit 이상 기다리지 않는다.\n  - **response time이 빨라짐**\n- Performance\n  - q &uarr; FCFS\n  - q &darr; context switching overhead가 커짐\n\n# Multilevel Queue\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/44153c1d-992e-4e0c-add0-159fef41c90e)\n- **Ready Queue를 여러 개로 분할**\n  - foreground(interactive)\n  - background(batch - no human interaction)\n- 각 큐는 *독립적인* 스케줄링 알고리즘을 가짐\n  - foreground - RR\n  - background - FCFS\n- 큐에 대한 스케줄링이 필요\n  - Fixed priority scheduling\n    - serve all from foreground then from background\n    - Possibility of starvation\n  - Time slice\n    - 각 큐에 CPU time을 적절한 비율로 할당\n    - ex. 80% to foreground in RR, 20% to background in FCFS\n\n# Multilevel Feedback Queue\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/da0f8234-69bd-4b00-810b-39b060552835)\n  - 3 Queues: 8ms, 16ms, FCFS &rarr; $Q_0, Q_1, Q_2$\n  - Scheduling\n    - new job이 $Q_0$로 들어감\n    - CPU를 잡아서 할당 시간 8ms동안 수행\n    - 8ms동안 다 끝내지 못하면 $Q_1$으로 내려감\n    - $Q_1$에 줄서서 기다렸다가 CPU를 잡아서 16ms동안 수행\n    - 16ms동안 끝내지 못하면 $Q_2$로 내려감\n- **프로세스가 다른 큐로 이동 가능**\n- ex) **aging**\n- Multilevel-feedback-queue scheduler를 정의하는 parameters\n  - Queue의 수\n  - 각 큐의 scheduling algorithm\n  - process를 상위 큐, 하위 큐로 보내는 기준\n  - 프로세스가 CPU 서비스를 받으려 할 때 들어갈 큐를 결정하는 기준\n- Multilevel Feedback Queue에서 상위 큐로 올라가는 방법\n  1. 시간 할당량 제한\n     - 보통 하위 큐에서 실행중인 프로세스가 시간 할당량을 모두 소모한 경우, 해당 프로세스는 하위 큐에 남게 되지만 MFQ에서는 상위 큐로 올라가는 기회를 주는 경우도 있음\n  2. 우선순위 상승\n     - 하위 큐에서 실행 중인 프로세스가 우선순위 상승 조건을 충족하는 경우, 해당 프로세스는 상위 큐로 올라갈 수 있음\n     - 상승 조건은 운영체제 마다 다를 수 있지만 일반적인 두 가지 조건   \n     a. 실행 시간 초과: 하위 큐에서 실행 중인 프로세스가 시간 할당량을 초과한 경우에는 상위 큐로 올라갈 수 있음   \n     b. I/O 요청의 유무: 하위 큐에서 실행 중인 프로세스가 I/O 작업을 요청하는 경우, 해당 프로세스는 상위 큐로 올라갈 수 있음  \n\n# Multiple-Processor Scheduling\n- CPU가 여러 개인 경우 스케줄링은 더욱 복잡해짐\n- Homogeneous processor인 경우\n  - Queue에 한 줄로 세워서 각 프로세서가 알아서 꺼내가게 할 수 있다\n  - 반드시 특정 프로세서에게 수행되어야 하는 프로세스가 있는 경우는 복잡해짐\n- Load sharing\n  - 일부 프로세서에 job이 몰리지 않도록 부하를 적절히 공유하는 메커니즘 필요\n  - 별개의 큐를 두는 방법 vs 공동 큐를 사용하는 방법\n- Symmetric Multiprocessing(SMP)\n  - 각 프로세서가 각자 알아서 스케줄링 결정\n- Asymmetric multiprocessing\n  - 하나의 프로세서가 시스템 데이터의 접근과 공유를 책임지고 나머지 프로세서는 거기에 따름\n\n# Real-Time Scheduling\n1. **Hard real-time systems**: 정해진 시간 안에 반드시 끝내도록 스케줄링해야 함 ex) 미사일, 원자력 발전소 시스템\n2. **Soft real-time computing**: 일반 프로세스에 비해 높은 priority를 갖도록 해야 함 ex) PC, 휴대폰\n\n# Thread Scheduling\n1. **Local Scheduling**: User level thread의 경우 사용자 수준의 thread library에 의해 어떤 thread를 스케줄할지 결정\n2. **Global Scheduling**: kernel level thread의 경우 일반 프로세스와 마찬가지로 커널의 단기 스케줄러가 어떤 thread를 스케줄할지 결정\n\n# Algorithm Evaluation\n1. Deterministic Modeling\n   - 이미 주어졌다고 가정된 특정 workload를 가지고서 각 알고리즘들을 평가하는 방법\n   - 쉽고 빠른 분석이 가능하지만, 주어지지 않은, 다른 종류의 workload에 대해서도 마찬가지일지는 알 수 없다.\n2. **Queueing models**: 이론적인 방법\n   - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/ffe96ee2-675c-47ca-90bc-c0a2c534aa01)\n   - 확률 분포로 주어지는 arrival rate와 service rate 등을 통해 각종 performance index(성능 척도) 값을 계산\n3. **Implementation & Measurement**\n   - 실제 시스템에 알고리즘을 구현하여 실제 작업(workload)에 대해서 성능을 측정 비교\n4. **Simulation**\n   - 알고리즘을 모의 프로그램으로 작성 후 trace를 입력으로 하여 결과 비교\n   - trace files란? \n     - 실제 시스템을 모니터링하고 그 이벤트의 순서를 기록함으로써 만들어 낸 파일\n     - 완전히 같은 입력 집합을 가지고서 여러 알고리즘들을 비교할 수 있으므로 매우 유용하다.\n   - 시뮬레이션 또한 수 시간이 걸릴 수 있을 만큼 비용이 비싸고, trace files 또한 매우 큰 저장 용량을 필요로 할 수 있다.','Bursts   continued actions, 한 번에 전송되는 data block, Period  프로세스 관점에서   CPU Burst - CPU를 사용할 때   I/O Burst - 입출력 대기할 때   CPU-I/O Burst Cycle이 존재  프로세스의 특성 분류   I/O-bound process: CPU를 잡고 계산하는 시간보다 I/O에 많은 시간이 필요한 job(many short CPU bursts)  CPU-bound process: 계산 위주의 job(few very long CPU bursts)  CPU Scheduler & Dispatcher   CPU Scheduler   Ready 상태의 프로세스 중에서 이번에 CPU를 줄 프로세스를 고른다  OS 안에서 scheduling하','5. CPU Scheduling'),(_binary '','2023-11-15 04:45:05.672775',30,97,'2023-11-15 04:03:50.862801',1,'## 데이터의 접근\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/6c0291c2-dcfe-4101-99be-9e353603db4f)\n\n## Race condition\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/7e148c85-2e21-4b42-9f45-3592cb5e9673)\n- 여러 프로세스들이 동시에 공유 데이터를 접근하는 상황\n- 데이터의 최종 연산 결과는 마지막에 그 데이터를 다룬 프로세스에 따라 달라짐\n\n## Race condition이 발생하는 경우\n1. Kernel 수행 중 interrupt 발생 시\n   - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/af55e189-a555-4ed4-955b-1cd3b7389409)\n2. Process가 system call을 하여 kernel mode로 수행 중인데 context switching이 일어나는 경우\n   - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/c4e11d3b-93a6-4df7-a4de-acc7be3a0d2b)\n   - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/5fe54edc-379c-463d-98e1-65df73772846)\n3. Multiprocessor에서 shared memory 내의 kernel data\n   - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/f5f27c79-7ac9-49ef-99d7-834f8b879ce8)\n\n# Process Synchronization 문제\n- shared data의 동시접근(concurrent access)은 데이터의 불일치 문제(inconsistency)를 발생시킬 수 있음\n- consistency 유지를 위해서는 협력 프로세스(cooperating process)간의 실행 순서(orderly execution)를 정해주는 메커니즘 필요\n- **race condition을 막기 위해서는 concurrent process가 synchronize되어야 함**\n\n# The Critical-Section Problem\n- n개의 프로세스가 공유 데이터를 동시에 사용하기를 원하는 경우\n- 각 프로세스의 code section에는 공유 데이터를 접근하는 코드인 **critical section**이 존재\n- Problem\n  - 하나의 프로세스가 critical section에 있을 때 다른 모든 프로세스는 critical section에 들어갈 수 없어야 한다\n  - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/18dd3919-4528-4ccc-9870-b1369c93384b)\n\n# Initial Attempts to Solve Problem\n- 두 개의 프로세스가 있다고 가정 $P_0, P_1$\n- 프로세스들의 일반적인 구조  \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/3cc61b81-dc82-44f3-87ba-93e2fa773d97)  \n- 프로세스들은 수행의 동기화를 위해 몇몇 변수를 공유할 수 있다 &rarr; synchronization variable\n\n# 프로그램적 해결법의 충족 조건\n1. **Mutual Exclusion**(상호 배타)\n   - 프로세스 Pi가 critical section 부분을 수행 중이면 다른 모든 프로세스들은 그들의 critical section에 들어가면 안 된다\n2. **Progress**\n   - 아무도 critical section에 있지 않은 상태에서 critical section에 들어가고자 하는 프로세스가 있으면 들어가게 해주어야 한다\n3. **Bounded Waiting**\n   - 프로세스가 critical section에 들어가려고 요청한 후부터 그 요청이 허용될 때까지 다른 프로세스들이 critical section에 들어가는 횟수에 한계가 있어야 한다\n   - 기다리는 시간이 유한해야 한다\n- 가정\n  - 모든 프로세스의 수행 속도는 0보다 크다\n  - 프로세스들 간의 상대적인 수행 속도는 가정하지 않는다\n\n# Algorithm 1\n- Synchronization variable(`int i`, initially turn = 0)\n- $P_i$ can enter its critical section if `(turn == i)`\n- Process $P_0$  \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/47413929-3545-4783-949c-535e70b70d10)  \n- Satisfy *mutual exclusion*, but not *progress*\n- 즉, 과잉양보: 반드시 한 번씩 교대로 들어가야만 함(swap-turn). 그가 turn을 내 값으로 바꿔줘야만 내가 들어갈 수 있음. 특정 프로세스가 더 빈번히 critical section을 들어가야 한다면?\n\n# Algorithm 2\n- Synchronization variable\n  - `boolean flag[2]`, initially `flag[모두] = false` &rarr; no one is in CS\n  - $P_i$ ready to enter its CS if `flag[i] == true`\n- Process $P_i$  \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/56c89871-b1a5-4191-8abc-2327a7b42c2f)\n- Satisfy *mutual exclusion*, but not *progress*\n- 둘 다 2행까지 수행 후 끊임없이 양보하는 상황 발생 가능\n\n# Algorithm 3 (Peterson\'s Algorithm)\n- Combined synchronization variables of algorithms 1 and 2\n- Process $P_i$  \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/3ad54988-256c-4eac-a46a-e5c53e038d98)\n- meets all three requirements &rarr; solves the critical section problem for 2 processes\n- **Busy waiting(=Spin lock)**(계속 CPU와 memory를 쓰면서 wait)\n\n# Synchronization Hardware\n- 하드웨어적으로 **Test & modify**를 **atomic하게** 수행할 수 있도록 지원하는 경우 앞의 문제는 간단히 해결  \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/a142c5cf-0d02-4edf-bf72-93e408a618a1)  \n- Mutual Exclusion with Test & Set  \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/fa643a71-7695-4a28-a85d-f35645697961)\n\n# Semaphores\n- 앞의 방식들을 추상화시킴\n- Semaphore S\n  - integer variable = 자원의 개수와 같음\n  - 아래의 두 가지 atomic 연산에 의해서만 접근 가능  \n  ![image](https://github.com/Haaarimmm/TIL/assets/108309396/91e44ca4-0253-40ed-ba8f-9a2ae75c8bbd)\n  - **P(S): lock을 얻음, V(S): lock을 반납함**\n\n# Critical Section of n Processes\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/45a1c296-b81e-4c73-8a8c-67bc16f16b6e)\n- busy-wait(=spin lock)는 효율적이지 못 함\n- Block(Sleep) & Wakeup(=sleep lock) 방식의 구현\n\n# Block / Wakeup Implementation\n- Semaphore를 다음과 같이 정의\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/3cd9aade-f59c-40ec-83c3-7960ae03eab7)\n- block과 wakeup을 다음과 같이 가정\n- **block**: 커널은 block을 호출한 프로세스를 suspend시킴. 이 프로세스의 PCB를 semaphore에 대한 wait queue에 넣음\n- **wakeup(P)**: block된 프로세스 P를 wakeup시킴. 이 프로세스의 PCB를 ready queue로 옮김\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/cd01d8cb-9d55-4fef-961f-320ed6f37dde)\n\n# Implementation P() & V()\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/602935f0-7bbd-494a-878f-57c133a2d7f1)\n- P()에서 미리 S를 1빼고 음수면 sleep\n- V()에서 S에 1을 더하고 0이하면 wakeup\n\n# Which is better?\n- Block/wakeup overhead vs Critical section 길이\n  - critical section 길이가 긴 경우 Block/Wakeup이 적당\n  - critical section 길이가 매우 짧은 경우 Block/Wakeup overhead가 busy-wait overhead보다 더 커질 수 있음\n  - 일반적으로는 Block/wakeup 방식이 better!\n\n# Two Types of Semaphores\n1. Counting semaphore\n   - 도메인이 0 이상인 임의의 정수값\n   - 주로 resource counting에 사용\n2. Binary semaphore(=mutex)\n   - 0 또는 1 값만 가질 수 있는 semaphore\n   - 주로 mutual exclusion(lock/unlock)에 사용\n\n# Problem: Deadlock and Starvation\n1. Deadlock\n   - 둘 이상의 프로세스가 서로 상대방에 의해 충족될 수 있는 event를 무한히 기다리는 현상\n   - S와 Q가 1로 초기화된 semaphore라 하자.\n   - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/1371a01a-8f05-43d0-98b5-87dd92219c05)\n2. Starvation\n   - Indefinite blocking: 프로세스가 suspend된 이유에 해당하는 세마포어 큐에서 빠져나갈 수 없는 현상\n\n# Classical Problems of Synchronization\n## 1. Bounded-Buffer Problem(Producer-Consumer Problem)\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/ffbe53b1-781b-4413-8e86-ec3b25202e29)  \n- Shared data: buffer 자체 및 buffer 조작 변수(empty/full buffer의 시작 위치)\n- Synchronization variables\n   - mutual exclusion &rarr; Need binary semaphore(shared data의 mutual exclusion을 위해)\n   - resource count &rarr; Need integer semaphore(남은 full/empty buffer의 수 표시)\n   - `semaphore full = 0`(full buffer의 개수 count), `empty = n`(empty buffer의 개수 count), `mutex = 1`(lock을 걸기 위한 변수)\n- pseudo-code   \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/d0cd4e7f-75cf-44c2-a7bb-489de3631819)\n\n## 2. Readers and Writers Problem\n- 한 process가 DB에 write 중일 때 다른 process가 접근하면 안 됨\n- read는 동시에 여럿이 해도 됨\n- solution\n  - Writer가 DB에 접근 허가를 아직 얻지 못한 상태에서는 모든 대기 중인 Reader들을 다 DB에 접근하게 해준다\n  - Writer는 대기 중인 Reader가 하나도 없을 때 DB 접근이 허용된다\n  - 일단 Writer가 DB에 접근 중이면 Reader들은 접근이 금지된다\n  - Writer가 DB에서 빠져나가야만 Reader의 접근이 허용된다\n- Shared data: `DB 자체, int readcnt = 0(현재 DB에 접근 중인 Reader의 수)`\n- Synchronization variables\n  - `semaphore mutex = 1`: 공유 변수 readcnt를 접근하는 critical section의 mutual exclusion 보장을 위해 사용\n  - `db = 1`: Reader와 Writer가 공유 DB 자체를 올바르게 접근하게 하는 역할\n- pseudo-code    \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/b4900a5b-bc23-4a25-99ce-ef76429ccd44)\n\n## 3. Dining-Philosophers Problem\n- Synchronization variables: semaphore chopstick[5](initially all values are 1)  \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/2e729995-cf99-4ebe-9cc7-877260d451b2)\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/8a5d17ad-2d4f-4014-ac3c-4d9d42d9ff95)\n- problem\n  - Deadlock의 가능성 존재\n  - 모든 철학자가 동시에 배가 고파져 왼쪽 젓가락을 집어버린 경우\n- solution\n  - 4명의 철학자만이 테이블에 동시에 앉을 수 있도록 한다\n  - 젓가락을 두 개 모두 집을 수 있을 때에만 젓가락을 집을 수 있게 한다\n    ![image](https://github.com/Haaarimmm/TIL/assets/108309396/fee18782-7ab7-4b46-81c4-c87cc57f44c0)\n  - 비대칭: 짝수(홀수)철학자는 왼쪽(오른쪽) 젓가락부터 집도록\n\n# Semaphore의 문제점\n- 구현 어려움\n- 정확성 입증이 어려움\n- 자발적 협력이 필요\n- 한 번의 실수가 모든 시스템에 치명적 영향\n- example  \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/6496d079-92f8-4663-a70e-fa9f3aed4113)\n\n# Monitor(Condition Variable)\n- 동시 수행 중인 프로세스 사이에서 abstract data type의 안전한 공유를 보장하기 위한 high-level synchronization construct  \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/e21a0429-717f-49f0-b28f-cddc34b7866e)\n- 모니터 내에서는 한 번에 하나의 프로세스만이 활동 가능\n- 프로그래머가 동기화 제약 조건을 명시적으로 코딩할 필요없음\n- 프로세스가 모니터 안에서 기다릴 수 있도록 하기 위해 condition variable 사용(`condition x, y`)\n- Condition variable은 **wait**과 **signal**연산에 의해서만 접근 가능\n  - `x.wait()`: `x.wait()`을 invoke한 프로세스는 다른 프로세스가 `x.signal()`을 invoke하기 전까지 suspend된다\n  - `x.signal()`: `x.signal()`은 정확하게 하나의 suspend된 프로세스를 resume한다. suspend된 프로세스가 없으면 아무 일도 일어나지 않음\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/f1a3cb5d-795b-463d-bd16-a271739a017c)\n\n## Condition Variable: Bounded-Buffer Problem\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/177ee093-4e7d-4a89-a034-d7d824e1fcba)\n\n## Condition Variable: Dining Philosophers Problem\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/ef79bf48-2bc3-450a-be93-0ede0672adce)\n\n# Semaphore vs Monitor\n- 세마포어\n  - 주로 공유 자원의 동시 접근을 제어하기 위해 사용\n  - 여러 프로세스가 공유 자원에 접근하는 순서를 조정하고, 상호 배제와 동기화를 달성할 수 있음\n  - 세마포어는 저수준의 동기화 메커니즘이며, 개발자가 직접 세마포어를 조작해야 함\n- 모니터\n  - 고급 프로그래밍 언어에서 제공되는 동기화 추상화입니다.\n  - 모니터는 더 추상화된 수준에서 동기화를 처리하며, 개발자는 모니터 내에서 프로시저를 작성하여 상호 배제와 동기화를 자동으로 처리할 수 있음\n- 요약\n  - 세마포어는 저수준의 원시 동기화 도구로서 다양한 동기화 문제를 해결하는 데 사용\n  - 모니터는 고수준의 추상화로서 모듈화와 코드의 가독성을 향상시키는 데 중점을 둠\n  - 따라서, 세마포어는 프로세스 간의 동기화에 더 많은 유연성을 제공, 모니터는 모듈 수준에서의 동기화와 추상화를 제공','데이터의 접근 image  Race condition image - 여러 프로세스들이 동시에 공유 데이터를 접근하는 상황 - 데이터의 최종 연산 결과는 마지막에 그 데이터를 다룬 프로세스에 따라 달라짐  Race condition이 발생하는 경우   Kernel 수행 중 interrupt 발생 시   image   Process가 system call을 하여 kernel mode로 수행 중인데 context switching이 일어나는 경우   image  image   Multiprocessor에서 shared memory 내의 kernel data   image  Process Synchronization 문제   shared data의 동시접근(concurrent access)은 데이터의 불일치 문제(','6. Process Synchronization(Concurrency Control)'),(_binary '\0','2023-11-15 04:46:56.420902',30,98,NULL,1,'## The Deadlock Problem\n- **Deadlock**: 일련의 프로세스들이 서로가 가진 자원을 기다리며 block된 상태\n- Resource(자원)\n  - 하드웨어, 소프트웨어 등을 포함\n  - I/O device, CPU cycle, memory space, semaphore 등\n  - 프로세스가 자원을 사용하는 절차: request &rarr; allocate &rarr; use &rarr; release\n\n# Deadlock 발생의 4가지 조건\n1. **Mutual exclusion**: 매 순간 *하나의 프로세스만이 자원을 사용 가능*\n2. **No preemption**: 프로세스는 자원을 스스로 내어놓고 *강제로 빼앗기지 않음*\n3. **Hold and wait**: 자원을 가진 프로세스가 다른 자원을 기다릴 때 *보유자원을 놓지 않고 계속 가지고 있음*\n4. **Circular wait**: 자원을 기다리는 프로세스 간에 *사이클이 형성*됨\n\n# Resource-Allocation Graph(자원 할당 그래프)\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/9c491ffb-ca41-4417-82f9-d607856ee0e3)  \n- Vertex: process P, resource R\n- Edge: \n   - request edge $P_i$ &rarr; $R_j$\n   - assignment edge $R_j$ &rarr; $P_i$\n- 그래프에 cycle이 없으면 deadlock 아님\n- 그래프에 cycle이 있으면\n   - if *only one instance* per resource type, then *deadlock*\n   - if *several instances* per resource type, *possibility of deadlock*\n\n# Deadlock의 처리 방법\n1. **Deadlock Prevention**\n   - 자원 할당 시 deadlock의 4가지 필요 조건 중 어느 하나가 만족되지 않도록 방지\n   - Utilization &darr;, throughput &darr;, starvation problem\n2. **Deadlock Avoidance**\n   - 자원 요청에 대한 부가 정보를 이용해 deadlock 가능성 없는 경우에만 자원 할당\n   - 시스템 state가 원래 state로 돌아올 수 있는 경우에만 자원 할당\n3. **Deadlock Detection and recovery**\n   - deadlock 발생은 허용하되 그에 대한 detection 루틴을 두어 deadlock 발견 시 recover\n4. **Deadlock Ignorance**\n   - Deadlock을 시스템이 책임X\n   - 대부분의 OS가 채택\n   -  deadlock은 자주 발생하는 이벤트가 아니기 때문에 데드락을 방지하기 위해 많은 오버헤드를 두는 것이 비효율적\n\n# Deadlock Prevention\n1. Mutual exclusion\n   - 배제 불가: 공유해서는 안 되는 자원의 경우 반드시 성립해야 함\n2. Hold and wait\n   - 프로세스가 자원을 요청할 때 다른 어떤 자원도 가지고 있지 않아야 함\n   - sol 1) 프로세스 시작 시 모든 필요한 자원을 할당받게 함\n   - sol 2) 자원이 필요한 경우 보유 자원을 모두 놓고 다시 요청\n3. No preemption\n   - 프로세스가 어떤 자원을 기다려야 하는 경우 이미 보유한 자원이 선점됨(강제로 빼앗길 수 있음)\n   - 모든 필요한 자원을 얻을 수 있을 때 그 프로세스는 다시 시작됨\n   - state를 쉽게 save하고 다시 restore할 수 있는 자원에서 주로 사용(CPU, memory)\n4. Circular wait\n   - 모든 자원 유쳥에 할당 순서를 정하여 정해진 순서대로만 자원 할당\n\n# Deadlock Avoidance\n- 가장 단순하고 일반적인 모델은 프로세스들이 필요로 하는 각 자원별 최대 사용량을 미리 선언하도록 하는 방법\n- **safe state**\n   - 시스템 내의 프로세스들에 대한 safe sequence가 존재하는 상태\n- **safe sequence**\n   - 프로세스의 sequence가 safe하려면 $P_i$의 자원 요청이 \"가용 자원 + 모든 $P_j$의 보유 자원\"에 의해 충족되어야 함\n   - 조건을 만족하면 다음 방법으로 모든 프로세스의 수행 보장\n     - $P_i$의 자원 요청이 즉시 충족될 수 없으면 모든 $P_j$가 종료될 때까지 기다림\n     - $P_{i-1}$이 종료되면 $P_i$의 자원요청을 만족시켜 수행 \n- 시스템이 safe state에 있으면 &rarr; no deadlock\n- 시스템이 unsafe state에 있으면 &rarr; possibility of deadlock\n- Avoidance algorithm\n   - Single instance per resource types: **Resource Allocation Graph Algorithm**  \n   - Multiple instances per resource types: **Banker\'s Algorithm**\n\n## Resource Allocation Graph Algorithm\n- Clamin edge $P_i$ &rarr; $R_j$\n   - 프로세스 $P_i$가 미래에 자원 $R_j$를 요청할 수 있음을 뜻함(점선)\n   - 프로세스가 해당 자원 요청 시 request edge로 바뀜(실선)\n   - $R_j$가 release되면 assignment edge는 다시 claim edge로 변경\n- request edge의 assignment edge 변경 시 (점선을 포함하여) cycle이 생기지 않는 경우에만 요청 자원 할당\n- Cycle 생성 여부 조사 시 프로세스의 수가 n일 때 $O(n^2)$ 시간이 걸림\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/d6e9845f-fef3-43f3-be52-6fd847199d19)\n\n## Banker\'s Algorithm\n- $P_0, P_1, P_2, P_3, P_4$\n- A(10), B(5), C(7) instances\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/f3c2c9c2-1f97-437b-8ad5-1f085f79a663)\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/3df0f9c8-7c60-46dd-86b8-86d1a8a040fc)\n\n\n# Deadlock Detection and Recovery\n- Deadlock Detection\n  1. single instance per resource type: 자원 할당 그래프에서의 cycle이 곧 deadlock을 의미\n  2. multiple instance per resource type: Banker\'s algorithm과 유사한 방법 활용\n- Wait-for graph algorithm\n  - single instance per resource type\n  - Wait-for graph\n    - 자원할당 그래프의 변형\n    - 프로세스만으로 node 구성\n    - $P_j$가 가지고 있는 자원을 $P_k$가 기다리는 경우 $P_k$ &rarr; $P_j$\n  - algorithm\n    - Wait-for graph에 *사이클이 존재하는 지*를 주기적으로 조사\n    - $O(n^2)$\n- Recovery\n  1. **Process termination**\n     - Abort all deadlocked processes\n     - Abort one process at a time until the deadlock cycle is eliminated\n  2. **Resource Preemption**\n     - 비용을 최소화할 victim의 선정\n     - safe state로 rollback하여 process를 restart\n     - Starvation 문제\n        - 동일한 프로세스가 게속해서 victim으로 선정되는 경우\n        - cost factor에 rollback 횟수도 같이 고려\n\n## Single instance per resource type\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/4e2ef6ba-b4d0-4ef8-b225-8386309a7d9a)\n\n## Multiple instance per resource type\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/f2aafbc4-cb79-4497-8a8c-5f7da9d2d31a)\n','The Deadlock Problem   Deadlock: 일련의 프로세스들이 서로가 가진 자원을 기다리며 block된 상태  Resource(자원)  하드웨어, 소프트웨어 등을 포함  I/O device, CPU cycle, memory space, semaphore 등  프로세스가 자원을 사용하는 절차: request → allocate → use → release  Deadlock 발생의 4가지 조건   Mutual exclusion: 매 순간 하나의 프로세스만이 자원을 사용 가능  No preemption: 프로세스는 자원을 스스로 내어놓고 강제로 빼앗기지 않음  Hold and wait: 자원을 가진 프로세스가 다른 자원을 기다릴 때 보유자원을 놓지 않고 계속 가지고 있음  Circular wait','7. Deadlocks'),(_binary '','2023-11-15 04:47:10.477205',30,99,'2023-11-15 04:04:58.874939',1,'## Logical vs Physical Address\n1. **Logical address(=virtual address)**\n   - 프로세스마다 독립적으로 가지는 주소 공간\n   - 각 프로세스마다 0번지부터 시작\n   - **CPU가 보내는 주소는 logical address**\n2. **Physical address**\n   - 메모리에 실제 올라가는 위치\n- 주소 바인딩(=address translation): 주소를 결정하는 것\n   - Symbolic address &rarr; Logical address &rarr; Physical address\n\n# Address Binding\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/dca76ed1-fd6f-4f6a-a63c-1aa10c9fcfc5)  \n### 1. **Compile time binding**\n- physical address가 컴파일 시 알려짐\n- 시작 위치 변경 시 재컴파일\n- 컴파일러는 absolute code 생성\n### 2. **Load time binding**\n- Loader의 책임 하에 물리적 메모리 주소 부여\n- 컴파일러가 relocatable code를 생성한 경우 가능\n### 3. **Execution time binding(=Run time binding)**\n- 수행이 시작된 이후에도 프로세스의 메모리 상 위치를 옮길 수 있음\n- CPU가 주소를 참조할 때마다 binding을 점검(address mapping table)\n- 하드웨어적인 지원이 필요(base and limit registers, MMU)\n\n# Memory-Management Unit(MMU)\n- MMU: **logical address를 physical address로 매핑해주는 hardware device**\n- MMU Scheme: 사용자 프로세스가 CPU에서 수행되며 생성해내는 모든 주소값에 대해 base register의 값을 더한다\n- user program: logical address만을 다루며 physical address를 볼 수 없음\n\n## Dynamic Relocation\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/7d496363-f5d7-4717-80b5-4a2552905eb4) \n\n## Hardware Support for Address Translation\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/f1c7ac89-2093-4d7f-b522-3d07ae7c2fec)  \n- OS 및 사용자 프로세스 간의 메모리 보호를 위해 사용하는 레지스터\n  - **Base register**(=relocation register): 접근할 수 있는 물리적 메모리 주소의 최소값\n  - **Limit register**: 논리적 주소의 범위\n\n# Terminologies\n## Dynamic Loading\n- 프로세스 전체를 메모리에 미리 다 올리는 것이 아니라 **해당 루틴이 불려질 때 메모리에 load하는 것**\n- memory utilization&uarr;\n- 가끔씩 사용되는 많은 양의 코드의 경우 유용(예: 오류 처리 루틴)\n- OS의 특별한 지원 없이 프로그램 자체에서 구현 가능(OS는 라이브러리를 통해 지원 가능)\n- Loading: 메모리로 올리는 것\n- Paging처럼 OS가 지원해주는 것이 아닌, 프로그래머가 직접 구현하는 부분\n\n## Overlays\n- 메모리에 프로세스의 부분 중 실제 필요한 정보만을 올림\n- 프로세스의 크기가 메모리보다 클 때 유용\n- OS의 지원없이 사용자에 의해 구현\n- 작은 공간의 메모리를 사용하던 초창기 시스템에서 수작업으로 프로그래머가 구현\n  - Manual Overlay\n  - 프로그래밍이 매우 복잡\n- OS의 지원없음\n\n## Swapping\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/0c8d3a2c-1ed0-4e08-b0da-e78ffa3d737b)\n- **Swapping**: 프로세스를 일시적으로 메모리에서 backing store로 쫒아내는 것\n- **Backing store(=swap area)**\n  - 디스크: 많은 사용자의 프로세스 이미지를 담을 만큼 충분히 빠르고 큰 저장 공간\n- Swap in / Swap out\n  - 일반적으로 중기 스케줄러(swapper)에 의해 swap out 시킬 프로세스 선정\n  - priority-based CPU scheduling algorithm\n    - 우선순위가 낮은 프로세스를 swapped out, 높은 프로세스를 swapped in\n  - Compile time 혹은 load time binding에서는 원래 메모리 위치로 swap in 해야 함\n  - Execution time binding에서는 추후 빈 메모리 영역 아무 곳에나 올릴 수 있음\n  - swap time은 대부분 tranfer time(swap되는 양에 비례하는 시간)\n\n## Dynamic Linking\n- Linking을 execution time까지 미루는 기법\n- *Static linking*\n  - 라이브러리가 프로그램의 **실행 파일 코드에 포함**됨\n  - 실행 파일의 **크기가 커짐**\n  - 동일한 라이브러리를 각각의 프로세스가 메모리에 올리므로 **메모리 낭비**\n- *Dynamic Linking*\n  - 라이브러리가 **실행 시 linking됨**\n  - **라이브러리 호출 부분에** 라이브러리 루틴의 위치를 찾기 위한 **stub**이라는 작은 코드를 둠\n  - 라이브러리가 이미 메모리에 **있으면 그 루틴의 주소로 가고 없으면 디스크에서 읽어옴**\n  - OS의 지원 필요\n  - windows: dll\n\n# Allocation of Physical Memory\n- 메모리는 일반적으로 두 영역으로 나뉨\n  - **OS 상주 영역(kernel space)**: interrupt vector와 함께 낮은 주소 영역 사용\n  - **사용자 프로세스 영역(user space)**: 높은 주소 영역 사용\n- 사용자 프로세스 영역의 할당 방법\n  1. *Contiguous allocation*: 메모리에 연속적으로 적재\n     - Fixed partition allocation, Variable partition allocation\n  2. *Noncontiguous allocation*: 하나의 프로세스가 메모리의 여러 영역에 분산\n     - Paging, Segmentation, Paged Segmentation\n\n# Contiguous allocation\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/42aa617f-ae48-4937-a93a-afe2c14188d1)  \n## 1. 고정 분할 방식(Fixed partition allocation)\n- 물리적 메모리를 몇 개의 영구적 분할로 나눔\n- 분할의 크기가 모두 동일한 방식과 서로 다른 방식이 존재\n- 분할 당 하나의 프로그램\n- 융통성 X\n  - 동시에 메모리에 load되는 프로그램의 수가 고정됨\n  - 최대 수행 가능 프로그램 크기 제한\n- **Internal fragmentation, External fragmentation 발생**\n## 2. 가변 분할 방식(Variable partition allocation)\n- 프로그램의 크기를 고려해 할당\n- 분할의 크기, 개수가 동적으로 변함\n- 기술적 관리 기법 필요\n- **External fragmentation도 발생**\n\n## External fragmentation vs Internal fragmentation\n1. External fragmentation\n   - 프로그램의 크기보다 분할의 크기가 작은 경우\n2. Internal fragmentation\n   - 프로그램의 크기보다 분할의 크기가 큰 경우\n   - 하나의 분할 내부에서 발생하는 사용되지 않는 메모리 조각\n   - 특정 프로그램에 배정되었지만 사용되지 않는 공간\n\n## Hole\n- 가용 메모리 공간\n- 다양한 크기의 hole들이 메모리 여러 곳에 흩어져 있음\n- 프로세스가 도착하면 수용가능한 hole을 할당\n- OS는 할당공간과 가용공간(hole)의 정보를 유지  \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/72b35f09-b541-4767-bee4-37968200a1cc)\n\n## Dynamic Storage-Allocation Problem\n- 가변 분할 방식에서 size n인 요청을 만족하는 가장 적절한 hole을 찾는 문제\n1. **First-fit**\n   - size가 n 이상인 것 중 **최초로 찾아지는 hole에 할당**\n2. **Best-fit**\n   - **size가 n 이상인 가장 작은 hole에 할당**\n   - hole이 크기 순으로 정렬되지 않은 경우 모든 hole의 리스트를 탐색해야 함\n   - 많은 수의 아주 작은 hole들이 생성됨\n3. **Worst-fit**\n   - **size가 n 이상인 가장 큰 hole에 할당**\n   - 모든 리스트를 탐색해야 함\n   - 상대적으로 아주 큰 hole들이 생성됨\n\n## Compaction\n- external fragmentation 문제를 해결하는 한 가지 방법\n- 사용 중인 메모리 영역을 한 군데로 몰아 큰 block을 만드는 것\n- 비용이 많이 듦\n- Execution time binding인 경우에만 수행 가능\n\n# Noncontiguous allocation - 1. Paging\n- Process의 virtual memory를 **동일한 사이즈의 page 단위로 나눔**\n- virtual memory의 내용이 page 단위로 noncontiguous하게 저장됨\n- 일부는 backing storage에, 일부는 physical memory에 저장  \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/94c16d85-5bd6-4239-8b5a-76b25513f49e)\n\n## Address Translation Architecture\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/95e2ce5b-2312-42e0-8578-2f9453dfbec1)\n\n## Implementation of Page Table\n- Page Table은 main memory에 상주\n- **Page-Table Base Register(PTBR)**: page table을 가리킴\n- **Page-Table Length Register(PTLR)**: 테이블 크기를 보관\n- 모든 메모리 접근 연산에는 2번의 memory access 필요\n  - page table 접근 1번, 실제 date/instruction 접근 1번\n- 속도 향상을 위해 Translation Look-aside Buffer(**TLB**)라 불리는 고속의 lookup hardware *cache* 사용\n\n# Paging Hardware with TLB\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/622afbac-8806-4f3c-a578-02096ce52d89)\n\n## TLB\n- TLB(=Associative registers): parallel search가 가능\n  - TLB에는 일부 page table이 존재\n- Address Translation\n  - 만약 해당 VPN가 TLB에 있는 경우 곧바로 PFN을 얻음\n  - 없다면 main memory에 있는 page table로부터 PFN을 얻음\n  - **TLB는 context switching 때 flush(프로세스마다 TLB를 다르게 가짐)**\n\n## Effective Access Time\n- TLB lookup time = $\\epsilon$\n- Memory access time = 1\n- Hit ratio = $\\alpha$\n- EAT = (1 + $\\epsilon$)$\\alpha$ + (2 + $\\epsilon$)(1 - $\\alpha$) = 2 + $\\epsilon$ - $\\alpha$\n\n# Two-Level Page Table\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/5f998c46-3168-43e7-986e-ae6ab6bb9b62)  \n- 현대의 컴퓨터는 address space가 매우 큰 프로그램 지원\n  - 32 bit address 사용 시 : $2^{30}$ = G, 4GB의 address space\n    - page size가 4k 시 1M개의 PTE가 필요\n    - 각 PTE가 4B시 프로세스 당 4M의 Page table 필요\n    - but 대부분 프로그램은 4G 중 극히 일부분만 사용하므로 공간 낭비\n  - page table 자체를 page로 구성\n  - 사용되지 않는 주소 공간에 대한 outer page table의 entry 값은 NULL(대응하는 inner page table이 없음)\n- Example\n  - logical address: 20bit page number, 12bit page offset\n  - 20bit 중 10bit page directory number, 10bit page directory offset  \n  ![image](https://github.com/Haaarimmm/TIL/assets/108309396/3b81fd00-70f8-4890-a4ed-f05a5f2e9168)\n  - $P_1$: outer page table의 index\n  - $P_2$: outer page table의 offset\n- Address-Translation Scheme    \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/c942a499-a90a-4a65-abb2-78bc119f00b8)\n\n## Multilevel Paging and Performance\n- Address space가 더 커지면 다단계 페이지 테이블 필요\n- 각 단계의 페이지 테이블이 메모리에 존재하므로 Logical addressdml physical address **변환에 더 많은 메모리 접근 필요**\n- TLB를 통해 메모리 접근 시간을 줄일 수 있음\n- ex) 4단계 페이지 테이블을 사용하는 경우: 메모리 접근 5번 필요\n\n## Valid(v) / Invalid(i) Bit in a Page Table\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/3989a344-34fe-41a2-ab59-e555c8ac59f5)  \n- 6, 7번 page가 현재 사용되지 않지만 만들어놓고 invalid bit을 통해 check\n- PTE마다 가지는 bit\n  - *Protection bit*: page에 대한 접근 권한(read/write/read-only)\n  - *Valid/Invalid bit*\n    - valid: 해당 주소의 frame에 그 프로세스를 구성하는 유효한 내용이 있음을 뜻함(접근 허용)\n    - invalid: 프로세스가 주소 부분을 사용하지 않는 경우, 해당페이지가 메모리에 올라와 있지않고 Swap area에 있는 경우(접근  불허)\n\n# Inverted Page Table\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/05e125d6-af91-4873-9985-b1a38d7089a5)  \n- page table이 매우 큰 이유\n  - 모든 process별로 logical address에 대응되는 모든 page에 대해 PTE가 존재\n  - 대응하는 page가 메모리에 있든 아니든 간에 page table에는 entry로 존재\n- **Inverted Page Table**\n  - **Page frame 하나 당 page table에 하나의 entry를 둔 것**(system-wide)\n  - 각 PTE는 각각의 물리적 메모리의 PFN이 담고 있는 내용 표시(PID, process의 logical address)\n  - 단점: 테이블 전체를 탐색해야 함\n  - 조치: Base register 사용(expensive)\n\n# Shared Page\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/894b5f26-be76-4b1f-8a16-ce8cab96034d)   \n- Shared Page 조건\n  1. Shared code(=Re-entrant, pure code)가 read-only여야 한다.\n  2. 하나의 code만 메모리에 올린다.\n  3. Shared code는 모든 프로세스에서 logical address가 동일해야 한다.\n  - ex. text editors, window systems, compilers)\n- Private code and data(↔ Shared code)\n  - 각 프로세스들은 독자적으로 메모리에 올림\n  - Private data는 logical address가 달라도 무방\n\n# Noncontiguous allocation - 2. Segmentation\n- 프로그램은 의미 단위인 여러 개의 segment로 구성\n  - 일반적으로는 code, stack, data 부분이 하나씩의 세그먼트로 정의됨\n- Segment = logical unit\n  - main(), function, global variables, stack, symbol table, arrays...\n\n## Segmentation Artchitecture\n- Logical address: **<segment-number, offset>**\n- Segment table\n  - base - **starting physical address** of the segment\n  - limit - **length** of the segment\n- **Segment-Table Base Register(STBR)**: 물리적 메모리에서의 segment table의 위치\n- **Segment-Table Length Register(STLR)**: 프로그램이 사용하는 segment의 수\n- 장점: Segment는 의미 단이기 때문에 Sharing과 Protection에 있어 paging보다 훨씬 효과적\n  - Sharing\n    - shared segment\n    - same segment number\n    - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/d5656343-841a-481a-9ccf-d83dcd04c919)\n  - Protection bit: segment별로 존재\n    - Valid bit = 0 &rarr; illegal segment\n    - Read/Write/Execution 권한 bit\n- 단점: Segment의 길이가 동일X &rarr; 가변 분할 방식에서와 동일한 문제점들이 발생\n  - Allocation\n    - first fit / best fit\n    - external fragmentation 발생\n\n## Segmentation Hardware\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/b48f5b1a-b5c3-4cbd-9b95-3cd0f0c2f938)  \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/03df8303-6a4a-43c8-8170-ac30f1437d86)\n\n# Segmentation with Paging\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/9b61931d-4e71-46e1-8b15-402e424522c0)  \n- Outer Table이 Segmentation, Inner Table이 Paging 기법 사용 \n- pure segmentation과의 차이점\n  - segment-table entry가 segment의 base address를 가지고 있는 것이 아니라 segment를 구성하는 page table의 base address를 가지고 있음\n- segment offset이 segment length 이내일 경우만 valid\n\n## Physical address 계산법\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/9fa1982d-76c9-4632-831f-6e858d1c3c16)  \n- Logical address\n  - s : Segment number\n  - d : displacement(offset)\n  - p : Page number\n  - d\' == d (if valid)\n  - f : Frame number\n1. STBR + s 를 통해 Segment Table Entry 찾음\n2. Segment Length가 d(offset)보다 크면 통과(valid)\n3. Page Table Base + p를 통해 Page Table Entry 찾음\n4. PTE의 f 와 d\'을 합치면 physical address','Logical vs Physical Address   Logical address(=virtual address)   프로세스마다 독립적으로 가지는 주소 공간  각 프로세스마다 0번지부터 시작  CPU가 보내는 주소는 logical address   Physical address   메모리에 실제 올라가는 위치  주소 바인딩(=address translation): 주소를 결정하는 것  Symbolic address → Logical address → Physical address  Address Binding image 1. Compile time binding   physical address가 컴파일 시 알려짐  시작 위치 변경 시 재컴파일  컴파일러는 absolute code 생성 2. Load ti','8. Memory Management'),(_binary '\0','2023-11-15 04:43:45.358828',30,100,NULL,1,'# 9. Virtual Memory\n## Demand Paging\n- 대부분의 시스템은 Paging 사용 중\n- Demand Paging? 실제로 필요할 때 Page를 메모리에 올리는 것\n- 장점\n  - I/O 양의 감소\n  - Memory 사용량 감소\n  - 빠른 응답 시간 &rarr; 한정된 메모리 공간을 더 잘 쓰기 때문, Disk I/O 감소 등\n  - 더 많은 프로그램, 사용자 수용\n- Valid/Invalid bit 사용\n  - Invalid의 의미\n    - 사용되지 않는 주소 영역\n    - 페이지가 물리적 메모리에 없는 경우\n  - 초기에는 모든 PTE가 invalid로 초기화\n  - address translation 시 invalid로 set되어 있으면 &rarr; **Page fault**\n\n## Memory에 없는 Page의 Page Table\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/304de973-f7c4-4528-9fd5-1b47699fb1cf)\n\n# Page Fault\n- Invalid page에 접근하면 MMU가 *page fault trap* 발생시킴\n- Kernel mode로 들어가서 page fault handler가 invoke됨\n- Page fault 처리 순서\n  1. Invalid reference? (eg. bad address, protection violation) &rarr; abort process\n  2. 빈 page frame을 가져온다. 없으면 다른 page frame을 뺏어온다. (page replacement)\n  3. 해당 페이지를 디스크에서 메모리로 읽어온다 (Disk I/O)\n     1. 디스크 I/O가 끝나기까지 이 프로세스는 CPU를 preempt당함(blocked)\n     2. 디스크 read가 끝나면 PTE에 frame number 기록 후 valid로 set\n     3. ready queue에 프로세스를 추가 &rarr; dispatch later\n  4. 프로세스가 CPU를 잡고 다시 running\n  5. 중단되었던 instruction을 재개\n\n## Steps in Handling a Page Fault\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/86874e9c-dca2-4ece-aae3-a9b76c0960ba)\n\n## Performance of Demand Paging\n- Page fault rate $0 \\le p \\le 1$\n  - $p = 0$, no page faults\n  - $p = 1$, every reference is a fault\n- Effective Access Time = $(1 - p) \\times$memory access + $p \\times$(OS & HW page fault overhead + [swap page out if needed] + swap page in + OS & HW restart overhead)\n\n## Free frame이 없는 경우\n- Page replacement\n  - 어떤 frame을 빼앗아올지 결정해야 함\n  - 곧바로 사용되지 않을 page를 쫓아내는 것이 좋음\n  - 동일한 페이지가 여러 번 메모리에서 쫓겨났다가 다시 들어올 수 있음\n- Replacement Algorithm\n  - page-fault rate을 최소화하는 것이 목표\n  - 알고리즘 성능: 주어진 page reference string에 대해 page fault를 얼마나 내는지\n  - reference string: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3  \n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/72999df8-aa97-44e7-9558-affb4c1953f8)\n\n# Optimal Algorithm\n- MIN(OPT): 가장 먼 미래에 참조되는 page를 replace\n- 다른 알고리즘의 성능에 대한 upper bound 제공\n  - Belady\'s optimal algorithm, MIN, OPT 등으로 불림\n- Offline algorithm: 미래의 참조를 아는 알고리즘\n- 4 frames example  \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/c7e185a2-17d8-48b1-9f25-aaf7ea82f10c)\n\n# FIFO Algorithm\n- FIFO: First In First Out  \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/72184d04-3ea7-431d-a362-f7bc03154965)\n- FIFO Anomaly(Belady\'s Anomaly)\n  - more frames != less page faults\n\n# LRU Algorithm\n- LRU: Least Recently Used  \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/8ec9940b-eec3-4366-8e3f-02927d666aec)\n\n# LFU Algorithm\n- LFU: Least Frequently Used\n- 최저 참조 횟수인 page가 여럿 있는 경우\n  - LFU 알고리즘 자체에서는 여러 page 중 임의로 선정\n  - 성능 향상을 위해 LRU한 page를 지우게 구현할 수 있음\n- 장단점\n  - LRU처럼 직전 참조 시점만 보는 것이 아니라 장기적인 시간 규모를 보기 때문에 page의 인기도를 좀 더 정확히 반영 가능\n  - 참조 시점의 최근성을 반영하지 못 함\n  - LRU보다 구현이 복잡함\n\n# LRU와 LFU 알고리즘의 구현\n- LRU\n  - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/ee3448dc-dd51-40ac-b216-50ea199da0f6)\n  - $O(1)$\n- LFU\n  - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/a12a0937-dad6-4aa3-b556-58704e03c11d)\n  - $O(n)$\n  - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/b6fa07ac-3454-4779-88aa-e775eb846b60)\n  - $O(log n)$\n\n# 다양한 Caching 환경\n- Caching\n  - 한정된 빠른 공간(캐시)에 요청된 데이터를 저장해두었다가 후속 요청 시 캐시로부터 직접 서비스하는 방식\n- Cache 운영의 시간 제약\n  - 교체 알고리즘에서 삭제할 항목을 결정하는 일에 지나치게 많은 시간이 걸리는 경우 실제 시스템에서 사용할 수 없음\n  - Buffer caching이나 Web caching의 경우 O(1)에서 O(log n)정도까지 허용\n  - Paging system의 경우\n    - **page fault인 경우에만 OS가 관여**\n    - 페이지가 이미 메모리에 존재하는 경우 참조시각 등의 정보를 OS가 알 수 없음\n\n# Clock Algorithm\n- LRU의 근사 알고리즘 (= Second chance algorithm = NRU(Not Recently Used))\n- Reference bit을 사용해서 교체 대상 페이지 선정(circular list)\n- reference bit가 0인 것을 찾을 때까지 포인터를 하나씩 앞으로 이동\n- 포인터 이동하는 중에 reference bit 1은 모두 0으로 바꿈\n- Reference bit이 0인 것을 찾으면 그 페이지를 교체\n- 한 바퀴를 돌아와서도(=second chance) 0이면 replace\n- 자주 사용되는 페이지라면 second chance가 올 때도 1  \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/ef167583-cae3-4ddb-b141-49d60672590b)\n\n\n## Clock algorithm의 개선\n  - reference bit과 modified bit(dirty bit)을 함께 사용\n  - reference bit = 1: 최근에 참조된 페이지\n  - modified bit = 1: 최근에 변경된 페이지(disk I/O 필요함)\n    - modified bit = 0일 경우 disk I/O 없이 memory에서만 삭제하면 됨(내용이 동일하므로)\n\n# Page Frame의 Allocation\n- 실제로 프로그램이 원활하게 실행되기 위해서는 일련의 page들이 메모리에 같이 올라와 있어야 효율적임\n- Allocation problem: 각 process에 얼마만큼의 page frame을 할당할 것인가?\n- Allocation의 필요성\n  - 메모리 참조 명령어 수행 시 명령어, 데이터 등 여러 페이지 동시 참조\n    - 명령어 수행을 위해 최소한 할당되어야 하는 frame의 수가 있음\n  - Loop를 구성하는 page들은 한꺼번에 allocate되는 것이 유리함\n    - 최소한의 allocation이 없으면 매 loop마다 page fault\n- Allocation Scheme\n  - **Equal allocation**: 모든 프로세스에 똑같은 갯수 할당\n  - **Proportional allocation**: 프로세스 크기에 비례하여 할당\n  - **Priority allocation**: 프로세스의 priority에 따라 다르게 할당\n\n## Global vs Local Replacement\n1. Global replacement\n  - replace 시 다른 process에 할당된 frame을 빼앗아 올 수 있다\n  - process별 할당량을 조절하는 또 다른 방법\n  - FIFO, LRU, LFU 등의 알고리즘을 global replacement로 사용 시에 해당\n  - working set, PFF 알고리즘 사용\n2. Local replacement\n  - 자신에게 할당된 frame 내에서만 replacement\n  - FIFO, LRU, LFU 등의 알고리즘을 process 별로 운영 시\n\n# Thrashing\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/a81c897e-88b9-4c22-a6cc-264d16068167)  \n- 많은 프로그램이 동작 &rarr; 각 프로그램에 할당된 메모리가 적어짐\n- 프로세스의 원활한 수행에 필요한 최소한의 page frame 수를 할당 받지 못한 경우 발생\n- Page fault rate이 매우 높아짐\n- CPU utilization이 낮아짐\n- OS는 MPD(Multiprogramming degree)를 높여야 한다고 판단\n- 또 다른 프로세스가 시스템에 추가됨(higher MPD)\n- 프로세스 당 할당된 frame의 수가 더욱 감소\n- 프로세스는 page의 swap in/swap out으로 매우 바쁨(page fault 자주 발생)\n- 대부분의 시간에 CPU는 한가함\n- low throughput\n\n## Thrashing의 해결방법\n# 1. Working-Set Model\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/206946b0-1cdf-43da-90f9-2001dbe1737b)  \n- Locality of reference\n  - 프로세스는 특정 시간동안 일정 장소만을 집중적으로 참조함\n  - **locality set**: 집중적으로 참조되는 해당 page들의 집합\n- Working-set model\n  - **Working set**: Locality에 기반하여 프로세스가 일정 시간동안 원활하게 수행되기 위해 한꺼번에 메모리에 올라와 있어야 하는 page들의 집합\n  - Working set 모델에서는 process의 working set 전체가 메모리에 올라와 있어야 수행되고 그렇지 않을 경우 모든 frame을 반납한 후 swap out(suspended)\n  - Thrashing을 방지함\n  - MPD를 조절함\n\n## Working-Set Algorithm\n- Working set의 결정\n  - Working set window를 통해 알아냄\n  - winodw size가 $\\Delta$인 경우\n    - 시각 $t_i$에서의 working set WS($t_i$): Time interval [$t_i - \\Delta , t_i$] 사이에 참조된 서로 다른 페이지들의 집합\n  - Working set에 속한 page는 메모리에 유지, 속하지 않은 것은 버림\n  - 즉, 참조된 후 $\\Delta$시간 동안 해당 page를 메모리에 유지한 후 버림\n- Working-Set algorithm\n  - process들의 working set size의 합이 page frame의 수보다 큰 경우\n    - 일부 process를 swap out시켜 남은 process의 working set을 우선적으로 충족시켜 줌(MPD를 줄임)\n  - working set을 다 할당하고도 page frame이 남는 경우\n    - swap out되었던 프로세스에게 working set을 할당(MPD를 늘림)\n- Window size $\\Delta$\n  - working set을 제대로 탐지하기 위해서는 window size를 잘 결정해야 함\n  - $\\Delta$값이 너무 작으면 locality set을 모두 수용하지 못할 우려\n  - $\\Delta$값이 너무 크면 여러 규모의 locality set 수용\n  - $\\Delta$값이 $\\infty$이면 전체 프로그램을 구성하는 page를 working set으로 간주\n\n# 2. PFF(Page-Fault Frequency) Scheme\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/6ad07a85-a87c-417b-8a21-96b446827a57)  \n- page-fault rate의 상한값과 하한값을 둔다\n  - page-fault rate이 상한값 이상이면 frame을 더 할당함\n  - page-fault rate이 하한값 이하이면 할당 frame 수를 줄임\n- Free frame이 없으면 일부 프로세스를 swap out\n\n# Page Size의 결정\n- Page size &darr;\n  - 페이지 수 증가\n  - 페이지 테이블 크기 증가\n  - Internal fragmentation 감소\n  - Disk transfer의 효율성 감소\n    - Seek/rotation vs transfer\n  - 필요한 정보만 메모리에 올라와 메모리 이용이 효율적\n    - Locality의 활용 측면에서는 좋지 않음\n- Trend - Larger page size','9. Virtual Memory Demand Paging   대부분의 시스템은 Paging 사용 중  Demand Paging? 실제로 필요할 때 Page를 메모리에 올리는 것  장점  I/O 양의 감소  Memory 사용량 감소  빠른 응답 시간 → 한정된 메모리 공간을 더 잘 쓰기 때문, Disk I/O 감소 등  더 많은 프로그램, 사용자 수용  Valid/Invalid bit 사용  Invalid의 의미   사용되지 않는 주소 영역  페이지가 물리적 메모리에 없는 경우  초기에는 모든 PTE가 invalid로 초기화  address translation 시 invalid로 set되어 있으면 → Page fault  Memory에 없는 Page의 Page Table image  Page Fault   ','9. Virtual Memory'),(_binary '','2023-11-16 00:53:38.410936',30,101,'2023-11-15 04:05:55.716585',1,'## File and File System\n- **File**\n  - 일반적으로 **비휘발성 보조기억장치**에 저장\n  - OS는 다양한 저장 장치를 **file이라는 동일한 논리적 단위**로 볼 수 있게 해줌\n  - Operation: create, read, write, reposition, delete, open, close 등\n- **File attribute(파일의 metadata)**\n  - 파일을 관리하기 위한 각종 정보들\n    - 파일 이름, 유형, 저장된 위치, 파일 사이즈\n    - 접근 권한(r/w/x), 시간(생성/변경/사용), 소유자 등\n- **File system**\n  - OS에서 파일을 관리하는 부분\n  - 파일 및 파일의 메타데이터, 디렉토리 정보 등을 관리\n  - 파일의 저장 방법 결정\n  - 파일 보호 등\n\n## Directory and Logical Disk\n### **Directory**\n- 파일의 메타데이터 중 일부를 보관하고 있는 일종의 특별한 *파일*\n- **디렉토리에 속한 파일 이름 및 파일 attribute들**\n- Operation: search a file, create a file, delete a file\n\n### **Partition(= Logical Disk)**\n- 하나의 물리적 디스크 안에 여러 파티션을 두는 게 일반적\n- 여러 개의 물리적인 디스크를 하나의 파티션으로 구성하기도 함\n- 물리적 디스크를 파티션으로 구성한 뒤 각각의 파티션에 file system을 깔거나 swapping 등 다른 용도로 사용 가능\n\n# `open()`\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/0285140d-8901-42b9-91ed-76fd47025fc2)\n- ex) open(\"/a/b/c\")\n- 디스크로부터 파일 c의 메타데이터를 메모리로 가지고 온다.\n- 이를 위해 directory path를 search 한다.\n- 과정\n  1. 루트 디렉토리(\"/\")를 open하고 그 안에서 파일 \"a\"의 위치를 획득한다.\n  2. 파일 \"a\"를 open한 후 read하여 그 안에서 파일 \"b\"의 위치를 획득한다.\n  3. 파일 \"b\"를 open한 후 read하여 그 안에서 파일 \"c\"의 위치를 획득한다.\n  4. 파일 \"c\"를 open한다.\n- 과정에서 알 수 있듯이, Directory path의 search에 너무 많은 시간이 소요된다.\n  - open을 read/write과 별도로 두는 이유이다.\n  - 한 번 open한 파일은 read/write 시 directory search 불필요하도록 한다.\n- Open file table\n  - 현재 open 된 파일들의 metadata 보관소 (in memory)\n  - 디스크의 metadata보다 몇 가지 정보가 추가됨\n    - Open한 프로세스의 수\n    - File offset : 파일 어느 위치 접근 중인지 표시 (별도 테이블 필요)\n- File descriptor (file handle, file control block)\n  - Open file table에 대한 위치 정보 (프로세스별)\n\n\n# File Protection - Access Control Method\n## 1. Access control Matrix\n   - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/642d185b-56db-47bc-b742-00e12c17d4d4)\n   - Access control list: 파일 별로 누구에게 어떤 접근 권한이 있는지 표시\n   - Capability: 사용자 별로 자신이 접근 권한을 가진 파일 및 해당 권한 표시\n## 2. Grouping\n   - 전체 user를 *owner, group, public*의 세 그룹으로 구분\n   - 각 파일에 대해 세 그룹의 접근 권한(rwx)을 3비트씩으로 표시\n   - ex) rwx(owner)r--(group)r--(other)\n## 3. Password\n   - 파일마다 password를 두는 방법(디렉토리 파일에 두는 방법도 가능)\n   - 모든 접근 권한에 대해 하나의 password: all-or-nothing\n   - 접근 권한 별 password: 암기 문제, 관리 문제\n\n## Access Methods\n- 시스템이 제공하는 파일 정보의 접근 방식\n1. **Sequential access**: 읽거나 쓰면 *offset은 자동적으로 증가*\n2. **Direct access or random access**: 파일을 구성하는 레코드를 *임의의 순서*로 접근 가능','File and File System   File  일반적으로 비휘발성 보조기억장치에 저장  OS는 다양한 저장 장치를 file이라는 동일한 논리적 단위로 볼 수 있게 해줌  Operation: create, read, write, reposition, delete, open, close 등  File attribute(파일의 metadata)  파일을 관리하기 위한 각종 정보들   파일 이름, 유형, 저장된 위치, 파일 사이즈  접근 권한(r/w/x), 시간(생성/변경/사용), 소유자 등  File system  OS에서 파일을 관리하는 부분  파일 및 파일의 메타데이터, 디렉토리 정보 등을 관리  파일의 저장 방법 결정  파일 보호 등  Directory and Logical Disk Directory ','10. File Systems'),(_binary '','2023-11-15 04:43:21.098852',30,102,'2023-11-15 04:43:02.533942',1,'# Allocation of File Data in Disk\n## 1. Contiguous Allocation\n  - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/b8aa20da-05d7-4340-84dd-8110686773b3)\n  1. 단점\n     - external fragmentation\n     - File grow가 어려움\n       - file 생성 시 얼마나 큰 hole을 배당할 것인가?\n       - grow 가능 vs 낭비(internal fragmentation)\n  2. 장점\n     - Fast I/O\n       - 파일의 용량과 관계없이 한 번의 seek/rotation으로 많은 바이트 transfer\n       - realtime file용으로, 또는 이미 run 중이던 process의 swapping용\n     - Direct access(=random access) 가능\n## 2. Linked Allocation\n   - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/4c19c792-61a2-4db3-b687-3823f6021b92)\n   1. 장점\n     - external fragmentation X\n   2. 단점  \n      - No random access  \n      - Reliability 문제: 한 sector가 고장나 pointer가 유실되면 많은 부분을 잃음  \n      - Pointer를 위한 공간이 block의 일부가 되어 공간 효율성&darr;\n        - 512 bytes/sector, 4 bytes/pointer \n   3. File-Allocation Table(FAT) 파일 시스템\n      - 포인터를 별도의 위치에 보관하여 reliability와 공간효율성 문제 해결\n## 3. Indexed Allocation\n   - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/15d70bd3-4542-4a2f-bc79-fae90352a7bb)\n   1. 장점\n      - external fragmentation X  \n      - Direct access 가능\n   2. 단점\n      - small file: 공간 낭비(실제로 많은 file들이 small)\n      - Too large file: 하나의 block으로 index를 저장하기에 부족\n      - 해결방안: linked scheme, multi-level index\n\n# UNIX File system의 구조\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/2aca0e44-0027-417c-8eb1-d5c6a6949245)  \n![image](https://github.com/Haaarimmm/TIL/assets/108309396/305af9ee-0a40-4c8f-94e6-f2275ae2d1d1)\n1. Boot block: 부팅에 필요한 정보\n2. Superblock: 파일 시스템에 관한 총체적인 정보를 담고 있다\n3. Inode: 파일 이름을 제외한 파일의 모든 메타 데이터를 저장\n4. Data block: 파일의 실제 내용을 보관\n\n# FAT File System\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/376e4d66-e247-4ef7-a0b0-2f9a7472141a)\n  - FAT: 파일의 메타데이터 중 위치정보만을 FAT에 보관한다.\n  - 나머지는 메타데이터는 디렉토리가 보관한다.\n  - linked allocation 형태의 위치정보를 블록에 담고있는 것이 아니라, FAT에 저장한다.\n  - 배열 형태로 각 블록의 다음 블록을 저장하고 있다.\n- 장점\n  - 배드섹터가 발생하더라도 FAT에서 pointer를 관리하므로 reliability 해결\n  - FAT 테이블만 메모리에 올려두면 디스크의 block에 직접 접근이 가능하다.\n  - 공간 효율성 문제 해결\n\n# Free-Space Management\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/b0ad42de-0014-45be-b8d3-7c3f20b937e7)  \n\n## 1. Bit map of bit vector\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/0f8c8aa0-f9de-4e7f-b1e7-3637af6327d0)\n- Bit map은 부가적인 공간을 필요로 함\n- 연속적인 n개의 free block을 찾는데 효과적\n\n## 2. Linked list\n- 모든 free block들을 링크로 연결(free list)\n- 연속적인 가용공간을 찾는 것은 쉽지 않다\n- 공간 낭비X\n\n## 3. Grouping\n- linked list 방법의 변형\n- 첫 번째 free block이 n개의 pointer를 가짐\n  - n-1 pointer는 free data block을 가리킴\n  - 마지막 pointer가 가리키는 block은 또 다시 n pointer를 가짐\n\n## 4. Counting\n   - 프로그램들이 종종 여러 개의 연속적인 block을 할당하고 반납한다는 성질에 착안\n   - (first free block, # of contiguous free blocks)\n\n# Directory Implementation\n## 1. Linear list\n   - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/496df533-7c5a-48af-979a-5bae2b102a78)\n   - <file name, file의 metadata>의 list\n   - 구현이 간단\n   - 디렉토리 내에 파일이 있는지 찾기 위해서는 linear search 필요(time-consuming)\n\n## 2. Hash Table\n   - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/5565267d-0e3b-4b6d-b019-56ccdd149d4a)\n   - linear list + hashing\n   - Hash table은 file name을 이 파일의 linear list의 위치로 바꾸어줌\n   - 직접 접근이 가능하므로 search time을 없앰\n   - Hash collision 발생 가능\n\n### File의 metadata의 보관 위치\n  - 디렉토리 내에 직접 보관\n  - 디렉토리에는 포인터를 두고 다른 곳에 보관: inode, FAT 등\n\n### Long file name의 지원\n   - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/92ebcc43-2b22-443a-9ece-d4f463897590)\n   - <file name, file의 metadata>의 list에서 각 entry는 일반적으로 고정 크기\n   - file name이 고정 크기의 entry 길이보다 길어지는 경우 entry의 마지막 부분에 이름의 뒷부분이 위치한 곳의 포인터를 두는 방법\n   - 이름의 나머지 부분은 동일한 directory file의 일부에 존재\n\n# VFS and NFS\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/74b7f77d-938e-42c9-9a20-e7f357e3c886)  \n## 1. Virtual File System(VFS)\n   - 서로 다른 다양한 file system에 대해 동일한 시스템 콜 인터페이스(API)를 통해 접근할 수 있게 해주는 OS의 layer\n\n## 2. Network File System(NFS)\n   - 분산 시스템에서는 네트워크를 통해 파일 공유 가능\n   - NFS는 분산 환경에서의 대표적인 파일 공유 방법\n\n# Page Cache and Buffer Cache\n## Page Cache\n- Virtual memory의 paging system에서 사용하는 page frame을 caching의 관점에서 설명하는 용어\n- Memory-Mapped I/O를 쓰는 경우 file의 I/O에서도 page cache 사용\n\n## Memory-Mapped I/O\n- File의 일부를 virtual memory에 mapping 시킴\n- 매핑시킨 영역에 대한 메모리 접근 연산은 파일의 입출력을 수행하게 함\n\n## Buffer Cache\n- 파일 시스템을 통한 I/O 연산은 OS가 메모리의 특정 영역인 buffer cache 사용\n- File 사용의 locality 활용\n  - 한 번 읽어온 block에 대한 후속 요청 시 buffer cache에서 즉시 전달\n- 모든 프로세스가 공용으로 사용\n- Replacement algorithm 필요(LRU, LFU 등)\n\n## Unified Buffer Cache\n- 최근의 OS에서는 기존의 buffer cache가 page cache에 통합됨\n\n# Page Cache and Buffer Cache\n![image](https://github.com/Haaarimmm/TIL/assets/108309396/05982d51-fb8f-4abd-a1de-a8a226bf1243)![image](https://github.com/Haaarimmm/TIL/assets/108309396/f519f422-8ec7-458f-8cf3-1385c76ee223)\n- read(), write() system call - 반드시 OS를 거쳐 buffer cache에 있으면 바로 전달\n- memory-mapped I/O system call - buffer cache에 읽어온 후 page cache에 copy함\n  - OS 간섭없이 memory 접근을 통해 file 입출력 가능\n- Unified buffer cache 사용 시 경로가 단순해짐\n\n# Program Execution\n- 프로그램 실행 &rarr; File system에 저장된 실행파일을 실행하여 프로세스가 됨 &rarr; 프로세스만의 독자적인 주소 공간이 생성\n- 실행할 부분은 실제 메모리에 올라가고, 나머지는 swap area에 보관됨\n- 하지만 주소공간 중 **code 영역**은 이미 실행파일 형태로 *read-only 형태로 저장*되어 있음\n- 메모리 주소 공간이 만들어질 때 data, stack 영역은 만들어져서 메모리에 올라가고 사용되지 않으면 swap area로 내려감\n- 하지만 code 영역은 이미 실행파일에 들어있기 때문에 page를 삭제해버리고 필요해지면 file system으로부터 이 영역을 불러옴\n- 이는 메모리에 프로세스를 올리는 loader가 쓰는 memory-mapped I/O의 일종: 프로세스의 주소공간 중 code 영역을 실행파일에 mapping\n\n\n# Memory-mapped I/O를 통해 데이터 파일을 사용하는 과정\n- 어떤 프로세스가 데이터 파일을 memory-mapped I/O를 통해 사용하고자 할 때, `mmap()` 시스템 콜을 통해 해당 파일을 자신의 주소공간에 매핑\n- 그럼 실제 메모리 상의 페이지에도 파일에 매핑된 페이지가 존재할 것\n- 이 페이지를 조회하고자 하면 아직 매핑만 된 상태이고 파일이 올라오지 않았으므로 page fault가 발생함\n- 이 때는 swap area에서 page를 불러오는 것이 아니라 file system에 가서 파일의 내용을 메모리에 올려야 함\n\n# Read-Write system call을 통해 읽는 과정\n- 어떤 프로세스가 데이터 파일을 사용하고자 할때, `read()` 시스템콜을 통해 운영체제가 현재 buffer cache(page cache)에 올라와있지 않은 데이터 파일을 buffer cache(page cache)에 등록한다. \n- 그리고 사용자 프로세스 주소공간에 복사하여 사용할 수 있도록 해준다.','Allocation of File Data in Disk 1. Contiguous Allocation   image   단점   external fragmentation  File grow가 어려움  file 생성 시 얼마나 큰 hole을 배당할 것인가?  grow 가능 vs 낭비(internal fragmentation)  장점   Fast I/O  파일의 용량과 관계없이 한 번의 seek/rotation으로 많은 바이트 transfer  realtime file용으로, 또는 이미 run 중이던 process의 swapping용  Direct access(=random access) 가능 2. Linked Allocation   image   장점   external fragmentation X  단점  ','11. File System Implementation'),(_binary '\0','2023-11-15 04:48:47.732306',30,103,NULL,1,'## Disk Structure\n- **logical block**\n  - 디스크의 외부에서 보는 디스크의 단위 정보 저장 공간들\n  - 주소를 가진 1차원 배열처럼 취급\n  - 정보를 전송하는 최소 단위\n- **sector**\n  - 디스크 관리의 최소 단위\n  - logical block이 물리적인 디스크에 매핑된 위치\n  - sector 0은 최외곽 실린더의 첫 트랙에 있는 첫 번째 섹터이다\n\n## Disk Management\n### 1. physical formatting(Low-level formatting)\n- 디스크를 컨트롤러가 읽고 쓸 수 있도록 섹터들로 나누는 과정\n- 각 섹터는 **header + 실제 data(512 bytes) + trailer**로 구성\n- header와 trailer는 sector number, ECC(Error-Correcting Code) 등의 정보가 저장되며 controller가 직접 접근 및 운영\n\n### 2. Partitioning\n- 디스크를 하나 이상의 실린더 그룹으로 나누는 과정\n- OS는 이것을 *독립적 disk*로 취급(logical disk)\n\n### 3. logical formatting\n- 파일 시스템을 만드는 것\n- FAT, inode, free space 등의 구조 포함\n\n### 4. Booting\n- ROM에 있는 small bootstrap loader의 실행\n- sector 0(boot block)을 load하여 실행\n- sector 0은 full Bootstrap loader program\n- OS를 디스크에서 load하여 실행 \n\n# Disk Scheduling\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/5014b1ad-0ab0-4ae4-b207-08abe278d2e2)\n\n- Access time의 구성\n  1. Seek time: 헤드를 해당 실린더로 움직이는데 걸리는 시간\n  2. Rotational latency: 헤드가 원하는 섹터에 도달하기까지 걸리는 회전 지연시간\n  3. Transfer time: 실제 데이터의 전송 시간\n- Disk bandwidth: 단위 시간 당 전송된 바이트의 수\n- Disk Scheduling: seek time을 최소화하는 것이 목표, seek time = seek distance\n\n# Disk Scheduling Algorithm\n### 1. FCFS(First Come First Served)\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/27cf7735-befb-4166-b7ca-7e9624012ae8)\n\n### 2. SSTF(Shortest Seek Time First)\n- starvation 문제 발생  \n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/0bc79153-a87c-4a9d-b90a-cac4de6a073e)\n\n### 3. SCAN  \n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/b63435c4-1819-4a51-8294-6180d013a045)  \n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/4671c4d7-df1f-43ab-84d0-e963c96501c0)\n- disk arm이 디스크의 한 쪽 끝에서 다른 쪽 끝으로 이동$하며 가는 길목에 있는 모든 요청을 처리\n- 다른 쪽 끝에 도달하면 역방향으로 이동하며 똑같이 처리\n- 문제점: 실린더 위치에 따라 대기 시간이 다름\n\n### 4. C-SCAN(Circular SCAN)  \n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/59ab75b3-3a52-4af6-a03c-61eadd188cf8)  \n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/362f6b14-b2ab-40d0-8e25-4b4074285ccb)\n- 헤드가 한쪽 끝에서 다른 쪽 끝으로 이동하며 가는 길목에 있는 모든 요청을 처리\n- 다른 쪽 끝에 도달했으면 요청을 처리하지 않고 곧바로 출발점으로 다시 이동\n- SCAN보다 균일한 대기 시간 제공\n\n### 5. N-SCAN\n- 일단 arm이 한 방향으로 움직이기 시작하면 그 시점 이후에 도착한 job은 되돌아올 때 service\n\n### 6. LOOK and C-LOOK\n- 헤드가 진행 중이다가 그 방향에 더 이상 기다리는 요청이 없으면 헤드의 이동방향을 즉시 반대로 이동  \n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/de016786-455d-4a84-b77d-254fb7d938df)\n\n# Disk-Scheduling Algorithm의 결정\n- SCAN, C-SCAN 및 그 응용 알고리즘은 LOOK, C-LOOK 등이 일반적으로 디스크 입출력이 많은 시스템에서 효율적인 것으로 알려져 있음\n- File의 할당 방법에 따라 디스크 요청이 영향을 받음\n- 디스크 스케줄링 알고리즘은 필요할 경우 다른 알고리즘으로 쉽게 교체할 수 있도록 OS와 별도의 모듈로 작성되는 것이 바람직함\n\n# Swap-Space Management\n- Disk를 사용하는 두 가지 이유\n  1. memory의 volatile한 특성 &rarr; file system\n  2. 프로그램 실행을 위한 memory 공간 부족 &rarr; swap space(swap area)\n- Swap-space\n  - Virtual memory system에서는 디스크를 memory의 연장 공간으로 사용\n  - 파일시스템 내부에 둘 수도 있으나 별도 partition 사용이 일반적\n    - 공간효율성보다는 속도 효율성이 우선\n    - 일반 파일보다 훨씬 짧은 시간만 존재하고 자주 참조됨\n    - 따라서, block의 크기 및 저장 방식이 일반 파일시스템과 다름\n    - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/d53133e6-efab-4b61-bf7a-62ee8eb0585e)\n\n# RAID\n- ![image](https://github.com/Haaarimmm/TIL/assets/108309396/47ee10c1-042b-470a-b97d-0f3ae38e4a26)\n- Redundant Array of Independent Disks: 여러 개의 디스크를 묶어서 사용\n- RAID의 사용 목적\n   1. 디스크 처리 속도 향상 \n      - 여러 디스크에 block의 내용을 분산 저장 &rarr; 동시 액세스 가능\n      - 병렬적으로 읽어 옴(interleaving, striping)\n   2. 신뢰성(reliability) 향상\n      - 동일 정보를 여러 디스크에 중복 저장\n      - 하나의 디스크가 고장 시 다른 디스크에서 읽어옴(Mirroring, shadowing)\n        - Disk mirroring: 디스크에 저장된 데이터들은 짝을 이루고 있는 미러 디스크의 같은 위치에 복사\n      - 단순한 중복 저장이 아니라 일부 디스크에 parity를 저장하여 공간의 효율성을 높일 수 있다\n        - parity bit $p = b1 ⊕ b2 ⊕ b3 ⊕ b4$ \n        - 단점: 쓰기 동작 때마다 parity bit 갱신 필요 &rarr; 시간 지연 발생\n        - ![image](https://github.com/Haaarimmm/TIL/assets/108309396/4ef55884-0be8-4e31-97b3-dfa10aa7d63e)','Disk Structure   logical block  디스크의 외부에서 보는 디스크의 단위 정보 저장 공간들  주소를 가진 1차원 배열처럼 취급  정보를 전송하는 최소 단위  sector  디스크 관리의 최소 단위  logical block이 물리적인 디스크에 매핑된 위치  sector 0은 최외곽 실린더의 첫 트랙에 있는 첫 번째 섹터이다  Disk Management 1. physical formatting(Low-level formatting)   디스크를 컨트롤러가 읽고 쓸 수 있도록 섹터들로 나누는 과정  각 섹터는 header + 실제 data(512 bytes) + trailer로 구성  header와 trailer는 sector number, ECC(Error-Correcting Code)','12. Disk Management and Scheduling'),(_binary '\0','2023-11-16 16:46:47.222282',13,105,'2023-11-15 05:25:04.620698',5,'## ZigLog는 지식 그래프로 효율적으로 문서를 탐색하는 워크 스페이스입니다. \n그래프를 한 번 탐색해볼까요?  \n노트와 폴더를 2D와 3D로 볼 수 있네요.  \n노트와 폴더를 마음대로 움직여 볼 수도 있어요.\n\n글을 한 번 써볼까요?  \n글은 마크다운 에디터로 쓰고 편집을 할 수가 있어요.  \n글 작성과 동시에 오른쪽에서 프리뷰를 볼 수가 있네요.  \n\n글을 쓸 때는 다른 글을 참조할 수 있어요.  \n북마크 한 글 리스트가 쭉 나오고, 클릭 한 번이면 참조를 할 수 있어요.  \n\n내 글은 수정, 삭제 및 공개 설정 변경이 가능하고, 내 글도 북마크를 할 수가 있어요.  \n\n사이드바의 검색창에서 검색을 하면 해당 사용자의 글만 검색이 돼요.  \n글의 맨 아래에서는 이 글을 참조한 노트와 이 글이 참조하는 노트를 확인할 수 있어요.\n\n전체 글 검색은 사이드바의 아이콘을 눌러서 할 수 있어요.  \n다른 사람의 페이지에서는 노트와 폴더 추가 버튼이 보이지 않아요.  \n그래프 아이콘을 누르면 해당 사용자의 그래프를 볼 수 있어요.  \n\n그래프에서 사용자, 폴더, 노트, 참조한 노트는 모두 다른 색으로 표현돼요.  \n\n사이드바는 잠시 접어둘 수도 있어요.  \n\n지그로그는 다크 모드도 지원하고 있어요.  \n사이드바 제일 아래의 버튼 하나만 누르면 다크 모드로 바꿀 수 있어요.  \n\n이렇게 그래프도, 글도 다크 모드로 볼 수 있어요.  ','ZigLog는 지식 그래프로 효율적으로 문서를 탐색하는 워크 스페이스입니다. 그래프를 한 번 탐색해볼까요? 노트와 폴더를 2D와 3D로 볼 수 있네요. 노트와 폴더를 마음대로 움직여 볼 수도 있어요.  글을 한 번 써볼까요? 글은 마크다운 에디터로 쓰고 편집을 할 수가 있어요. 글 작성과 동시에 오른쪽에서 프리뷰를 볼 수가 있네요.  글을 쓸 때는 다른 글을 참조할 수 있어요. 북마크 한 글 리스트가 쭉 나오고, 클릭 한 번이면 참조를 할 수 있어요.  내 글은 수정, 삭제 및 공개 설정 변경이 가능하고, 내 글도 북마크를 할 수가 있어요.  사이드바의 검색창에서 검색을 하면 해당 사용자의 글만 검색이 돼요. 글의 맨 아래에서는 이 글을 참조한 노트와 이 글이 참조하는 노트를 확인할 수 있어요.  전체 글 ','UCC 아이디어'),(_binary '','2023-11-16 02:13:25.716168',35,106,'2023-11-16 00:30:52.863711',6,'## ZigLog\n\n2023.10.09~ (진행중)\n\n📘**지식그래프로 확인하는 문서 툴**\n\n**팀 프로젝트**\n\n- 프론트엔드 4명 / 백엔드 2명\n- 프론트엔드 개발 담당\n\n**프로젝트 결과물**\n\n- url: https://ziglog.site/\n\n**활용한 기술스택**\n\n- `Typescript` `Next.js`   `Cypress` `Storybook` `Redux-toolkit` `TailWind CSS`  `Yarn Berry`  `Three.js` `return-fetch`\n\n**담당 역할**\n\n- 공통 UI 컴포넌트 개발(폴더 탐색, 북마크 등)\n- 폴더 기반 노드 그래프 표현(2D, 3D)\n- 라이트모드/다크모드 구현\n- return-fetch 라이브러리를 활용한 네트워크 요청 모듈화(Next.js 기반 캐시 최적화)\n- 프로젝트 초기 설정 및 디자인 시스템 구축 (eslint, prettier, next.config.js, storybook, tsconfig.json, cypress)\n\n### 메인페이지\n\n- 트리 형태의 폴더 컴포넌트를 구현하여 API 요청과 동기화하였습니다.\n- 2D 그래프 커스텀을 위해 CanvasRenderingContext2D 객체를 조작하였습니다. 또한 3D로 구체를 렌더링 하기위해 Three의 기본옵션을 사용하였습니다.','ZigLog 2023.10.09~ (진행중)  📘지식그래프로 확인하는 문서 툴  팀 프로젝트    프론트엔드 4명 / 백엔드 2명  프론트엔드 개발 담당  프로젝트 결과물    url: https://ziglog.site/  활용한 기술스택    Typescript Next.js   Cypress Storybook Redux-toolkit TailWind CSS  Yarn Berry  Three.js return-fetch  담당 역할    공통 UI 컴포넌트 개발(폴더 탐색, 북마크 등)  폴더 기반 노드 그래프 표현(2D, 3D)  라이트모드/다크모드 구현  return-fetch 라이브러리를 활용한 네트워크 요청 모듈화(Next.js 기반 캐시 최적화)  프로젝트 초기 설정 및 디자인 시스템 구축 (','Ziglog'),(_binary '','2023-11-16 02:13:33.844128',35,107,'2023-11-16 00:30:55.841981',6,'## 베네픽\n\n2023.08.21~2023.10.06 (7주)\n\n💳**위치 기반 카드 추천 서비스**\n\n**삼성 청년SW아카데미 핀테크 트랙 우수상**\n\n**팀 프로젝트**\n\n- 프론트엔드 2명 / 백엔드 4명\n- 프론트엔드 개발 담당\n\n**프로젝트 결과물**\n\n- 깃허브: https://github.com/Benepick/Benepick\n- 시연영상: https://www.youtube.com/watch?v=KMJX3GOS7eo\n- 플레이스토어: https://play.google.com/store/apps/details?id=com.benepick&hl=ko-KR\n\n**활용한 기술스택**\n\n- `Typescript` `React Native` `React-Navigation` `Redux-toolkit`\n\n**담당 역할**\n\n- build.gradle 설정 최적화 및 플레이스토어 배포\n- axios의 인터셉터, 인스턴스를 활용한 네트워크 요청 모듈화\n- Yarn berry를 활용한 개발자 경험 개선\n- 위치기반 추천 페이지(권한 승인을 통한 조회)\n- 혜택 및 소비 내역 페이지(월별 소비 내역 조회, SVG를 활용한 그래프 구현)\n- 챗봇 페이지(답변 내용 기반의 옵션 선택 기능)\n- 혜택 검색 페이지\n\n**챗봇**\n\n\n- 카드의 다양한 혜택 정보를 사용자에게 효과적으로 전달하고자 챗봇 서비스를 도입을 하였습니다.\n\n**메인페이지**\n\n\n- 앱을 실행하는 순간 간편 로그인이 활성화 된다면, 자신의 위치에 따른 카드 추천을 받을 수 있도록 메인 페이지를 구현하였습니다.\n\n**혜택 및 소비 내역 그래프**\n\n\n- 그래프 라이브러리를 활용하는 대신, 세밀한 조정과 특별한 디자인을 위해 SVG를 직접 코드로 생성하였습니다.\n\n**장소 기반 혜택 검색**\n\n\n- 사용자가 장소를 검색할 때, 보유한 카드의 최대 혜택을 추천하며 해당 장소에서 최고 혜택을 제공하는 다른 카드도 함께 제시됩니다.\n\n```\nconst test = 123123\n```','베네픽 2023.08.21~2023.10.06 (7주)  💳위치 기반 카드 추천 서비스  삼성 청년SW아카데미 핀테크 트랙 우수상  팀 프로젝트    프론트엔드 2명 / 백엔드 4명  프론트엔드 개발 담당  프로젝트 결과물    깃허브: https://github.com/Benepick/Benepick  시연영상: https://www.youtube.com/watch?v=KMJX3GOS7eo  플레이스토어: https://play.google.com/store/apps/details?id=com.benepick&hl=ko-KR  활용한 기술스택    Typescript React Native React-Navigation Redux-toolkit  담당 역할    build.gradle 설정 최적화 및 플','베네픽'),(_binary '','2023-11-15 06:46:23.063690',13,108,'2023-11-15 06:45:57.048360',5,'안녕하세여  \n[리락쿠마 : 리락쿠마](https://ziglog.site/user-page/리락쿠마/read-note/108)','안녕하세여 리락쿠마 : 리락쿠마','리락쿠마'),(_binary '','2023-11-15 07:44:09.069808',37,109,'2023-11-15 07:42:05.064135',10,'### 나는 글길이 테스트를 좋아합니다.\n\n- 테스트1\n  - 테스트111111111111111111111111111111111111111111111111111111111111111111111\n- 테스트2\n  - 테스트 2ㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴ### 나는 글길이 테스트를 좋아합니다.\n아합니다.\n\n','나는 글길이 테스트를 좋아합니다.   테스트1  테스트111111111111111111111111111111111111111111111111111111111111111111111  테스트2  테스트 2ㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴㄴ### 나는 글길이 테스트를 좋아합니다. 아합니다. ','글 제목 LENGTH TEST 글 제목 LENGTH TES 글 제목 LENGTH TEST'),(_binary '\0','2023-11-16 02:14:43.686289',2,110,NULL,2,'<!-- aasdasd -->','','asdasd'),(_binary '','2023-11-16 02:13:45.255303',35,112,'2023-11-16 00:30:58.042295',6,'## 입찰왕\n\n2023.07.04~2023.08.18 (7주)\n\n🪙**쉽고 재미있는 라이브 경매 플랫폼, 입찰왕**\n\n**삼성 청년SW아카데미 웹기술 트랙 우수상**\n\n**팀 프로젝트**\n\n- 프론트엔드 2명 / 백엔드 4명\n- 프론트엔드 개발 담당\n\n**프로젝트 결과물**\n\n- 깃허브: https://github.com/bid-king/bidking\n- 시연영상: https://www.youtube.com/watch?v=iyUf4gSRbaA\n\n**활용한 기술스택**\n\n- `Typescript` `React, Redux-toolkit` `Emotion`  `Yarn berry`  `Storybook` `React-query`\n\n**담당 역할**\n\n- 메인페이지 및 Scroll event 수신 시 쓰로틀링을 이용한 API 요청으로 무한 스크롤 경매방 탐색 기능\n- Openvidu를 활용한 판매자 실시간 화면 송출 기능(1:N)\n- Socket.io를 활용한 경매방 구매자간의 채팅 기능\n- SSE를 활용한 알림 수신 기능 및 알림 내역 조회 기능\n- 토큰 기반의 회원 인증 및 갱신 기능(Access Token, Refresh Token 활용)\n- 경매방 생성, 수정, 삭제 기능\n- 판매자와 구매자를 구분하는 다크모드와 라이트모드 기능\n\n**경매진행 페이지**\n\n- 판매자는 Openvidu로 상품을 실시간 송출하고, 구매자는 동시에 이를 시청하여 다수와 함께 경매에 참여합니다.\n- 판매자와 구매자 간의 실시간 채팅을 지원하며, 판매자는 채팅방 참여자의 닉네임을 확인할 수 있습니다.\n\n**메인페이지 (구매자 페이지)**\n\n- 메인페이지의 경매 목록 탐색에 카테고리 및 무한 스크롤링 기능을 도입하였습니다.\n\n**Atomic 디자인 기반의 컴포넌트와 Storybook 사용**\n\n- 각 컴포넌트의 사용법과 속성을 명확하게 해, 팀원들이 컴포넌트를 쉽게 이해하고 사용할 수 있도록 하였습니다.\n\n**Yarn Berry 도입 및 최적화**\n\n- 의존성 설치 시간을 40% 줄이고, 빌드 속도를 20% 향상하였습니다. CI 과정의 속도 개선으로 인해, 배포 과정이 빠르게 진행되어 신속한 서비스 제공이 가능해졌습니다.\n- Yarn Berry의 Zero Install 기능을 도입하면서 프로젝트 실행 및 관리 효율성이 향상되었습니다.','입찰왕 2023.07.04~2023.08.18 (7주)  🪙쉽고 재미있는 라이브 경매 플랫폼, 입찰왕  삼성 청년SW아카데미 웹기술 트랙 우수상  팀 프로젝트    프론트엔드 2명 / 백엔드 4명  프론트엔드 개발 담당  프로젝트 결과물    깃허브: https://github.com/bid-king/bidking  시연영상: https://www.youtube.com/watch?v=iyUf4gSRbaA  활용한 기술스택    Typescript React, Redux-toolkit Emotion  Yarn berry  Storybook React-query  담당 역할    메인페이지 및 Scroll event 수신 시 쓰로틀링을 이용한 API 요청으로 무한 스크롤 경매방 탐색 기능  Openvidu를 ','입찰왕'),(_binary '','2023-11-16 00:27:46.667644',35,113,'2023-11-16 00:30:51.082663',6,'## MOVIE101\n\n2023.05.17~2023.05.25 (2주)\n\n🎞️**나만의 영화취향 분석으로 위한 월드컵 챌린지**\n\n**팀 프로젝트**\n\n- 프론트엔드 1명 / 백엔드 1명\n- 프론트엔드 개발 담당\n\n**프로젝트 결과물**\n\n- 깃허브: https://github.com/yongseong2/movie101_final_pjt\n\n**활용한 기술스택**\n\n- `Vue.js`  `Vuex`\n\n**담당 역할**\n\n- 영화 월드컵 페이지\n- 영화 추천 및 검색 페이지\n- 커뮤니티 게시판 페이지\n- 회원가입 페이지\n- 반응형 웹으로 구성\n\n**영화 검색 및 추천 서비스와 회원 관리**\n\n- 사용자가 영화 제목으로 검색하면 동적으로 영화 포스터와 함께 검색 결과를 제공하였습니다.\n\n- 사용자의 선호를 반영하여 랜덤 영화 추천, 마음에 드는 영화 및 배우 기반의 추천 기능을 구현하였습니다.\n- 회원 관리 시스템을 통해 회원가입, 로그인, 로그아웃 기능을 구현하였고, 비회원에 대한 서비스 제한 기능을 추가하였습니다.','MOVIE101 2023.05.17~2023.05.25 (2주)  🎞️나만의 영화취향 분석으로 위한 월드컵 챌린지  팀 프로젝트    프론트엔드 1명 / 백엔드 1명  프론트엔드 개발 담당  프로젝트 결과물    깃허브: https://github.com/yongseong2/movie101_final_pjt  활용한 기술스택    Vue.js  Vuex  담당 역할    영화 월드컵 페이지  영화 추천 및 검색 페이지  커뮤니티 게시판 페이지  회원가입 페이지  반응형 웹으로 구성  영화 검색 및 추천 서비스와 회원 관리    사용자가 영화 제목으로 검색하면 동적으로 영화 포스터와 함께 검색 결과를 제공하였습니다.   사용자의 선호를 반영하여 랜덤 영화 추천, 마음에 드는 영화 및 배우 기반의 추천 기능을','MOVIE 101'),(_binary '','2023-11-16 00:32:30.552132',39,115,'2023-11-16 00:36:50.183149',6,'# Ziglog\n\n<img src=\"./asset/image/ziglog.png\" width=\"100%\" height=\"400px\"/>\n\n## 📖목차\n\n- [Ziglog](#ziglog)\n  - [📖목차](#목차)\n  - [프로젝트 진행 기간](#프로젝트-진행-기간)\n  - [❤ 팀 소개](#-팀-소개)\n    - [팀명](#팀명)\n    - [팀원 소개](#팀원-소개)\n  - [🎉 프로젝트 요약](#-프로젝트-요약)\n  - [✨주요 기능 및 구현](#주요-기능-및-구현)\n  - [🖥 서비스 화면](#-서비스-화면)\n  - [🏗️ 아키텍쳐](#️-아키텍쳐)\n  - [🛠 기술 스택](#-기술-스택)\n  - [� Communication Tool](#-communication-tool)\n  - [⚙️ SKILL STACK](#️-skill-stack)\n    - [🧷 프론트엔드](#-프론트엔드)\n    - [🧷 백엔드](#-백엔드)\n    - [🧷 인프라](#-인프라)\n  - [📂 파일 구조](#-파일-구조)\n  - [📝 설계 문서](#-설계-문서)\n    - [ERD](#erd)\n    - [API](#api)\n    - [FIGMA](#figma)\n  - [📚 컨벤션](#-컨벤션)\n    - [Ground Rule](#ground-rule)\n  - [🥇 프로젝트 수칙](#-프로젝트-수칙)\n    - [💻 회의 진행](#-회의-진행)\n    - [💻 코드 리뷰](#-코드-리뷰)\n    - [💻 코드 작성](#-코드-작성)\n    - [💻 깃 관리](#-깃-관리)\n    - [Git Commit](#git-commit)\n    - [Git Branch](#git-branch)\n- [브랜치 명명 컨벤션](#브랜치-명명-컨벤션)\n  - [Git flow](#git-flow)\n    - [Codding](#codding)\n    - [Jira](#jira)\n  - [💻 구동 방법](#-구동-방법)\n  - [💾 결과물](#-결과물)\n    - [UCC](#ucc)\n    - [시연 영상](#시연-영상)\n\n---\n\n## 프로젝트 진행 기간\n\n`2023.10.10 ~ 2023.11.17 (약 7주)`\n\n---\n\n## ❤ 팀 소개\n\n### 팀명\n\n> 📢 안녕하세요! 지식그래프\n\n### 팀원 소개\n\n|                           Backend                            |                           Backend                            |                           Frontend                           |                          Frontend                           |                          Frontend                           |                          Frontend                           |\n| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :---------------------------------------------------------: | :---------------------------------------------------------: | :---------------------------------------------------------: |\n| <img src=\"./asset/image/임수형.png\" width=400px alt=\"수형\"/> | <img src=\"./asset/image/박영서.png\" width=400px alt=\"영서\"/> | <img src=\"./asset/image/김성용.gif\" width=400px alt=\"성용\"/> | <img src=\"./asset/image/김하늘.jpg\" width=400px alt=\"하늘\"> | <img src=\"./asset/image/이정민.jpg\" width=400px alt=\"정민\"> | <img src=\"./asset/image/정현아.jpg\" width=400px alt=\"현아\"> |\n|          [임수형(팀장)](https://github.com/sulogc)           |           [박영서](https://github.com/Frog-Slayer)           |           [김성용](https://github.com/yongseong2)            |           [김하늘](https://github.com/hanulkimm)            |            [이정민](https://github.com/hyuna333)            |            [정현아](https://github.com/hhyeona)             |\n\n---\n\n## 🎉 프로젝트 요약\n\n💡 **프로젝트 명**: Ziglog\n\n**목적**: 지식그래프를 활용한 마크다운 노트 필기 웹 서비스\n\n**기대효과**:\n\n- 쉬운 마크다운 문법을 이요한 지식 정리\n- 참조 관계를 활용한 효율적인 지식 관리\n- 폴더 관계를 활용한 효율적인 노트 관리\n\n  **차별점**:\n\n- 노\\* : 폴더관계가 명확하지 않고 그래프를 이용한 탐색기능이 없음\n- 옵시\\*언 : 로컬 서비스이고 다른 사용자의 노트를 확인할 수 없음\n\n  => Ziglog: 웹 + 그래프 서비스를 제공\n\n---\n\n## ✨주요 기능 및 구현\n\n💡 **로그인 및 회원가입**:\n\n1.  소셜 로그인(Kakao, Google)\n\n💡 **그래프 탐색**:\n\n1.  노트 기반 2D, 3D\n2.  폴더 기반 2D, 3D\n\n💡 **폴더 탐색기**:\n\n1.  폴더와 노트를 탐색하는 사이드바\n\n💡 **검색**:\n\n1. 공개 설정이 적용된 전체 노트 검색\n2. 사용자의 내 노트 탐색\n\n💡 **노트 생성 및 수정**:\n\n1.  실시간 마크다운 문법을 변환해주는 에디터 제공\n2.  해당 노트를 참조하고 있는 노트를 북마크에서 선택할 수 있는 기능\n\n💡 **노트 읽기**:\n\n1.  마크다운을 파싱한 화면 제공\n\n💡 **라이트모드/다크모드**:\n\n1.  사용자의 눈을 보호하기 위한 밝기 변환 기능 제공\n\n💡 **알림**:\n\n1.  타사용자가 내 글을 참조하거나, 북마크를 할 때 알림 기능 제공\n\n💡 **개인정보 수정**:\n\n1.  사용자의 프로필 이미지, 닉네임을 수정하는 기능 제공\n\n---\n\n## 🖥 서비스 화면\n\n<summary>메인 페이지</summary>\n<div markdown=\"1\">\n<!-- <img src=\"./readme-asset/image/gif/휴대폰인증.gif\" width=\"200px\" /> -->\n</div>\n\n<summary>개인 페이지</summary>\n<div markdown=\"1\">\n\n</div>\n\n<summary>검색 페이지</summary>\n<div markdown=\"1\">\n\n</div>\n\n---\n\n## 🏗️ 아키텍쳐\n\n<!-- <img alt=\"Group 8\" src=\"./readme-asset/image/아키텍쳐.png\" /> -->\n\n---\n\n## 🛠 기술 스택\n\n## 💻 Communication Tool\n\n<img src=\"https://img.shields.io/badge/Github-181717?style=flat&logo=Github&logoColor=#181717\"/> <img src=\"https://img.shields.io/badge/Notion-000000?style=flat&logo=Notion&logoColor=#000000\"/> <img src=\"https://img.shields.io/badge/Mattermost-0058CC?style=flat&logo=mattermost&logoColor=#0058CC\"/> <img src=\"https://img.shields.io/badge/GitLab-FC6D26?style=flat&logo=gitlab&logoColor=#FC6D26\"/> <img src=\"https://img.shields.io/badge/Figma-F24E1E?style=flat&logo=Figma&logoColor=white\"/> <img src=\"https://img.shields.io/badge/Jira-0052CC?style=flat&logo=Jira&logoColor=white\"/>\n\n<br><br>\n\n## ⚙️ SKILL STACK\n\n### 🧷 프론트엔드\n\n<img src=\"https://img.shields.io/badge/typescript-3178C6?style=flat&logo=typescript&logoColor=white\"/> <img src=\"https://img.shields.io/badge/Next.js-000000?style=flat&logo=next.js&logoColor=white\"> <img src=\"https://img.shields.io/badge/Node.js-339933?style=flat&logo=node.js&logoColor=white\"/> <img src=\"https://img.shields.io/badge/Yarn-2C8EBB?style=flat&logo=Yarn&logoColor=white\"/> <img src=\"https://img.shields.io/badge/tailwind css-06B6D4?style=flat&logo=tailwindcss&logoColor=white\"/> <img src=\"https://img.shields.io/badge/Storybook-FF4785?style=flat&logo=Redux&logoColor=white\"/> <img src=\"https://img.shields.io/badge/Google Analytics-E37400?style=flat&logo=googleanalytics&logoColor=white\"/>\n\n**Language |** Typescript\n\n**Framework |** Next.js\n\n**Engine |** Node.js\n\n**Package Manager |** Yarn Berry\n\n**Library |** Redux Toolkit, Tailwind CSS, Storybook, [return-fetch](https://return-fetch.myeongjae.kim/?ref=blog.deering.co), [react-md-editor](https://github.com/uiwjs/react-md-editor), [react-force-graph](https://github.com/vasturiano/react-force-graph)\n\n<br><br>\n\n### 🧷 백엔드\n\n<img src=\"https://img.shields.io/badge/Spring-6DB33F?style=flat&logo=Spring&logoColor=white\"/> <img src=\"https://img.shields.io/badge/Spring Boot-6DB33F?style=flat&logo=SpringBoot&logoColor=white\"/> <img src=\"https://img.shields.io/badge/Spring Security-6DB33F?style=flat&logo=Spring&logoColor=white\"/> <img src=\"https://img.shields.io/badge/MySQL-4479A1?style=flat&logo=MySQL&logoColor=white\"/> <img src=\"https://img.shields.io/badge/gradle-02303A?style=flat&logo=gradle&logoColor=white\"/> <img src=\"https://img.shields.io/badge/redis-DC382D?style=flat&logo=redis&logoColor=white\"/>\n\n**Language |** Java 17\n\n**Framework |** Spring Boot 2.7\n\n**Data(RDBMS) |** Spring-Data-JPA 2.7.14, MySQL 8.0, Query DSL 5.0\n\n**Cache |** Redis 2.7.14\n\n**Build Tool |** Gradle 8.3\n\n**Test |** Junit 5.8.2, Mockito 4.5.1, JaCoCo 0.8.10\n<br><br>\n\n### 🧷 인프라\n\n<img src=\"https://img.shields.io/badge/ubuntu-E95420?style=flat&logo=ubuntu&logoColor=white\"/> <img src=\"https://img.shields.io/badge/Jenkins-D24939?style=flat&logo=jenkins&logoColor=white\"/> <img src=\"https://img.shields.io/badge/Amazon EC2-FF9900?style=flat&logo=amazonec2&logoColor=white\"/> <img src=\"https://img.shields.io/badge/nginx-009639?style=flat&logo=nginx&logoColor=white\"/> <img src=\"https://img.shields.io/badge/amazons3-569A31?style=flat&logo=amazons3&logoColor=white\"/> <img src=\"https://img.shields.io/badge/docker-2496ED?style=flat&logo=docker&logoColor=white\"/> <img src=\"https://img.shields.io/badge/sonarqube-4E9BCD?style=flat&logo=sonarqube&logoColor=white\"/>\n\n**Infra |** AWS EC2, Nginx, Sonarqube\n\n**DB |** H2, MySQL 8\n\n**CI/CD |** Git, Jenkins\n\n<br><br>\n\n---\n\n## 📂 파일 구조\n\n<details  style=\"margin-left: 5px;\">\n<summary><b>프론트 프로젝트 구조</b></summary>\n<div>\n\n```\n📦app\n ┣ 📂(pages)\n ┃ ┣ 📂oauth\n ┃ ┣ 📂search\n ┃ ┗ 📂user-page\n ┃   ┗ 📂[userNickname]\n ┃     ┣ 📂edit-note\n ┃     ┃ ┗ 📂[noteId]\n ┃     ┗ 📂read-note\n ┃       ┗ 📂[noteId]\n ┣ 📂api\n ┃ ┣ 📂bookmark\n ┃ ┣ 📂folder\n ┃ ┣ 📂graph\n ┃ ┣ 📂note\n ┃ ┣ 📂notification\n ┃ ┣ 📂quote\n ┃ ┣ 📂search\n ┃ ┗ 📂user\n ┣ 📂components\n ┃ ┣ 📂common\n ┃ ┣ 📂main\n ┃ ┣ 📂search\n ┃ ┗ 📂userPage\n ┃   ┣ 📂Notification\n ┃   ┣ 📂QuotationModal\n ┃   ┣ 📂Search\n ┃   ┗ 📂SideBar\n ┃     ┗  📂Directory\n ┣ 📂src\n ┃ ┣ 📂design\n ┃ ┣ 📂fonts\n ┃ ┣ 📂hooks\n ┃ ┗ 📂util\n ┣ 📂store\n ┗  ┗  📂modules\n\n```\n\n</div>\n</details>\n<br>\n<details  style=\"margin-left: 5px;\">\n<summary><b>백엔드 프로젝트 구조</b></summary>\n<div>\n\n```\n📦benepick\n ┣ 📂domain\n ┃ ┣ 📂card\n ┃ ┃ ┣ 📂controller\n ┃ ┃ ┣ 📂dto\n ┃ ┃ ┃ ┣ 📂request\n ┃ ┃ ┃ ┗ 📂response\n ┃ ┃ ┣ 📂repository\n ┃ ┃ ┗ 📂service\n ┃ ┣ 📂mydata\n ┃ ┃ ┣ 📂controller\n ┃ ┃ ┣ 📂dto\n ┃ ┃ ┃ ┣ 📂request\n ┃ ┃ ┃ ┗ 📂response\n ┃ ┃ ┗ 📂service\n ┃ ┗ 📂user\n ┃ ┃ ┣ 📂controller\n ┃ ┃ ┣ 📂dto\n ┃ ┃ ┃ ┣ 📂request\n ┃ ┃ ┃ ┗ 📂response\n ┃ ┃ ┣ 📂entity\n ┃ ┃ ┣ 📂repository\n ┃ ┃ ┗ 📂service\n ┣ 📂global\n ┃ ┣ 📂api\n ┃ ┃ ┣ 📂dto\n ┃ ┃ ┃ ┣ 📂request\n ┃ ┃ ┃ ┗ 📂response\n ┃ ┃ ┗ 📂service\n ┃ ┣ 📂config\n ┃ ┣ 📂exception\n ┃ ┣ 📂interceptor\n ┃ ┣ 📂log\n ┃ ┃ ┣ 📂annotation\n ┃ ┃ ┣ 📂logTrace\n ┃ ┣ 📂response\n ┃ ┗ 📂util\n ┗ 📜BenepickApplication.java\n```\n\n</div>\n</details>\n\n---\n\n## 📝 설계 문서\n\n### ERD\n\n<details>\n<summary>ERD</summary>\n<div markdown=\"1\">       \n    <img src=\"./readme-asset/image/erd.png\" alt=\"ERD 페이지\"/>\n</div>\n</details>\n\n### API\n\n<details>\n<summary>전체 문서</summary>\n<div markdown=\"1\">       \n    <img src=\"./readme-asset/api명세서.png\" alt=\"전체 문서 페이지\"/>\n</div>\n</details>\n\n<details>\n<summary>Request</summary>\n<div markdown=\"1\">       \n    <img src=\"./readme-asset/requestImg.png\" alt=\"전체 문서 페이지\"/>\n</div>\n</details>\n\n<details>\n<summary>Response</summary>\n<div markdown=\"1\">       \n    <img src=\"./readme-asset/responseImge.png\" alt=\"전체 문서 페이지\"/>\n</div>\n</details>\n\n### FIGMA\n\n<details>\n<summary>WIREFRAME</summary>\n<div markdown=\"1\">       \n    <img src=\"./readme-asset/wireFrame.png\" alt=\"전체 문서 페이지\"/>\n</div>\n</details>\n\n---\n\n## 📚 컨벤션\n\n### Ground Rule\n\n<details>\n  <summary>클릭하여 내용 표시/숨기기</summary>\n\n> GROUND RULE\n\n## 🥇 프로젝트 수칙\n\n### 💻 회의 진행\n\n1. 매일 오전 9시, 오후 5시 2회에 걸쳐 **데일리 스크럼(Daily Scrum)**을 진행해, 개인별 당일 목표를 설정하고 진행 상황을 공유합니다.\n2. 매주 금요일 오후 5시에 **스프린트 세션(Sprint Session)**을 진행해 일주일간 프로젝트의 진행 상황 및 추후 진행 목표를 설정합니다.\n3. 데일리 스크럼과 스프린트 세션은 팀장이 회의를 주재하고, 다른 팀원들이 돌아가며 회의록을 작성합니다.\n4. 회의에 적극적으로 참여하고, 팀장의 지목에 따라 본인의 의견을 반드시 제시합니다.\n\n### 💻 코드 리뷰\n\n1. **코드 리뷰(Code Review)**는 점심시간을 활용해 필요한 부분만 간단히 30분 동안 진행합니다.\n2. 서로 다른 코드 스타일을 합의한 **코딩 컨벤션(Coding Convention)**에 따라 일원화합니다.\n3. 코드 리뷰는 우선순위에 따라 빠르게 진행하며, 사소한 의견을 반영할 지에 대한 부분은 코드 작성자가 선택할 수 있도록 합니다.\n\n### 💻 코드 작성\n\n1. 에러(Error)가 발생 시 1시간 정도는 혼자서 고민해보고, 해결이 되지 않을 경우 팀원들과 바로 공유합니다.\n2. 에러를 해결하기 위해 고민한 내용 및 해결 과정은 노션에 정리하여 공유합니다.\n3. 코드에 **주석(Comment)을 작성**하는 습관을 생활화하여, 다른 팀원들이 내가 작성한 코드를 이해하기 쉽도록 합니다.\n4. 기능의 구현 원리를 공부하고 파악하기 위해서 오픈 소스(Open Source) 라이브러리 사용을 최소화하는 것을 원칙으로 합니다.\n\n### 💻 깃 관리\n\n1. 풀리퀘스트(Pull Request)가 있을 경우, 이를 확인했다는 의미에서 최소한 1개 이상의 의견을 남겨야 합니다.\n2. 풀리퀘스트 시 의견 갈등이 생겼다면, 충분한 토론과 의견 수렴 과정을 거쳐 **다수의 의견**을 따라야 합니다.\n3. 커밋(Commit)하기 전에 고칠 부분을 한 번 더 점검합니다.\n4. 1가지 기능 또는 1가지 함수를 새로 만들 때마다 커밋하는 습관을 생활화합니다.\n5. **커밋 메시지(Commit Message)**는 합의한 **커밋 컨벤션(Commit Convention)**에 따라 최대한 상세하게 작성합니다.\n6. 깃 브랜치(Branch) 규칙에 따라 브랜치를 관리하고, 모든 작업은 올바른 브랜치에서 작업해야 합니다.\n\n</details>\n\n### Git Commit\n\n<details>\n  <summary>클릭하여 내용 표시/숨기기</summary>\n    \n> COMMIT CONVENTION\n>\n\n- **Commit 메세지 구조**\n  - ex) ✨ feat : Add sign in page #S09P11A308-52\n\n```\n<emoji> <type> : <subject> <Jira ticket number> // 필수\n// 빈 행으로 구분\n<body>      // 생략가능\n// 빈 행으로 구분\n<footer>    // 생략가능\n```\n\n</details>\n\n### Git Branch\n\n<details>\n  <summary>클릭하여 내용 표시/숨기기</summary>\n\n# 브랜치 명명 컨벤션\n\n> BRANCH NAMING CONVENTION\n\n## Git flow\n\n- ex) **feat/{이슈 키}-{BE/FE}-{이슈 요약}**\n\n- **master** / **main** - 제품으로 출시 및 배포가 가능한 상태인 브랜치 → 최종 결과물 제출 용도\n- **develop** - 다음 출시 버전을 개발하는 브랜치 → 기능 완성 후 중간에 취합하는 용도\n- **feature** - 각종 기능을 개발하는 브랜치 → feat/login, feat/join 등으로 기능 분류 후 작업\n- **hotfix** - 출시 버전에서 발생한 버그를 수정하는 브랜치\n\n</details>\n\n### Codding\n\n<details>\n  <summary>클릭하여 내용 표시/숨기기</summary>\n\n> CODING CONVENTION\n\n- 1문자의 이름은 사용하지 않는다.\n- 네임스페이스, 오브젝트, 함수 그리고 인스턴스에는 camelCase를 사용한다 `ex) camelCase`\n- 클래스나 constructor에는 PascalCase를 사용한다. `ex) PascalCase`\n- 약어 및 이니셜은 항상 모두 대문자이거나 모두 소문자여야 한다. `ex) NFT`\n- 클래스명과 변수명은 `명사 사용`\n- 메서드명은 `동사 사용`\n- 상수명은 대문자를 사용하고, 단어와 단어 사이는 \\_로 연결한다.\n- component는 PascalCase를 사용한다.\n\n</details>\n\n### Jira\n\n<details>\n  <summary>클릭하여 내용 표시/숨기기</summary>\n\n> JIRA CONVENTION\n\n1. 매주 월요일 오전 스크럼 회의 이후 각자의 이슈 티켓을 생성한다.\n2. 이슈 생성 시 확인해야 할 부분\n   - **\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***담당자가 본인**\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***으로 설정되어 있는지\n   - **컴포넌트**가 지정되어 있는지 (FE, BE, 공통 중 택1)\n   - **Epic Link**가 지정되어 있는지 (설계, FE개발, BE개발, 회의, 학습…)\n   - 스프린트의 **총 Story Points가 40 이상**인지\n3. 이슈 티켓 이름은 **\\*\\***\\*\\***\\*\\***[말머리] 구체적인 기능**\\*\\***\\*\\***\\*\\*** 으로 적는다.\n   - \\***\\*\\*\\*\\*\\*\\*\\***\\*\\*\\*\\*\\***\\*\\*\\*\\*\\*\\*\\***기능 관련 이슈일 경우 **\\*\\***\\*\\***\\*\\***[말머리]**\\*\\***\\*\\***\\*\\***는 기능 명세서의 대분류를 따른다.\n4. 매일 오전 스크럼 회의 이후 그 날 처리할 이슈 티켓을 **진행 중**으로 이동시킨다.\n   - 실시간으로 이슈를 처리할 때마다 **완료** 처리한다.\n\n</details>\n\n## 💻 구동 방법\n\n[포팅메뉴얼 참조](./exec/포팅매뉴얼_A610.pdf)\n\n---\n\n## 💾 결과물\n\n### UCC\n\nhttps://youtu.be/ohmziXA1uHU\n\n### 시연 영상\n\nhttps://youtu.be/KMJX3GOS7eo\n','Ziglog   📖목차   Ziglog  📖목차  프로젝트 진행 기간  ❤ 팀 소개   팀명  팀원 소개  🎉 프로젝트 요약  ✨주요 기능 및 구현  🖥 서비스 화면  🏗️ 아키텍쳐  🛠 기술 스택  � Communication Tool  ⚙️ SKILL STACK   🧷 프론트엔드  🧷 백엔드  🧷 인프라  📂 파일 구조  📝 설계 문서   ERD  API  FIGMA  📚 컨벤션   Ground Rule  🥇 프로젝트 수칙   💻 회의 진행  💻 코드 리뷰  💻 코드 작성  💻 깃 관리  Git Commit  Git Branch  브랜치 명명 컨벤션  Git flow   Codding  Jira  💻 구동 방법  💾 결과물   UCC  시연 영상   프로젝트 진행 기간 ','Ziglog README.md'),(_binary '','2023-11-16 00:34:22.402260',39,116,'2023-11-16 00:36:45.446364',6,'# Benepick\n\n<img src=\"./readme-asset/image/logo.png\" width=\"100%\" height=\"400px\"/>\n\n## 📖목차\n\n- [Benepick](#benepick)\n  - [📖목차](#목차)\n  - [프로젝트 진행 기간](#프로젝트-진행-기간)\n  - [❤ 팀 소개](#-팀-소개)\n    - [팀명](#팀명)\n    - [팀원 소개](#팀원-소개)\n    - [Frontend](#frontend)\n    - [Backend](#backend)\n  - [🎉 프로젝트 요약](#-프로젝트-요약)\n  - [✨주요 기능 및 구현](#주요-기능-및-구현)\n  - [🖥 서비스 화면](#-서비스-화면)\n  - [🏗️ 아키텍쳐](#️-아키텍쳐)\n  - [🛠 기술 스택](#-기술-스택)\n  - [📂 파일 구조](#-파일-구조)\n  - [📝 설계 문서](#-설계-문서)\n    - [ERD](#erd)\n    - [API](#api)\n    - [FIGMA](#figma)\n  - [📚 컨벤션](#-컨벤션)\n    - [Ground Rule](#ground-rule)\n  - [🥇 프로젝트 수칙](#-프로젝트-수칙)\n    - [💻 회의 진행](#-회의-진행)\n    - [💻 코드 리뷰](#-코드-리뷰)\n    - [💻 코드 작성](#-코드-작성)\n    - [💻 깃 관리](#-깃-관리)\n    - [Git Commit](#git-commit)\n    - [Git Branch](#git-branch)\n- [브랜치 명명 컨벤션](#브랜치-명명-컨벤션)\n  - [Git flow](#git-flow)\n    - [Codding](#codding)\n    - [Jira](#jira)\n  - [💻 구동 방법](#-구동-방법)\n  - [💾 결과물](#-결과물)\n    - [UCC](#ucc)\n    - [시연 영상](#시연-영상)\n\n---\n\n## 프로젝트 진행 기간\n\n`2023.08.21 ~ 2023.10.06 (약 7주)`\n\n---\n\n## ❤ 팀 소개\n\n<img src=\"./readme-asset/image/profile/team.jpg\" width=\"300px\" height=\"300px\" />\n\n### 팀명\n\n> 📢 안녕하세요! 핀테크 주제로 프로젝트를 진행한 팀《현실에서는 신용불량자였던 내가 이세계에선 최강의 카드 혜택 마에스트로?》입니다.\n\n### 팀원 소개\n\n### Frontend\n\n|                                                                                                     |                                                                                                 |\n| :-------------------------------------------------------------------------------------------------: | :---------------------------------------------------------------------------------------------: |\n| <img src=\"./readme-asset/image/profile/seongYong.gif\" width=\"200px\" height=\"200px\" /><br>**김성용** | <img src=\"./readme-asset/image/profile/ikgun.gif\" width=\"200px\" height=\"200px\" /><br>**진익근** |\n\n---\n\n### Backend\n\n|                                                                                                     |                                                                                                  |                                                                                                     |                                                                                                  |\n| :-------------------------------------------------------------------------------------------------: | :----------------------------------------------------------------------------------------------: | :-------------------------------------------------------------------------------------------------: | :----------------------------------------------------------------------------------------------: |\n| <img src=\"./readme-asset/image/profile/dongGyeom.gif\" width=\"200px\" height=\"200px\" /><br>**김동겸** | <img src=\"./readme-asset/image/profile/siGgun.gif\" width=\"200px\" height=\"200px\" /><br>**박시균** | <img src=\"./readme-asset/image/profile/hyeonChul.gif\" width=\"200px\" height=\"200px\" /><br>**박현철** | <img src=\"./readme-asset/image/profile/hyeJin.gif\" width=\"200px\" height=\"200px\" /><br>**임혜진** |\n\n---\n\n## 🎉 프로젝트 요약\n\n💡 **프로젝트 명**: 베네픽\n\n**목적**: 보유 카드를 효율적으로 사용하여 혜택을 극대화하고, 더 좋은 카드를 추천 받을 수 있는 서비스\n\n**기대효과**:\n\n- 보유 카드 실적을 효과적으로 관리할 수 있다.\n- 카드를 효율적으로 사용하여 최대 혜택을 받을 수 있다.\n- 더 좋은 카드를 추천 받을 수 있다.  \n  **차별점**:\n- 위치 기반 결제 전 혜택 정보 확인(방향에 따른 사업장 선택)\n\n---\n\n## ✨주요 기능 및 구현\n\n💡 **계정**:\n\n1.  휴대폰 인증 (본인인증)\n\n💡 **마이데이터(더미데이터)**:\n\n1.  더미데이터 생성\n    1. 사용자\n    2. 카드\n    3. 소비내역\n2.  연동 카드사 선택\n\n💡 **소비 습관**:\n\n1.  카테고리 별 소비내역 조회\n    1. 기간 별 소비내역\n    2. 카테고리 별 소비내역\n    3. 통계 그래프\n\n💡 **내 카드**:\n\n1.  실적 모아보기\n2.  혜택 조회\n    1. 받은 혜택 금액\n    2. 받을 수 있는 혜택 금액\n3.  소비내역 조회\n\n💡 **검색(추천)**:\n\n1.  위치 기반 추천\n    1. 위치별 사업장 조회\n    2. 제스처 기능을 통한 빠른 추천 알림 → 실사용성 고려\n2.  혜택 기반 추천(챗봇)\n    1. 가맹점에 따른 사용 카드 추천 (내 카드, 신규 카드)\n    2. 소비패턴에 따른 신규 카드 추천\n\n💡 **결제 테스트**:\n\n1.  시연을 위한 결제 데이터 추가\n\n---\n\n## 🖥 서비스 화면\n\n<summary>메인 페이지</summary>\n<div markdown=\"1\">\n<img src=\"./readme-asset/image/gif/메인페이지.gif\" width=\"200px\" />\n<img src=\"./readme-asset/image/gif/쉑픽.gif\" width=\"200px\" />\n</div>\n\n<summary>회원가입 페이지</summary>\n<div markdown=\"1\">\n<img src=\"./readme-asset/image/gif/개인정보처리방침.gif\" width=\"200px\" />\n<img src=\"./readme-asset/image/gif/회원정보입력.gif\" width=\"200px\" />\n<img src=\"./readme-asset/image/gif/휴대폰인증.gif\" width=\"200px\" />\n</div>\n\n<summary>혜택찾기</summary>\n<div markdown=\"1\">\n<img src=\"./readme-asset/image/gif/혜택상세보기.gif\" width=\"200px\" />\n</div>\n\n<summary>내 카드 페이지</summary>\n\n<div markdown=\"1\">\n<img src=\"./readme-asset/image/gif/내카드모아보기.gif\" width=\"200px\" />\n<img src=\"./readme-asset/image/gif/카드상세보기.gif\" width=\"200px\" />\n</div>\n\n<summary>내 소비 페이지</summary>\n\n<div markdown=\"1\">\n<img src=\"./readme-asset/image/gif/소비혜택그래프.gif\" width=\"200px\" />\n</div>\n\n<summary>챗봇페이지</summary>\n<div markdown=\"1\">\n<img src=\"./readme-asset/image/gif/챗봇.gif\" width=\"200px\" />\n</div>\n\n<summary>알람 페이지</summary>\n\n<div markdown=\"1\">\n<img src=\"./readme-asset/image/gif/알람내역.gif\" width=\"200px\" />\n</div>\n\n---\n\n## 🏗️ 아키텍쳐\n\n<img alt=\"Group 8\" src=\"./readme-asset/image/아키텍쳐.png\" />\n\n---\n\n## 🛠 기술 스택\n\n<div align=center>\n<!-- 백엔드 -->\n<img src=\"https://img.shields.io/badge/-Java-007396?style=flat-square&logo=java&logoColor=white\">\n<img src=\"https://img.shields.io/badge/-SpringBoot-6DB33F?style=flat-square&logo=spring&logoColor=white\">\n<img src=\"https://img.shields.io/badge/-JPA-FFCA28?style=flat-square&logo=java&logoColor=white\">\n<!-- 데이터베이스 -->\n<img src=\"https://img.shields.io/badge/-MySQL-4479A1?style=flat-square&logo=mysql&logoColor=white\">\n<img src=\"https://img.shields.io/badge/-Redis-DC382D?style=flat-square&logo=redis&logoColor=white\">\n<img src=\"https://img.shields.io/badge/-Pinecone-606060?style=flat-square\"> \n<!-- 프론트엔드 -->\n<img src=\"https://img.shields.io/badge/-React_Native-61DAFB?style=flat-square&logo=react&logoColor=white\">\n<img src=\"https://img.shields.io/badge/-TypeScript-3178C6?style=flat-square&logo=typescript&logoColor=white\">\n<img src=\"https://img.shields.io/badge/-React_Navigation-61DAFB?style=flat-square&logo=react&logoColor=white\">\n<img src=\"https://img.shields.io/badge/-Redux-764ABC?style=flat-square&logo=redux&logoColor=white\">\n<!-- 인프라 -->\n<img src=\"https://img.shields.io/badge/-Docker-2496ED?style=flat-square&logo=docker&logoColor=white\">\n<img src=\"https://img.shields.io/badge/-Jenkins-D24939?style=flat-square&logo=jenkins&logoColor=white\">\n<img src=\"https://img.shields.io/badge/-Prometheus-E6522C?style=flat-square&logo=prometheus&logoColor=white\">\n<img src=\"https://img.shields.io/badge/-Grafana-F46800?style=flat-square&logo=grafana&logoColor=white\">\n<img src=\"https://img.shields.io/badge/-nGrinder-8E24AA?style=flat-square\"> \n<img src=\"https://img.shields.io/badge/-nginx-009639?style=flat-square&logo=nginx&logoColor=white\">\n</div>\n\n---\n\n## 📂 파일 구조\n\n<details  style=\"margin-left: 5px;\">\n<summary><b>프론트 프로젝트 구조</b></summary>\n<div>\n\n```\n📦src\n ┣ 📂api\n ┣ 📂common\n ┃ ┣ 📂assets\n ┃ ┃ ┣ 📂fonts\n ┃ ┃ ┣ 📂icons\n ┃ ┃ ┣ 📂images\n ┃ ┃ ┃ ┣ 📂logo\n ┃ ┣ 📂components\n ┃ ┃ ┣ 📂progress\n ┃ ┃ ┃ ┣ 📂childs\n ┃ ┣ 📂design\n ┃ ┗ 📂utils\n ┣ 📂hooks\n ┣ 📂interfaces\n ┣ 📂navigator\n ┃ ┣ 📂stacks\n ┣ 📂pages\n ┃ ┣ 📂auth\n ┃ ┃ ┣ 📂Login\n ┃ ┃ ┣ 📂PersonalAuth\n ┃ ┃ ┣ 📂PhoneAuth\n ┃ ┃ ┃ ┣ 📂Components\n ┃ ┃ ┣ 📂ReadTerms\n ┃ ┃ ┣ 📂RegistrationComplete\n ┃ ┃ ┣ 📂SelectCard\n ┃ ┃ ┣ 📂SelectCompany\n ┃ ┃ ┣ 📂SetPassword\n ┃ ┃ ┣ 📂Start\n ┃ ┃ ┗ 📂Terms\n ┃ ┣ 📂Loading\n ┃ ┣ 📂main\n ┃ ┃ ┣ 📂Benefit\n ┃ ┃ ┃ ┣ 📂Container\n ┃ ┃ ┣ 📂ChatBot\n ┃ ┃ ┃ ┣ 📂Container\n ┃ ┃ ┣ 📂Consumption\n ┃ ┃ ┃ ┣ 📂Container\n ┃ ┃ ┃ ┃ ┣ 📂ConsumptionHistory\n ┃ ┃ ┃ ┃ ┣ 📂MonthlyBenefit\n ┃ ┃ ┣ 📂CreditCard\n ┃ ┃ ┃ ┣ 📂Container\n ┃ ┃ ┃ ┃ ┣ 📂progress\n ┃ ┃ ┃ ┃ ┃ ┣ 📂childs\n ┃ ┃ ┣ 📂CreditCardDetail\n ┃ ┃ ┃ ┣ 📂Container\n ┃ ┃ ┃ ┃ ┣ 📂CardConsumption\n ┃ ┃ ┃ ┃ ┣ 📂DateOption\n ┃ ┃ ┗ 📂Home\n ┃ ┃ ┃ ┣ 📂Container\n ┃ ┣ 📂Notification\n ┃ ┃ ┣ 📂Container\n ┃ ┣ 📂setting\n ┃ ┃ ┣ 📂ChangePassword\n ┃ ┃ ┣ 📂CheckPassword\n ┃ ┃ ┣ 📂CompanyConnection\n ┃ ┃ ┃ ┣ 📂Container\n ┃ ┃ ┗ 📂Setting\n ┃ ┃ ┃ ┣ 📂Container\n ┣ 📂store\n ┃ ┣ 📂slices\n ┗ 📜README.md\n```\n\n</div>\n</details>\n<br>\n<details  style=\"margin-left: 5px;\">\n<summary><b>백엔드 프로젝트 구조</b></summary>\n<div>\n\n```\n📦benepick\n ┣ 📂domain\n ┃ ┣ 📂card\n ┃ ┃ ┣ 📂controller\n ┃ ┃ ┣ 📂dto\n ┃ ┃ ┃ ┣ 📂request\n ┃ ┃ ┃ ┗ 📂response\n ┃ ┃ ┣ 📂repository\n ┃ ┃ ┗ 📂service\n ┃ ┣ 📂mydata\n ┃ ┃ ┣ 📂controller\n ┃ ┃ ┣ 📂dto\n ┃ ┃ ┃ ┣ 📂request\n ┃ ┃ ┃ ┗ 📂response\n ┃ ┃ ┗ 📂service\n ┃ ┗ 📂user\n ┃ ┃ ┣ 📂controller\n ┃ ┃ ┣ 📂dto\n ┃ ┃ ┃ ┣ 📂request\n ┃ ┃ ┃ ┗ 📂response\n ┃ ┃ ┣ 📂entity\n ┃ ┃ ┣ 📂repository\n ┃ ┃ ┗ 📂service\n ┣ 📂global\n ┃ ┣ 📂api\n ┃ ┃ ┣ 📂dto\n ┃ ┃ ┃ ┣ 📂request\n ┃ ┃ ┃ ┗ 📂response\n ┃ ┃ ┗ 📂service\n ┃ ┣ 📂config\n ┃ ┣ 📂exception\n ┃ ┣ 📂interceptor\n ┃ ┣ 📂log\n ┃ ┃ ┣ 📂annotation\n ┃ ┃ ┣ 📂logTrace\n ┃ ┣ 📂response\n ┃ ┗ 📂util\n ┗ 📜BenepickApplication.java\n```\n\n</div>\n</details>\n\n---\n\n## 📝 설계 문서\n\n### ERD\n\n<details>\n<summary>ERD</summary>\n<div markdown=\"1\">       \n    <img src=\"./readme-asset/image/erd.png\" alt=\"ERD 페이지\"/>\n</div>\n</details>\n\n### API\n\n<details>\n<summary>전체 문서</summary>\n<div markdown=\"1\">       \n    <img src=\"./readme-asset/api명세서.png\" alt=\"전체 문서 페이지\"/>\n</div>\n</details>\n\n<details>\n<summary>Request</summary>\n<div markdown=\"1\">       \n    <img src=\"./readme-asset/requestImg.png\" alt=\"전체 문서 페이지\"/>\n</div>\n</details>\n\n<details>\n<summary>Response</summary>\n<div markdown=\"1\">       \n    <img src=\"./readme-asset/responseImge.png\" alt=\"전체 문서 페이지\"/>\n</div>\n</details>\n\n### FIGMA\n\n<details>\n<summary>WIREFRAME</summary>\n<div markdown=\"1\">       \n    <img src=\"./readme-asset/wireFrame.png\" alt=\"전체 문서 페이지\"/>\n</div>\n</details>\n\n---\n\n## 📚 컨벤션\n\n### Ground Rule\n\n<details>\n  <summary>클릭하여 내용 표시/숨기기</summary>\n\n> GROUND RULE\n\n## 🥇 프로젝트 수칙\n\n### 💻 회의 진행\n\n1. 매일 오전 9시, 오후 5시 2회에 걸쳐 **데일리 스크럼(Daily Scrum)**을 진행해, 개인별 당일 목표를 설정하고 진행 상황을 공유합니다.\n2. 매주 금요일 오후 5시에 **스프린트 세션(Sprint Session)**을 진행해 일주일간 프로젝트의 진행 상황 및 추후 진행 목표를 설정합니다.\n3. 데일리 스크럼과 스프린트 세션은 팀장이 회의를 주재하고, 다른 팀원들이 돌아가며 회의록을 작성합니다.\n4. 회의에 적극적으로 참여하고, 팀장의 지목에 따라 본인의 의견을 반드시 제시합니다.\n\n### 💻 코드 리뷰\n\n1. **코드 리뷰(Code Review)**는 점심시간을 활용해 필요한 부분만 간단히 30분 동안 진행합니다.\n2. 서로 다른 코드 스타일을 합의한 **코딩 컨벤션(Coding Convention)**에 따라 일원화합니다.\n3. 코드 리뷰는 우선순위에 따라 빠르게 진행하며, 사소한 의견을 반영할 지에 대한 부분은 코드 작성자가 선택할 수 있도록 합니다.\n\n### 💻 코드 작성\n\n1. 에러(Error)가 발생 시 1시간 정도는 혼자서 고민해보고, 해결이 되지 않을 경우 팀원들과 바로 공유합니다.\n2. 에러를 해결하기 위해 고민한 내용 및 해결 과정은 노션에 정리하여 공유합니다.\n3. 코드에 **주석(Comment)을 작성**하는 습관을 생활화하여, 다른 팀원들이 내가 작성한 코드를 이해하기 쉽도록 합니다.\n4. 기능의 구현 원리를 공부하고 파악하기 위해서 오픈 소스(Open Source) 라이브러리 사용을 최소화하는 것을 원칙으로 합니다.\n\n### 💻 깃 관리\n\n1. 풀리퀘스트(Pull Request)가 있을 경우, 이를 확인했다는 의미에서 최소한 1개 이상의 의견을 남겨야 합니다.\n2. 풀리퀘스트 시 의견 갈등이 생겼다면, 충분한 토론과 의견 수렴 과정을 거쳐 **다수의 의견**을 따라야 합니다.\n3. 커밋(Commit)하기 전에 고칠 부분을 한 번 더 점검합니다.\n4. 1가지 기능 또는 1가지 함수를 새로 만들 때마다 커밋하는 습관을 생활화합니다.\n5. **커밋 메시지(Commit Message)**는 합의한 **커밋 컨벤션(Commit Convention)**에 따라 최대한 상세하게 작성합니다.\n6. 깃 브랜치(Branch) 규칙에 따라 브랜치를 관리하고, 모든 작업은 올바른 브랜치에서 작업해야 합니다.\n\n</details>\n\n### Git Commit\n\n<details>\n  <summary>클릭하여 내용 표시/숨기기</summary>\n    \n> COMMIT CONVENTION\n>\n\n- **Commit 메세지 구조**\n  - ex) ✨ feat : Add sign in page #S09P11A308-52\n\n```\n<emoji> <type> : <subject> <Jira ticket number> // 필수\n// 빈 행으로 구분\n<body>      // 생략가능\n// 빈 행으로 구분\n<footer>    // 생략가능\n```\n\n</details>\n\n### Git Branch\n\n<details>\n  <summary>클릭하여 내용 표시/숨기기</summary>\n\n# 브랜치 명명 컨벤션\n\n> BRANCH NAMING CONVENTION\n\n## Git flow\n\n- ex) **feat/{이슈 키}-{BE/FE}-{이슈 요약}**\n\n- **master** / **main** - 제품으로 출시 및 배포가 가능한 상태인 브랜치 → 최종 결과물 제출 용도\n- **develop** - 다음 출시 버전을 개발하는 브랜치 → 기능 완성 후 중간에 취합하는 용도\n- **feature** - 각종 기능을 개발하는 브랜치 → feat/login, feat/join 등으로 기능 분류 후 작업\n- **hotfix** - 출시 버전에서 발생한 버그를 수정하는 브랜치\n\n</details>\n\n### Codding\n\n<details>\n  <summary>클릭하여 내용 표시/숨기기</summary>\n\n> CODING CONVENTION\n\n- 1문자의 이름은 사용하지 않는다.\n- 네임스페이스, 오브젝트, 함수 그리고 인스턴스에는 camelCase를 사용한다 `ex) camelCase`\n- 클래스나 constructor에는 PascalCase를 사용한다. `ex) PascalCase`\n- 약어 및 이니셜은 항상 모두 대문자이거나 모두 소문자여야 한다. `ex) NFT`\n- 클래스명과 변수명은 `명사 사용`\n- 메서드명은 `동사 사용`\n- 상수명은 대문자를 사용하고, 단어와 단어 사이는 \\_로 연결한다.\n- component는 PascalCase를 사용한다.\n\n</details>\n\n### Jira\n\n<details>\n  <summary>클릭하여 내용 표시/숨기기</summary>\n\n> JIRA CONVENTION\n\n1. 매주 월요일 오전 스크럼 회의 이후 각자의 이슈 티켓을 생성한다.\n2. 이슈 생성 시 확인해야 할 부분\n   - **\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***담당자가 본인**\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***\\*\\*\\*\\***으로 설정되어 있는지\n   - **컴포넌트**가 지정되어 있는지 (FE, BE, 공통 중 택1)\n   - **Epic Link**가 지정되어 있는지 (설계, FE개발, BE개발, 회의, 학습…)\n   - 스프린트의 **총 Story Points가 40 이상**인지\n3. 이슈 티켓 이름은 **\\*\\***\\*\\***\\*\\***[말머리] 구체적인 기능**\\*\\***\\*\\***\\*\\*** 으로 적는다.\n   - \\***\\*\\*\\*\\*\\*\\*\\***\\*\\*\\*\\*\\***\\*\\*\\*\\*\\*\\*\\***기능 관련 이슈일 경우 **\\*\\***\\*\\***\\*\\***[말머리]**\\*\\***\\*\\***\\*\\***는 기능 명세서의 대분류를 따른다.\n4. 매일 오전 스크럼 회의 이후 그 날 처리할 이슈 티켓을 **진행 중**으로 이동시킨다.\n   - 실시간으로 이슈를 처리할 때마다 **완료** 처리한다.\n\n</details>\n\n<!-- ## 📄 문서 정리\n\n### 회의록\n\n<details>\n<summary>페이지 전체 모습</summary>\n<div markdown=\"1\">\n    <img     src=\"https://hackmd.io/_uploads/rk5Okmoh2.png\" alt=\"전체 페이지\"/>\n    <img     src=\"https://hackmd.io/_uploads/HJ9hyXsn2.png\" alt=\"전체 페이지\"/>\n    <img     src=\"https://hackmd.io/_uploads/BJi01mj3n.png\" alt=\"전체 페이지\"/>\n</div>\n</details>\n\n<details>\n<summary>기획 회의록 페이지 세부 모습</summary>\n<div markdown=\"1\">\n    <img     src=\"https://hackmd.io/_uploads/HJoie7j33.png\" alt=\"기획 회의록 페이지 세부 모습\"/>\n</div>\n</details>\n<details>\n<summary>스크럼 페이지 세부 모습</summary>\n<div markdown=\"1\">\n    <img     src=\"https://hackmd.io/_uploads/HyWDZmi3n.png\" alt=\"스크럼 페이지 세부 모습\"/>\n</div>\n</details>\n<details>\n<summary>스프린트 페이지 세부 모습</summary>\n<div markdown=\"1\">\n    <img     src=\"https://hackmd.io/_uploads/S1QCW7j32.png\" alt=\"스프린트 페이지 세부 모습\"/>\n</div>\n</details>\n\n### 버그 리포트\n<details>\n<summary>페이지 전체 모습</summary>\n<div markdown=\"1\">\n    <img     src=\"https://hackmd.io/_uploads/ryAtAzi3n.png\" alt=\"전체 페이지\"/>\n</div>\n</details>\n<details>\n<summary>세부 페이지 모습</summary>\n<div markdown=\"1\">\n    <img src=\"https://hackmd.io/_uploads/HkY1y7sh3.png\" alt=\"전체 페이지\"/>\n</div>\n</details>\n\n### 지식 공유\n\n<details>\n<summary>페이지 전체 모습</summary>\n<div markdown=\"1\">\n    <img     src=\"https://hackmd.io/_uploads/BkMa3Gs3h.png    \" alt=\"전체 페이지\"/>\n</div>\n</details>\n<details>\n<summary>세부 페이지 모습</summary>\n<div markdown=\"1\">\n    <img     src=\"https://hackmd.io/_uploads/Hyfgpzs3n.png\" alt=\"전체 페이지\"/>\n</div>\n</details>\n\n--- -->\n\n## 💻 구동 방법\n\n[포팅메뉴얼 참조](./exec/포팅매뉴얼_A610.pdf)\n\n---\n\n## 💾 결과물\n\n### UCC\n\nhttps://youtu.be/ohmziXA1uHU\n\n### 시연 영상\n\nhttps://youtu.be/KMJX3GOS7eo','Benepick   📖목차   Benepick  📖목차  프로젝트 진행 기간  ❤ 팀 소개   팀명  팀원 소개  Frontend  Backend  🎉 프로젝트 요약  ✨주요 기능 및 구현  🖥 서비스 화면  🏗️ 아키텍쳐  🛠 기술 스택  📂 파일 구조  📝 설계 문서   ERD  API  FIGMA  📚 컨벤션   Ground Rule  🥇 프로젝트 수칙   💻 회의 진행  💻 코드 리뷰  💻 코드 작성  💻 깃 관리  Git Commit  Git Branch  브랜치 명명 컨벤션  Git flow   Codding  Jira  💻 구동 방법  💾 결과물   UCC  시연 영상   프로젝트 진행 기간 2023.08.21 ~ 2023.10.06 (약 7주)   ❤ 팀 소개   ','Benepick README.md'),(_binary '','2023-11-16 00:35:10.536666',39,117,'2023-11-16 00:36:46.960747',6,'# 입찰왕(Bid King)\n\n실시간 경매 라이브 플랫폼\n---\n\n## 팀 멤버\n\n<table>\n  <tr>\n    <td align=\"center\">\n      <a href=\"https://github.com/brewcoldblue\">\n        <img src=\"./docs/images/profile/승윤.png\" width=\"100px;\" height=\"100px\" alt=\"\"/><br />\n        <sub><b>유승윤</b></sub><br />\n        <sub>Frontend</sub>\n      </a>\n    </td>\n    <td align=\"center\">\n      <a href=\"https://github.com/yongseong2\">\n        <img src=\"./docs/images/profile/성용.png\" width=\"100px;\" height=\"100px\" alt=\"\"/><br />\n        <sub><b>김성용</b></sub><br />\n        <sub>Frontend</sub>\n      </a>\n    </td><td align=\"center\">\n      <a href=\"https://github.com/DJ-archive\">\n        <img src=\"./docs/images/profile/다정.jpg\" width=\"100px;\" height=\"100px\" alt=\"\"/><br />\n        <sub><b>윤다정</b></sub><br />\n        <sub>Backend</sub>\n      </a>\n    </td><td align=\"center\">\n      <a href=\"https://github.com/jeong-yeji\">\n        <img src=\"./docs/images/profile/예지.png\" width=\"100px;\" height=\"100px\" alt=\"\"/><br />\n        <sub><b>정예지</b></sub><br />\n        <sub>Backend</sub>\n    	</a>\n    </td><td align=\"center\">\n      <a href=\"https://github.com/DHKIM-0511\">\n        <img src=\"./docs/images/profile/동현.png\" width=\"100px;\" height=\"100px\" alt=\"\"/><br />\n        <sub><b>김동현</b></sub><br />\n        <sub>Backend</sub>\n    	</a>\n    </td><td align=\"center\">\n      <a href=\"https://github.com/yyanoos\">\n        <img src=\"./docs/images/profile/연우.png\" width=\"100px;\" height=\"100px\" alt=\"\"/><br />\n        <sub><b>이연우</b></sub><br />\n        <sub>Backend</sub>\n 	   </a>\n    </td>\n  </tr>\n</table>\n\n## 서비스 화면\n[경매 진행 파트 유튜브 영상](https://www.youtube.com/watch?v=iyUf4gSRbaA)\n\n\n\n## 시스템 아키텍쳐\n\n![시스템 아키텍쳐](./docs/images/system_architecture.png)\n\n---\n\n## 기술 스택\n\n![기술 스택](./docs/images/dev_tools.png)\n\n---\n\n## ERD\n\n![ERD](./docs/images/erd.png)\n\n---\n\n## WIREFRAME\n\n![ERD](./docs/images/wireframe.png)\n\n[와이어프레임 PDF 파일 보기](./docs/wireframe.pdf)\n\n---\n\n## Convention\n\n1. Frontend\n\n   Airbnb JavaScript Style Guide를 기반으로 커스텀함\n\n1. [Backend](./docs/convention/BidkingStyle.xml)\n\n   Google Java Style Guide를 기반으로 커스텀함\n\n1. [Git Commit Rule](./docs/convention/git_convention.md)\n\n1. [Git Branch Strategy](./docs/convention/git_branch.md)\n\n---\n\n## 포팅 매뉴얼\n\n- [사용 버전](./docs/manual/version.md)\n\n- [포팅 매뉴얼](./docs/manual/porting_manual.md)\n\n---\n\n## 발표\n\n- [1차 발표](./docs/presentation/230714_presentation.pdf)\n- [2차 발표](./docs/presentation/230728_presentation.pdf)\n- [최종 발표](./docs/presentation/230818_presentation.pdf)\n','입찰왕(Bid King) 실시간 경매 라이브 플랫폼 팀 멤버  서비스 화면 경매 진행 파트 유튜브 영상  시스템 아키텍쳐 시스템 아키텍쳐   기술 스택 기술 스택   ERD ERD   WIREFRAME ERD  와이어프레임 PDF 파일 보기   Convention   Frontend  Airbnb JavaScript Style Guide를 기반으로 커스텀함    Backend  Google Java Style Guide를 기반으로 커스텀함    Git Commit Rule   Git Branch Strategy   포팅 매뉴얼   사용 버전   포팅 매뉴얼   발표   1차 발표  2차 발표  최종 발표','Bidking README.md'),(_binary '','2023-11-16 00:35:53.723314',39,118,'2023-11-16 00:36:48.200959',6,'# 포트폴리오 웹사이트\n\n## 프로젝트 정보\n\n- URL: https://yongseong2.github.io/portfolio/\n- 기술스택: React, Typescript, Emotion CSS, React Router, Firebase\n\n## 프로젝트 소개\n\n- 이 웹사이트는 제 개인 포트폴리오를 담고 있습니다. 프로젝트, 스킬셋, 프로젝트 등을 볼 수 있습니다.\n\n- 반응형 웹으로 구성되어있습니다.\n\n## 와이어프레임\n\n![와이어프레임](https://yongseong2.github.io/portfolio/Image/portfolioWireframe.png)\n\n## 설치 및 실행 방법\n\n로컬에서 실행하려면 다음과 같이 해주세요.\n\n## 필요한 도구\n\n- Node.js\n- npm\n\n## 설치 및 실행\n\n```bash\n# 저장소 클론\ngit clone https://github.com/yongseong2/portfolio.git\n\n# 디렉토리 이동\ncd portfolio\n\n# 의존성 설치\nnpm install\n# 또는\nyarn install\n\n# 프로젝트 실행\nnpm start\n# 또는\nyarn start\n\n```\n\n## 기능\n\n- 메인페이지: 자기소개와 상세 소개 글\n- 스킬셋: 주로 사용하는 기술 스택과 능력\n- 프로젝트: 진행한 프로젝트에 대한 설명\n- 프로젝스 상세 모달: 마크다운을 활용한 프로젝트 디테일 표시\n- 조회수: 포트폴리오 방문자수 표시\n- Contact: 연락처, 이메일, 이름 정보\n\n## 개발 과정\n\n- React와 Typescript를 사용하여 컴포넌트 기반의 SPA(Single Page Application) 구조로 개발\n- Emotion CSS를 사용하여 스타일링\n- React Router를 사용하여 라우팅 구현\n- React Scroll를 사용하여 페이지 구분\n- Firebase를 활용하여 데이터베이스를 생성 및 조회수 구현\n- react-markdown을 활용하여 markdown 렌더링 구현\n\n---\n\n작성자: yongseong2(김성용)\n최종 업데이트: 2023-10-25\n','포트폴리오 웹사이트 프로젝트 정보   URL: https://yongseong2.github.io/portfolio/  기술스택: React, Typescript, Emotion CSS, React Router, Firebase  프로젝트 소개   이 웹사이트는 제 개인 포트폴리오를 담고 있습니다. 프로젝트, 스킬셋, 프로젝트 등을 볼 수 있습니다.   반응형 웹으로 구성되어있습니다.  와이어프레임 와이어프레임  설치 및 실행 방법 로컬에서 실행하려면 다음과 같이 해주세요.  필요한 도구   Node.js  npm  설치 및 실행 # 저장소 클론 git clone https://github.com/yongseong2/portfolio.git  # 디렉토리 이동 cd portfolio  # 의존성 설치 npm','Portfolio README.md'),(_binary '','2023-11-16 12:23:46.030508',40,120,'2023-11-16 02:00:50.120111',6,'# JSX란?\n\n---\n\n- JSX는 JavaScript XML의 약자로, React에서 사용되는 자바스크립트의 확장 문법입니다. JSX는 JavaScript 코드 안에 XML과 비슷한 구문을 작성하여 UI 컴포넌트를 표현할 수 있게 해줍니다.\n- JSX는 React에서 UI를 렌더링하기 위해 사용되며, 리액트 컴포넌트의 구조와 모습을 정의하는데에 널리 사용됩니다. JSX는 JavaScript의 일부이기 때문에 브라우저에서 바로 실행될 수 있으며, 일반적인 HTML과 유사한 모습을 가지고 있습니다.\n- JSX는 일반적인 자바스크립트 코드 내에서 HTML 태그와 속성을 사용하여 컴포넌트를 정의할 수 있게 해줍니다. JSX를 사용하면 컴포넌트의 구조와 레이아웃을 더 직관적이고 가독성 좋게 작성할 수 있습니다.\n\n예를 들어, 다음은 JSX를 사용하여 \"Hello, World!\"를 출력하는 간단한 React 컴포넌트의 예시입니다:\n\n```jsx\nimport React from \'react\';\n\nfunction HelloWorld() {\n  return <h1>Hello, World!</h1>;\n}\n\nexport default HelloWorld;\n\n```\n\n위의 코드에서 **`<h1>Hello, World!</h1>`** 부분이 JSX로 작성된 부분입니다. JSX 안에서는 HTML 태그를 사용할 수 있으며, 자바스크립트 표현식을 중괄호 **`{}`**로 감싸서 동적인 값을 삽입할 수도 있습니다.\n\nJSX는 React 컴포넌트의 구조와 기능을 표현하는 강력한 도구이며, React 생태계에서 널리 사용되고 있습니다.\n\n### 문법\n\n- class 넣을때 `className`\n- 변수 꽂을 땐 `{ 변수명 }`\n- style 넣을 땐 `style={{ 이름: ‘값’ }}`','JSX란?    JSX는 JavaScript XML의 약자로, React에서 사용되는 자바스크립트의 확장 문법입니다. JSX는 JavaScript 코드 안에 XML과 비슷한 구문을 작성하여 UI 컴포넌트를 표현할 수 있게 해줍니다.  JSX는 React에서 UI를 렌더링하기 위해 사용되며, 리액트 컴포넌트의 구조와 모습을 정의하는데에 널리 사용됩니다. JSX는 JavaScript의 일부이기 때문에 브라우저에서 바로 실행될 수 있으며, 일반적인 HTML과 유사한 모습을 가지고 있습니다.  JSX는 일반적인 자바스크립트 코드 내에서 HTML 태그와 속성을 사용하여 컴포넌트를 정의할 수 있게 해줍니다. JSX를 사용하면 컴포넌트의 구조와 레이아웃을 더 직관적이고 가독성 좋게 작성할 수 있습니다.  예를 들어, 다','1. JSX 기초문법'),(_binary '','2023-11-16 02:11:34.899284',40,121,'2023-11-16 00:37:54.418890',6,'### React에서 event를 사용하는 방법\n\n---\n\n1. 이벤트 핸들러 함수 생성: 이벤트를 처리하기 위해 함수를 생성합니다. 함수는 이벤트가 발생했을 때 실행됩니다.\n\n```jsx\n\nfunction handleClick() {\n  // 이벤트 핸들러 함수 내부에서 처리할 작업을 작성합니다.\n}\n```\n\n1. 이벤트 핸들러 함수 연결: 이벤트를 처리할 요소에 핸들러 함수를 연결합니다. 주로 JSX에서 **`onClick`**, **`onChange`** 등의 속성을 사용하여 연결합니다.\n\n```jsx\n\n<button onClick={handleClick}>Click me!</button>\n<input onChange={handleInputChange} />\n\n```\n\n1. state 변경하기: state 변수를 변경시에는 직접적으로 변경하지 않습니다.\n\n```jsx\n\nlet[따봉, set따봉] = useState(0) ;\n\n  function like() {\n    set따봉( 따봉 += 1 )\n  }\n\n```\n\n1. Array를 변경할 때에는 얕은 복사를 활용합니다\n\n```jsx\nlet [글제목들, set글제목들] = useState([\'남자코트 추천\', \'강남 우동 맛집\', \'리액트 기초 배우기\']\n\n  function changeName() {\n    let copy = [...글제목들] //얕은 복사\n    copy[0] = \'여자코트 추천\'\n    set글제목들(\n      copy\n    )\n  }\n```\n\n### 실습\n\n```jsx\n<div className=\'list\'>\n        <h4>{ 글제목들[0] } <span onClick={ like }>🍬</span> { 따봉 } </h4>\n        <p>2월 14일 발행</p>\n </div>\n```\n\n```jsx\nfunction like() {\n    set따봉( 따봉 += 1 )\n  }\n```','React에서 event를 사용하는 방법    이벤트 핸들러 함수 생성: 이벤트를 처리하기 위해 함수를 생성합니다. 함수는 이벤트가 발생했을 때 실행됩니다.   function handleClick() {   // 이벤트 핸들러 함수 내부에서 처리할 작업을 작성합니다. }    이벤트 핸들러 함수 연결: 이벤트를 처리할 요소에 핸들러 함수를 연결합니다. 주로 JSX에서 onClick, onChange 등의 속성을 사용하여 연결합니다.   <button onClick={handleClick}>Click me!</button> <input onChange={handleInputChange} />     state 변경하기: state 변수를 변경시에는 직접적으로 변경하지 않습니다.   let[따봉, set따봉]','2. array, object state 변경하는 법'),(_binary '','2023-11-16 02:32:52.906517',40,122,'2023-11-16 02:00:52.925683',6,'### 복잡한 html을 한 단어로 치환할 수 있는 Component 문법\n\n- 리액트는 긴 HTML을 한 단어로 깔끔하게 치환해서 넣을 수 있는 문법을 제공합니다. Component라고 합니다.\n\n### Component 만들 때 주의점\n\n1. component 작명할 땐 영어대문자로 보통 작명합니다.\n2. return () 안엔 html 태그들이 평행하게 여러개 들어갈 수 없습니다.\n3. function App(){} 내부에서 만들면 안됩니다.\n\n왜냐면 function App(){} 이것도 다시보니 컴포넌트 생성문법이죠?\n\ncomponent 안에 component 를 만들진 않습니다.\n\n1. <컴포넌트></컴포넌트> 이렇게 써도 되고 <컴포넌트/> 이렇게 써도 됩니다.\n\n### 어떤 HTML들을 Component 만드는게 좋을까\n\n기준은 없습니다만 관습적으로 어떤 부분을 주로 Component화 하냐면\n\n- 사이트에 반복해서 출현하는 HTML 덩어리들은 Component로 만들면 좋습니다.\n- 내용이 매우 자주 변경될 것 같은 HTML 부분을 잘라서 Component로 만들면 좋습니다.\n- 다른 페이지를 만들고 싶다면 그 페이지의 HTML 내용을 하나의 Component로 만드는게 좋습니다.\n- 또는 다른 팀원과 협업할 때 웹페이지를 Component 단위로 나눠서 작업을 분배하기도 합니다.\n\n### Component의 단점\n\n일단 HTML 깔끔하게 쓰려고 Component를 수백개 만들면 그것 만으로도 관리가 힘듭니다.\n\n예를 들어서 function Modal 안에서 글제목 state를 쓰고싶어서 {글제목} 이렇게 쓰면 잘 안되는데\n\n왜냐면 당연히 자바스크립트에선\n\n한 function 안에 있는 변수를 다른 function에서 맘대로 쓸 수 없어서 그렇습니다.\n\nprops라는 문법을 이용해 state를 <Modal>까지 전해줘야 비로소 사용가능합니다.','복잡한 html을 한 단어로 치환할 수 있는 Component 문법   리액트는 긴 HTML을 한 단어로 깔끔하게 치환해서 넣을 수 있는 문법을 제공합니다. Component라고 합니다.  Component 만들 때 주의점   component 작명할 땐 영어대문자로 보통 작명합니다.  return () 안엔 html 태그들이 평행하게 여러개 들어갈 수 없습니다.  function App(){} 내부에서 만들면 안됩니다.  왜냐면 function App(){} 이것도 다시보니 컴포넌트 생성문법이죠?  component 안에 component 를 만들진 않습니다.    <컴포넌트></컴포넌트> 이렇게 써도 되고 <컴포넌트/> 이렇게 써도 됩니다.  어떤 HTML들을 Component 만드는게 좋을까 기준은 없','3. Component'),(_binary '','2023-11-16 02:11:16.943393',40,123,'2023-11-16 02:00:54.451642',6,'### **리액트에서 동적인 UI 만드는 step**\n\n---\n\n1.  **html css로 미리 UI 디자인을 다 해놓고**\n\n```jsx\nfunction Modal() {\n  return (\n    <div className=\'modal\'>\n      <h4>제목</h4>\n      <p>날짜</p>\n      <p>상세내용</p>\n    </div>\n  )\n}\n```\n\n1.  **UI의 현재 상태를 state로 저장해두고**\n\n```jsx\nlet [modal, setModal] = useState(false)\n```\n\n1. **state에 따라서 UI가 어떻게 보일지 조건문 등으로 작성**\n\n```jsx\n{\n  modal === true ? <Modal/> : null\n }\n```','리액트에서 동적인 UI 만드는 step    html css로 미리 UI 디자인을 다 해놓고  function Modal() {   return (     <div className=\'modal\'>       <h4>제목</h4>       <p>날짜</p>       <p>상세내용</p>     </div>   ) }    UI의 현재 상태를 state로 저장해두고  let [modal, setModal] = useState(false)    state에 따라서 UI가 어떻게 보일지 조건문 등으로 작성  {   modal === true ? <Modal/> : null  } ','4. 리액트 환경에서 동적인 UI 만드는 법'),(_binary '','2023-11-16 02:11:08.180620',40,124,'2023-11-16 02:00:56.733720',6,'### **자바스크립트 map 함수 쓰는 법**\n\n똑같은 html이 반복적으로 출현하면\n\n반복문을 이용해서 쉽게 똑같은 html을 생성할 수도 있습니다.\n\n**안타깝게도 for 반복문은 JSX 중괄호 안에서 사용할 수 없어서 map() 을 대신 사용합니다.**\n\n### **JSX 안에서 html을 반복생성하고 싶으면**\n\n```jsx\n{\n  글제목들.map((글제목, idx)=> {\n    return (\n      <div className=\'list\' key={idx}>\n        <p>{idx} 번째 글</p>\n        <h4 onClick={ toggleModal }>{ 글제목 }</h4>\n        <span onClick={ () => like(idx) }>🍬</span> { 따봉[idx] }\n        <p>2월 14일 발행</p>\n      </div>\n    )\n  })\n }\n```\n\n(참고) map 반복문으로 반복생성한 html엔 key={i} 이런 속성을 추가해야합니다.\n\n```jsx\n<div className=\"list\" key={i}>\n```\n\n그래야 리액트가 <div>들을 각각 구분할 수 있어서 그렇습니다.\n\n없으면 워닝띄워줌','자바스크립트 map 함수 쓰는 법 똑같은 html이 반복적으로 출현하면  반복문을 이용해서 쉽게 똑같은 html을 생성할 수도 있습니다.  안타깝게도 for 반복문은 JSX 중괄호 안에서 사용할 수 없어서 map() 을 대신 사용합니다.  JSX 안에서 html을 반복생성하고 싶으면 {   글제목들.map((글제목, idx)=> {     return (       <div className=\'list\' key={idx}>         <p>{idx} 번째 글</p>         <h4 onClick={ toggleModal }>{ 글제목 }</h4>         <span onClick={ () => like(idx) }>🍬</span> { 따봉[idx] }         <p>2월 14일 발행</','5. map: 많은 div들을 반복문으로 줄이고 싶을때'),(_binary '','2023-11-16 02:10:57.781707',40,125,'2023-11-16 02:01:35.734948',6,'### **<Modal>안에 글제목 state 가 필요한데**\n\n---\n\n```jsx\nfunction App (){\n  let [글제목, 글제목변경] = useState([\'남자코트 추천\', \'강남 우동맛집\', \'파이썬독학\']);\n  return (\n    <div>\n      <Modal></Modal>\n    </div>\n  )\n}\n\nfunction Modal(){\n  return (\n    <div className=\"modal\">\n      <h4>{ 글제목[0] }</h4>\n      <p>날짜</p>\n      <p>상세내용</p>\n    </div>\n  )\n}\n```\n\n- 하지만 제대로 실행 안됨\n\n\'글제목\'이라는 변수가 define 되지 않았다고 에러가 뜹니다.\n\n왜냐면 글제목이라는 state 변수는 function App()에 있지 function Modal()에 없으니까요.\n\n자바스크립트에선 다른 함수에 있는 변수를 마음대로 가져다쓸 수 없습니다.\n\n컴포넌트 2개가 부모/자식 관계인 경우엔 가능합니다.\n\n(다른 컴포넌트 안에 있는 컴포넌트를 자식컴포넌트라고 부릅니다\n\n부모 컴포넌트의 state를 자식 컴포넌트로 전송해줄 수 있습니다. 그럼 자식도 사용가능\n\n전송시엔 props라는 문법을 사용합니다.\n\n### **props로 부모 -> 자식 state 전송하는 법**\n\n---\n\n**1.  자식컴포넌트 사용하는 곳에 가서 <자식컴포넌트 작명={state이름} />**\n\n**2.  자식컴포넌트 만드는 function으로 가서 props라는 파라미터 등록 후 props.작명 사용**\n\n**글제목**이라는 부모 컴포넌트의 state를 자식 컴포넌트 <Modal>에 전송\n\n```jsx\nfunction App (){\n  let [글제목, 글제목변경] = useState([\'남자코트 추천\', \'강남 우동맛집\', \'파이썬독학\']);\n  return (\n    <div>\n      <Modal 글제목={글제목}></Modal>\n    </div>\n  )\n}\n\nfunction Modal(props){\n  return (\n    <div className=\"modal\">\n      <h4>{ props.글제목[0] }</h4>\n      <p>날짜</p>\n      <p>상세내용</p>\n    </div>\n  )\n}\n```\n\n1.  자식컴포넌트 사용하는 곳에 가서 **<자식컴포넌트 작명={state이름} />**\n2.  자식컴포넌트 만드는 곳에 가서 props라는 파라미터 등록 후 **props.작명** 사용하면 됩니다.\n\nprops 전송문법은 중요하니 외워두도록 합시다.\n\n![자식 → 부모 패륜방향 전송은 불가능합니다.](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6da7d2c0-7e1f-447b-b85d-c115362069f7/Untitled.png)\n\n자식 → 부모 패륜방향 전송은 불가능합니다.\n\n![옆집 컴포넌트로의 불륜전송도 불가능합니다.](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/550189c7-c638-4245-b640-65fd52654f9b/Untitled.png)\n\n옆집 컴포넌트로의 불륜전송도 불가능합니다.\n\n### **props는 함수 파라미터 문법이랑 똑같습니다**\n\n---\n\n\"함수 하나로 다양한 기능을 사용하기 위해서 쓰는게 파라미터 문법\" 이랬습니다.\n\nprops도 실은 파라미터랑 똑같은 문법입니다.\n\n```jsx\nfunction Modal(props){\n  return (\n    <div className=\"modal\" style={{ background : props.color }}>\n      <h4>{ props.글제목[0] }</h4>\n      <p>날짜</p>\n      <p>상세내용</p>\n    </div>\n  )\n}\n```\n\nprops.color 이런 식으로 구멍을 뚫어놓으면 이제 컴포넌트 사용할 때\n\n<Modal color={\'skyblue\'} /> 이러면 하늘색 모달창이 생성됩니다.\n\n<Modal color={\'orange\'} /> 이러면 오렌지색 모달창이 생성됩니다.\n\n그래서 비슷한 컴포넌트를 또 만들 필요가 없어지는 것입니다.','안에 글제목 state 가 필요한데  function App (){   let [글제목, 글제목변경] = useState([\'남자코트 추천\', \'강남 우동맛집\', \'파이썬독학\']);   return (     <div>       <Modal></Modal>     </div>   ) }  function Modal(){   return (     <div className=\"modal\">       <h4>{ 글제목[0] }</h4>       <p>날짜</p>       <p>상세내용</p>     </div>   ) }    하지만 제대로 실행 안됨  \'글제목\'이라는 변수가 define 되지 않았다고 에러가 뜹니다.  왜냐면 글제목이라는 state 변수는 function App()에 있지 functio','6. 자식이 부모의 state 가져다쓰고 싶을 때는 props'),(_binary '','2023-11-16 02:10:48.648595',40,126,'2023-11-16 02:25:27.571669',6,'### 제목을 클릭했을 때 해당하는 상세페이지로 이동\n\n1. **현재 UI의 상태를 state로 만들어두고**\n\n```jsx\nlet [title, setTitle] = useState(0);\n```\n\nfunction App(){} 안에 state 하나 만들었습니다.\n\n모달창 안의 글제목은 0번글이 보이거나 1번글이 보이거나 2번글이 보이거나\n\n이런 상태밖에 없어서 그냥 숫자로 표현하고 싶어서 숫자적어놨습니다.\n\n1. **state에 따라서 UI가 어떻게 보일지 작성**\n\n```jsx\nfunction App (){\n  let [title, setTitle] = useState(0);\n  (생략)\n}\n\nfunction Modal(props){\n  return (\n    <div className=\"modal\">\n      <h4>{ 만약에 title == 0이면 0번 글제목 보여주세요~ }</h4>\n      <p>날짜</p>\n      <p>상세내용</p>\n    </div>\n  )\n}\n```\n\n결과\n\n```jsx\nfunction App (){\n  let [title, setTitle] = useState(0);\n  (생략)\n  {\n    modal == true ? <Modal title={title} 글제목={글제목} /> : null\n  }\n}\n\nfunction Modal(props){\n  return (\n    <div className=\"modal\">\n      <h4>{ props.글제목[props.title] }</h4>\n      <p>날짜</p>\n      <p>상세내용</p>\n    </div>\n  )\n}\n```\n\nprops 전송은 됐지만 어떠한 제목을 클릭한지 알지 못함.\n\n```jsx\nfunction App (){\n  return (\n    <div>\n      { \n        글제목.map(function(a, i){\n          return (\n          <div className=\"list\">\n            <h4 onClick={()=>{ setModal(true); setTitle(i); }}>{ 글제목[i] }</h4>\n            <p>2월 18일 발행</p>\n          </div> )\n        }) \n      }\n    </div>\n  )\n}\n```','제목을 클릭했을 때 해당하는 상세페이지로 이동   현재 UI의 상태를 state로 만들어두고  let [title, setTitle] = useState(0);  function App(){} 안에 state 하나 만들었습니다.  모달창 안의 글제목은 0번글이 보이거나 1번글이 보이거나 2번글이 보이거나  이런 상태밖에 없어서 그냥 숫자로 표현하고 싶어서 숫자적어놨습니다.    state에 따라서 UI가 어떻게 보일지 작성  function App (){   let [title, setTitle] = useState(0);   (생략) }  function Modal(props){   return (     <div className=\"modal\">       <h4>{ 만약에 title == 0이면 0번 ','7. props를 응용한 상세페이지 만들기'),(_binary '','2023-11-16 02:10:40.353380',40,127,'2023-11-16 02:25:25.524166',6,'### **`<input>` 에 뭔가 입력시 코드를 실행하려면**\n\n유저가 <input>에 뭔가 입력시 코드를 실행해주고 싶을 때가 많습니다.\n\n그러고 싶으면 onChange 아니면 onInput 이벤트핸들러를 부착하면 됩니다.\n\n```jsx\n<input onChange={()=>{ 실행할코드 }}/>\n```\n\n(참고)\n\n이벤트 핸들러들은 매우 많습니다.\n\nonMouseOver={ } 이건 이 요소에 마우스를 댔을 때 안의 코드를 실행해줍니다.\n\nonScroll={ } 이건 이 요소를 스크롤했을 때 안의 코드를 실행해줍니다.\n\n몇십개 있는데 원하는 이벤트가 있으면 찾아서 사용해봅시다.\n\n### **<input>에 입력한 값 가져오는 법**\n\n```jsx\n<input onChange={(e)=>{ console.log(e.target.value) }}/>\n```\n\ne.target 이러면 현재 이벤트가 발생한 곳을 알려주고\n\ne.preventDefault() 이러면 이벤트 기본 동작을 막아주고\n\ne.stopPropagation() 이러면 이벤트 버블링도 막아줍니다. 이거 쓰면 좋아요버튼 누를 때 모달창도 떠버리는 버그 해결가능\n\n### **사용자가 input에 입력한 데이터 저장하기**\n\n```jsx\nfunction App (){\n\n  let [입력값, 입력값변경] = useState(\'\');\n  return (\n    <input onChange={(e)=>{ \n      입력값변경(e.target.value) \n      console.log(입력값)\n    }} />\n  )\n}\n```\n\nstate를 하나 만들어주고 onChange될 때 마다 state에 e.target.value 넣으라고 코드를 짰습니다.\n\nstate에 문자를 저장하고 싶은데 일단 기본값을 뭘 넣을지 모르겠으면 따옴표 2개만 치면 됩니다.\n\n따옴표 2개는 빈문자를 뜻합니다.\n\n이제 입력값이라는 state를 필요한 곳에서 마음대로 사용하면 되겠습니다.\n\n(참고)\n\n근데 위 코드 실행해보면 a를 입력하면 콘솔창에 아무것도 안뜨지 않습니까\n\naa를 입력하면 a만 콘솔창에 뜨고요.\n\n왜냐면 state 변경함수 특징 때문인데 **state 변경함수는 약간 늦게 처리됩니다.**\n\n전문용어로 async하게 (비동기적으로) 처리된다고 합니다.\n\n그리고 자바스크립트에선 늦게 처리되는 코드들은 잠깐 제쳐두고 바로 다음줄을 실행해줍니다.\n\n그래서 console.log(입력값) 이게 먼저 실행되어서 저렇게 나오는 것일 뿐입니다.\n\n그냥 실행 순서만 좀 다를 뿐 state변경은 어쨌든 잘 됩니다.\n\n### 화면과 같이 만들기\n\n1. input 과 button 태그 만들고 글제목들 arrary 복사해서 state 변경해주기\n\n```jsx\nconst [글제목들, set글제목들] = useState([\'남자코트 추천\', \'강남 우동 맛집\', \'리액트 기초 배우기\'])\nconst [input, setInput] = useState(\'\')\n\n<input \n      type=\'text\'\n      value={input} //이걸 넣어줘야 양방향으로 값이 바뀜\n      onChange={(e)=>{setInput(e.target.value)}}\n      />\n\n      <button\n      onClick={()=>{\n        const copy = [...글제목들]\n        copy.push(input)\n        set글제목들(copy)\n\n        const copyLikes = [...따봉] //따봉 Arrary도 추가해주기 위함\n        copyLikes.push(0)\n        set따봉(copyLikes)\n        setInput(\'\')\n      }}\n      >글발행</button>\n```','<input> 에 뭔가 입력시 코드를 실행하려면 유저가 에 뭔가 입력시 코드를 실행해주고 싶을 때가 많습니다.  그러고 싶으면 onChange 아니면 onInput 이벤트핸들러를 부착하면 됩니다.  <input onChange={()=>{ 실행할코드 }}/>  (참고)  이벤트 핸들러들은 매우 많습니다.  onMouseOver={ } 이건 이 요소에 마우스를 댔을 때 안의 코드를 실행해줍니다.  onScroll={ } 이건 이 요소를 스크롤했을 때 안의 코드를 실행해줍니다.  몇십개 있는데 원하는 이벤트가 있으면 찾아서 사용해봅시다.  에 입력한 값 가져오는 법 <input onChange={(e)=>{ console.log(e.target.value) }}/>  e.target 이러면 현재 이벤트가 발생한','8. input 1 : 사용자가 입력한 글 다루기'),(_binary '','2023-11-16 02:10:31.364991',40,128,'2023-11-16 02:25:20.698082',6,'# 기존학습내용 복습\n\n---\n\n### **버튼누르면 유저가 입력한 글을 글목록에 추가해주세요**\n\n```jsx\nconst [글제목들, set글제목들] = useState([\'남자코트 추천\', \'강남 우동 맛집\', \'리액트 기초 배우기\'])\nconst [input, setInput] = useState(\'\')\n\n...\n\n<input \ntype=\'text\'\nvalue={input}\nonChange={(e)=>{setInput(e.target.value)}}\n/>\n\n<button\nonClick={()=>{\n  const copy = [...글제목들]\n  copy.unshift(input)\n  set글제목들(copy)\n  setInput(\'\')\n}}\n>글발행</button>\n```\n\n### **글마다 삭제버튼과 기능만들기**\n\n```jsx\nconst [글제목들, set글제목들] = useState([\'남자코트 추천\', \'강남 우동 맛집\', \'리액트 기초 배우기\'])\nconst [input, setInput] = useState(\'\')\n\n...\n\n{\n  글제목들.map((글제목, idx)=> {\n    return (\n      <div className=\'list\' key={idx}>\n        <p>{idx} 번째 글</p>\n        <h4 onClick={ ()=> {\n          toggleModal() \n          setTitle(idx)\n          }\n        }>\n        { 글제목 }\n          <span onClick={ (e) => {e.stopPropagation(); like(idx);} }>🍬</span> { 따봉[idx] }\n        </h4>\n        <p>2월 14일 발행</p>\n        <button onClick={()=>{\n          const copy = [...글제목들]\n          copy.splice(idx, 1) // idx번째 글 하나 삭제 splice 기능\n          set글제목들(copy)\n        }}>삭제</button>\n      </div>\n    )\n  })\n}\n```\n\n### **글에 아무것도 입력안하고 발행버튼 누르는거 막으려면?**\n\n```jsx\n<button\nonClick={()=>{\n  if (input === \'\') { // 글이 빈칸이면\n    window.alert(\'글을 입력하세요~\')\n    return\n  }\n  const copy = [...글제목들]\n  copy.unshift(input)\n  set글제목들(copy)\n  setInput(\'\')\n}}\n>글발행</button>\n```\n\n### **글을 하나 추가하면 따봉갯수 개별적용하던 것도 이상해질 수 있습니다.**\n\n```jsx\n<button\nonClick={()=>{\n  if (input === \'\') {\n    window.alert(\'글을 입력하세요~\')\n    return\n  }\n  const copy = [...글제목들]\n  copy.unshift(input)\n  set글제목들(copy)\n\n  const copyLikes = [...따봉] // 따봉갯수도 글의 갯수에 알맞게끔 Arrary에 추가\n  copyLikes.unshift(0)\n  set따봉(copyLikes)\n  setInput(\'\')\n}}\n>글발행</button>\n```\n\n### 날짜데이터 추가\n\n- 첫번째로 날짜를 추가하기 위해선 전체적인 구조 변경 필요\n- 기존에 Arrary로 가지고 오던 글제목들을 ⇒ articles로 변경하면서 객체로 변경\n- 객체 변경과 동시에 articles객체 속성에 title과 date 속성 추가\n\n```jsx\nimport { useState } from \'react\';\nimport \'./App.css\';\nimport React from \'react\';\n\nfunction App() {\n\n  // const [글제목들, set글제목들] = useState([\'남자코트 추천\', \'강남 우동 맛집\', \'리액트 기초 배우기\'])\n  const [따봉, set따봉] = useState([0, 0, 0]) ;\n  const [modal, setModal] = useState(false)\n  const [articleIndex, setArticleIndex] = useState(0)\n  const [input, setInput] = useState(\'\')\n  // const [date, setDate] = useState([\'2023/05/13 17:22\', \'2022/9/28 17:22\', \'2023/12/22 17:22\'])\n  \n	// 객체로 변경\n	const [articles, setArticles] = useState(\n    [\n      {\n        title : \'남자코트 추천\',\n        date : \'2023/05/13 17:22\'\n      },\n      {\n        title : \'강남 우동 맛집\',\n        date : \'2022/9/28 17:22\'\n      },\n      {\n        title : \'리액트 기초 배우기\',\n        date : \'2023/12/22 17:22\'\n      }\n    ]\n  )\n\n  function like(idx) {\n    const copy = [...따봉]\n    copy[idx] += 1\n    set따봉( copy )\n  }\n  function changeName() {\n    // console.log(articles)\n    const copy = [...articles]\n    copy[0].title = \'여자코트 추천\'\n    setArticles(copy)\n  }\n\n	// 객체로 변경시 정렬 방식이 바뀌므로 주석처리\n  // function sortArrary() {\n  //   let copy = [...articles]\n  //   copy.sort()\n  //   setArticles(copy)\n  // }\n  function toggleModal() {\n    setModal(!modal)\n  }\n\n  return (\n    <div className=\"App\">\n      <div className=\'black-nav\'>\n        <h4>React Blog</h4>\n      </div>\n\n      {/* <button onClick={ sortArrary }>가나다라정렬</button> */}\n\n      <button onClick={ changeName }> 글 수정</button>\n\n      {\n        articles.map((article, idx)=> {\n          return (\n            <div className=\'list\' key={idx}>\n              <p>{idx} 번째 글</p>\n              <h4 onClick={ ()=> {\n                toggleModal() \n                setArticleIndex(idx)\n                }\n              }>\n              { article.title }\n                <span onClick={ (e) => {e.stopPropagation(); like(idx);} }>🍬</span> { 따봉[idx] }\n              </h4>\n              <p>{ article.date}</p>\n              <button onClick={()=>{\n                const copy = [...articles]\n                copy.splice(idx, 1)\n                setArticles(copy)\n              }}>삭제</button>\n            </div>\n          )\n        })\n      }\n      {\n        modal === true ? \n        <Modal \n        articles={articles}\n        changeName={changeName}\n        articleIndex={articleIndex}\n        /> : null\n      }\n\n      <input \n      type=\'text\'\n      value={input}\n      onChange={(e)=>{setInput(e.target.value)}}\n      />\n\n      <button\n      onClick={()=>{\n        if (input.trim() === \'\') {\n          window.alert(\'글을 입력하세요~\')\n          return\n        }\n        \n				// 날짜로 가지고 오기 위한 날짜 함수들\n        const copy = [...articles]\n        const today = new Date()\n        const year = today.getFullYear()\n        const month = today.getMonth() + 1\n        const date = today.getDate()\n        const hours = today.getHours()\n        const minutes = today.getMinutes()\n\n        const todayDate = (year + \'/\' + month + \'/\' + date + \' \' + hours + \':\' + minutes) \n        copy.unshift(\n          {\n            title: input,\n            date: todayDate\n          }\n        )\n        // copy.unshift(input)\n        setArticles(copy)\n\n        const copyLikes = [...따봉]\n        copyLikes.unshift(0)\n        set따봉(copyLikes)\n        setInput(\'\')\n      }}\n      >글발행</button>\n    </div>\n  );\n}\n\nfunction Modal(props) {\n  console.log(props)\n  \n  const articles = props.articles[props.articleIndex]\n  \n  return (\n    <div className=\'modal\'>\n      <h4>{articles.title }</h4>\n      <p> {articles.date} </p>\n      <p>상세내용</p>\n      <button onClick={()=> { props.changeName() }}>글 수정</button>\n    </div>\n  )\n}\n\nexport default App;\n```','기존학습내용 복습  버튼누르면 유저가 입력한 글을 글목록에 추가해주세요 const [글제목들, set글제목들] = useState([\'남자코트 추천\', \'강남 우동 맛집\', \'리액트 기초 배우기\']) const [input, setInput] = useState(\'\')  ...  <input  type=\'text\' value={input} onChange={(e)=>{setInput(e.target.value)}} />  <button onClick={()=>{   const copy = [...글제목들]   copy.unshift(input)   set글제목들(copy)   setInput(\'\') }} >글발행</button>  글마다 삭제버튼과 기능만들기 const [글제목들, set글제목들] = use','9. input 다루기 2 : 블로그 글발행 기능 만들기'),(_binary '','2023-11-16 02:21:03.256401',40,130,'2023-11-16 02:25:32.595397',6,'class 문법으로 컴포넌트 만드는 법\n1. class + 컴포넌트 이름 작명합니다.\n2. constuctor, super, render 함수 3개 채워넣습니다.\n3. 컴포넌트는 길고 복잡한 html 축약할 때 쓴다고 했습니다. return  안에 축약한 html 적으면 됩니다.\n\n```\nclass Modal2 extends React.Component {\n  constructor(){\n    super()\n  }\n\n  render(){\n    return (\n      <div>안녕</div>\n    )\n  }\n\n}\n```','class 문법으로 컴포넌트 만드는 법 1. class + 컴포넌트 이름 작명합니다. 2. constuctor, super, render 함수 3개 채워넣습니다. 3. 컴포넌트는 길고 복잡한 html 축약할 때 쓴다고 했습니다. return  안에 축약한 html 적으면 됩니다.  class Modal2 extends React.Component {   constructor(){     super()   }    render(){     return (       <div>안녕</div>     )   }  } ','10. class를 이용한 옛날 React 문법'),(_binary '','2023-11-16 02:28:48.502251',40,131,'2023-11-16 02:28:55.323150',6,'## 서버란\n- \"누가 A를 요청하면 A를 보내주세요\"\n서버에 데이터를 요청할 때는 정확한 규격에 맞춰서 요청해야하는데\n1. 어떤 데이터인지(URL 형식으로)\n2. 어떤 방법으로 요청할지 (GET or POST)\n\n잘 기재해야 데이터를 보내줍니다.\n\n### **GET/POST 요청하는 법?**\n\n---\n\nGET요청을 날리고 싶으면 가장 쉬운 방법은 브라우저 주소창입니다.\n\n거기에 URL 아무거나 적으면 그 곳으로 GET요청을 날려줍니다.\n\n진짠지 테스트해보셈\n\nPOST요청을 날리고 싶으면\n\n<form action=\"요청할url\" method=\"post\"> 태그 이용하면 됩니다.\n\n그럼 폼이 전송되었을 때 POST요청을 날려줍니다.\n\n근데 GET, POST 요청을 저렇게 날리면 단점이 뭐냐면 **브라우저가 새로고침**됩니다.\n\n## **AJAX 요청하는 법**\n\n---\n\n```jsx\nimport axios from \'axios\'\n\nfunction App(){\n  return (\n    <button onClick={()=>{\n      axios.get(\'https://codingapple1.github.io/shop/data2.json\').then((결과)=>{\n        console.log(결과.data)\n      })\n      .catch(()=>{\n        console.log(\'실패함\')\n      })\n    }}>버튼</button>\n  )\n}\n```','서버란   누가 A를 요청하면 A를 보내주세요 서버에 데이터를 요청할 때는 정확한 규격에 맞춰서 요청해야하는데   어떤 데이터인지(URL 형식으로)  어떤 방법으로 요청할지 (GET or POST)  잘 기재해야 데이터를 보내줍니다.  GET/POST 요청하는 법?  GET요청을 날리고 싶으면 가장 쉬운 방법은 브라우저 주소창입니다.  거기에 URL 아무거나 적으면 그 곳으로 GET요청을 날려줍니다.  진짠지 테스트해보셈  POST요청을 날리고 싶으면   그럼 폼이 전송되었을 때 POST요청을 날려줍니다.  근데 GET, POST 요청을 저렇게 날리면 단점이 뭐냐면 브라우저가 새로고침됩니다.  AJAX 요청하는 법  import axios from \'axios\'  function App(){   return','리액트에서 서버와 통신하려면'),(_binary '\0','2023-11-16 04:37:16.342834',14,137,NULL,6,'### 완전 검색(Exaustive Search)\n\n- 문제의 해법으로 생각할 수 있는 모든 경우의 수를 나열해보고 확인하는 기법\n- 수행 속도 느리지만 해답 찾아내지 못할 확률 작음\n- 경우의 수가 상대적으로 작을 경우 유용\n- 문제 풀 때 완전 검색으로 해답 도출 후, 성능 개선 위해 다른 알고리즘 사용하고 해답 확인하는 것이 바람직\n- 완전 검색 종류\n    1. Brute-force : for문 사용하여 처음부터 끝까지 탐색\n    2. 비트 마스크 : 비트 연산 사용(&, |, ^, ~, <<, >>)\n    3. 백트래킹 : 해를 찾아가는 도중 해가 될 가능성이 없는 경로라면 되돌아감\n    4. 재귀함수 : 함수 내에서 함수 자기 자신을 계속해서 호출\n    5. 순열 : 서로 다른 n개 중에서 r개를 뽑아서 한 줄로 나열\n        - nPr = n * (n-1) * (n-2) * ... * (n-r+1) = n! / (n-r)!\n    6. BFS(너비 우선 탐색)/ DFS(깊이 우선 탐색)\n\n### 순차 검색 (Sequential Search)\n\n- 일렬로 되어 있는 자료를 순서대로 검색하는 방법, 간단하고 직관적\n- 배열이나 연결 리스트 등 순차구조로 구현된 자료구조에서 원하는 항목을 찾을 때 유용\n- 검색 대상이 많을 때는 수행시간 급격히 증가\n- 정렬되어 있지 않은 경우\n    - 첫 번째 원소부터 순서대로 검색 대상과 키 값이 같은 원소가 있는지 비교하며 찾음\n    - 키 값이 동일한 원소를 찾으면 그 원소의 인덱스 반환\n    - 자료구조의 마지막에 이를 때까지 검색 대상을 찾지 못하면 검색 실패\n    - 찾고자하는 원소의 순서에 따라 비교 횟수가 결정됨\n        - 첫 번째 원소를 찾으면 1번 비교, 두 번째 원소를 찾으면 2번 비교 ...\n        - 정렬되지 않은 자료에서의 순차 검색 평균 비교 횟수\n        - = (1/n) * (1+2+3+...+n) = (n+1)/2\n    - 시간 복잡도 : O(n)\n    \n- 정렬되어 있는 경우\n    - 자료가 오름차순 정렬된 상태에서 검색을 실시할 경우, 자료를 순차적으로 검색하며 키 값을 비교하여원소의 키 값이 검색 대상의 키 값보다 크면 찾는 원소가 없다는 것이므로 더 이상 검색하지 않고 검색 종료\n    - 찾고자 하는 원소의 순서에 따라 비교 횟수가 결정됨\n        - 정렬이 되어있으므로, 검색 실패를 반환하는 경우 평균 비교 횟수가 반으로 줄어듦\n    - 시간 복잡도 : O(n)\n\n### 이진 검색 (Binary Search)\n\n- 자료의 가운데에 있는 항목의 키 값과 비교하여 다음 검색의 위치를 결정하고 검색을 계속 진행하는 방법\n- 목적 키를 찾을 때까지 이진 검색 반복 수행함으로써 검색 범위를 반으로 줄여가며 보다 빠르게 검색을 수행\n- 이진 검색을 하기 위해서는 자료가 정렬된 상태여야함\n- 검색 과정\n    1. 자료의 중앙에 있는 원소 고름\n    2. 중앙 원소의 값과 찾고자 하는 목표 값 비교\n    3. 목표 값이 중앙 원소의 값보다 작으면 자료의 왼쪽 반에 대해서 새로 검색을 수행, 크다면 자료의 오른쪽 반에 대해서 새로 검색을 수행\n    4. 찾고자 하는 값을 찾을 때까지 1-3 반복\n- 구현\n    - 검색 범위의 시작점과 종료점을 이용하여 검색을 반복 수행\n    - 자료에 삽입이나 삭제가 발생했을 때, 배열의 상태를 항상 정렬 상태로 유지하는 추가 작업 필요\n\n\n### 선택 정렬 (Selection Sort)\n\n- 주어진 자료들 중 가장 작은 값의 원소부터 차례대로 선택하여 위치를 교환하는 방식\n- 정렬 과정\n    1. 주어진 리스트 중에서 최소값 찾기\n    2. 그 값을 리스트의 맨 앞에 위치한 값과 교환\n    3. 맨 처음 위치를 제외한 나머지 리스트를 대상으로 위의 과정 반복\n- 비교와 교환\n- 교환의 횟수가 버블, 삽입 정렬보다 작음\n- O(n^2)','완전 검색(Exaustive Search)   문제의 해법으로 생각할 수 있는 모든 경우의 수를 나열해보고 확인하는 기법  수행 속도 느리지만 해답 찾아내지 못할 확률 작음  경우의 수가 상대적으로 작을 경우 유용  문제 풀 때 완전 검색으로 해답 도출 후, 성능 개선 위해 다른 알고리즘 사용하고 해답 확인하는 것이 바람직  완전 검색 종류   Brute-force : for문 사용하여 처음부터 끝까지 탐색  비트 마스크 : 비트 연산 사용(&, |, ^, ~, , )  백트래킹 : 해를 찾아가는 도중 해가 될 가능성이 없는 경로라면 되돌아감  재귀함수 : 함수 내에서 함수 자기 자신을 계속해서 호출  순열 : 서로 다른 n개 중에서 r개를 뽑아서 한 줄로 나열   nPr = n * (n-1) * (n-2)','알고리즘(탐색, 선택정렬)'),(_binary '\0',NULL,44,138,NULL,15,NULL,NULL,'글 제목');
/*!40000 ALTER TABLE `note` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `notification`
--

DROP TABLE IF EXISTS `notification`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `notification` (
  `is_read` bit(1) DEFAULT NULL,
  `date_time` datetime(6) DEFAULT NULL,
  `id` varchar(255) COLLATE utf8mb4_unicode_ci NOT NULL,
  `note_id` bigint DEFAULT NULL,
  `receiver_id` bigint NOT NULL,
  `sender_id` bigint NOT NULL,
  `message` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `type` enum('BOOKMARK','QUOTE') COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `title` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `FKnw9h9nwuv4ibj02k085mmaqxa` (`note_id`),
  KEY `FK1jpw68rbaxvu8u5l1dniain1l` (`receiver_id`),
  KEY `FKovuqht5f5v592yehlp3tgji9y` (`sender_id`),
  CONSTRAINT `FK1jpw68rbaxvu8u5l1dniain1l` FOREIGN KEY (`receiver_id`) REFERENCES `member` (`id`),
  CONSTRAINT `FKnw9h9nwuv4ibj02k085mmaqxa` FOREIGN KEY (`note_id`) REFERENCES `note` (`id`),
  CONSTRAINT `FKovuqht5f5v592yehlp3tgji9y` FOREIGN KEY (`sender_id`) REFERENCES `member` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `notification`
--

LOCK TABLES `notification` WRITE;
/*!40000 ALTER TABLE `notification` DISABLE KEYS */;
INSERT INTO `notification` VALUES (_binary '','2023-11-16 06:28:10.702536','15_4_1dba6e6c-4aa9-401a-a14a-fca2db91e5bd',14,4,15,NULL,'BOOKMARK','Docker Compose'),(_binary '\0','2023-11-16 06:27:30.753500','15_4_52162ad8-45da-42f0-a2af-e6d17acfbb1e',14,4,15,NULL,'BOOKMARK','Docker Compose'),(_binary '\0','2023-11-16 06:27:25.334267','15_4_60d1ba18-ba43-407d-bb72-cd371e1f623d',9,4,15,NULL,'BOOKMARK','Docker'),(_binary '\0','2023-11-16 06:26:46.993850','15_4_7065d26f-6d3d-4f54-91e9-fbbdb4d4069d',9,4,15,NULL,'BOOKMARK','Docker'),(_binary '','2023-11-16 06:28:01.117656','15_4_a1a48dce-682f-4f20-a0c4-58911b54fe29',14,4,15,NULL,'BOOKMARK','Docker Compose'),(_binary '\0','2023-11-16 06:27:15.777525','15_4_b9af09c3-2bec-4bbc-a444-b86d5b2e4c84',9,4,15,NULL,'BOOKMARK','Docker'),(_binary '\0','2023-11-16 16:39:45.816698','2_1_5b7390ed-8b5b-4790-b002-7e5b2d639fbe',55,1,2,NULL,'QUOTE','나김하늘성원숭'),(_binary '\0','2023-11-16 16:39:45.889040','2_4_9ffc9562-847b-4dd2-b308-7815c0300fc7',55,4,2,NULL,'QUOTE','나김하늘성원숭');
/*!40000 ALTER TABLE `notification` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `quotation`
--

DROP TABLE IF EXISTS `quotation`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `quotation` (
  `e_note_id` bigint DEFAULT NULL,
  `id` bigint NOT NULL AUTO_INCREMENT,
  `member_id` bigint DEFAULT NULL,
  `s_note_id` bigint DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `FKqf7wnsd8r4r3io7c4f3dfkt2k` (`e_note_id`),
  KEY `FK5rsns812emjj7muqrg8vces3r` (`member_id`),
  KEY `FKq0b5ga2huw8c123gujnmeo2xu` (`s_note_id`),
  CONSTRAINT `FK5rsns812emjj7muqrg8vces3r` FOREIGN KEY (`member_id`) REFERENCES `member` (`id`),
  CONSTRAINT `FKq0b5ga2huw8c123gujnmeo2xu` FOREIGN KEY (`s_note_id`) REFERENCES `note` (`id`),
  CONSTRAINT `FKqf7wnsd8r4r3io7c4f3dfkt2k` FOREIGN KEY (`e_note_id`) REFERENCES `note` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=154 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `quotation`
--

LOCK TABLES `quotation` WRITE;
/*!40000 ALTER TABLE `quotation` DISABLE KEYS */;
INSERT INTO `quotation` VALUES (8,5,3,6),(26,15,4,9),(26,16,4,15),(41,25,4,28),(41,26,4,37),(28,27,4,43),(37,28,4,43),(35,32,4,22),(22,33,4,43),(25,34,4,43),(24,35,4,43),(27,36,4,24),(30,37,4,24),(31,38,4,24),(32,39,4,24),(33,40,4,43),(36,41,4,43),(29,42,4,36),(34,43,4,36),(10,44,4,38),(10,45,4,8),(43,46,4,9),(59,72,7,55),(13,90,4,16),(14,91,4,9),(15,92,4,13),(15,93,4,16),(19,94,4,9),(20,95,4,9),(21,96,4,9),(23,97,4,13),(38,98,4,35),(38,99,4,25),(40,100,4,20),(40,101,4,43),(42,102,4,13),(102,104,1,101),(100,105,1,99),(94,107,1,93),(95,108,1,94),(96,109,1,95),(97,110,1,96),(98,111,1,97),(99,112,1,98),(103,114,1,102),(11,115,4,20),(11,116,4,9),(11,117,4,101),(109,118,10,8),(101,125,1,100),(93,126,1,92),(128,127,6,127),(127,128,6,126),(126,129,6,125),(125,130,6,124),(124,131,6,123),(123,132,6,122),(121,134,6,120),(130,145,6,128),(130,146,6,127),(131,147,6,130),(122,148,6,121),(55,150,2,58),(55,151,2,6),(55,152,2,7),(55,153,2,9);
/*!40000 ALTER TABLE `quotation` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Dumping routines for database 'ziglogdb'
--
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2023-11-16 17:23:48
